[{"categories":["Integration"],"content":"test desc","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"ODATA actions in Data Entities provide a way to inject behaviors into the data model, or expose custom business logic from Dynamics 365 Finance \u0026 Operations. You can add actions by adding a method to the data entity and then decorating the method with specific attributes [SysODataActionAttribute] I use this Odata actions mostly in automation job like after refreshing data from PROD to UAT, we need to enable users, assign company to users, enable batches … Or simply consume it in Power Automate. 1. Create an action to OData entity You can create a new entity following this standard docs or you can duplicate any standard entity. I created AutomationDataEntity. Right-click the enitity, select View code and add the code public class AutomationDataEntity extends common { //1st example [SysODataActionAttribute(\"assignUserToCompany\", false)] public static void assignUserToCompany(NetworkAlias _networkAlias, DataAreaName _company) { UserInfo userInfo; ttsbegin; select firstonly forupdate userInfo where userInfo.networkAlias == _networkAlias; userInfo.company = _company; userInfo.update(); ttscommit; } //2nd example [SysODataActionAttribute(\"ReturnRental\", true)] public str ReturnRental() { return \"Rental was successfully returned. Thanks for your business\"; } //following 3rd example of an OData action takes in a parameter and returns a list [SysODataActionAttribute(\"GetColors\", true), SysODataCollectionAttribute(\"return\", Types::Record, \"CarColor\")] public List GetColorsByAvailability(boolean onlyAvailableVehicles) { List returnList = new List(Types::Record); // do something return returnList; } } In this example, the SysODataActionAttribute class decorates the assginUserToCompany method that is exposed as an action. The first argument of the attribute is the publicly exposed name of the action, and the second argument indicates whether this action need an entity instance or not. If you set the second argument to false, the method has to be static. You might need reset IIS service to update Odata endpoint. 2. Test Entity Odata actions with Postman and Power Automate ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:0:0","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.1. With Postman Please follow this document for basic configurations in Dynamics 365 Finance \u0026 Operation, Azure to work with Postman. ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:1:0","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.1.1. Let’s use the first example. Specify Odata endpoint request with POST method into Postman application [finopsURL]/data/AutomationDatas/Microsoft.Dynamics.DataEntities.assignUserToCompany [finopsURL] = https://[yourenvironment].cloudax.dynamics.com Here is the Json file contains the parameters for assignUserToCompany method { \"_networkAlias\":\"Max.Nguyen@Microsoft.com\", \"_company\":\"USMF\" } Click Send and you will get your logic executed. ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:1:1","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.1.2. Let’s try with the second example Everything should be remain the same, you just need to change the method to ReturnRental [finopsURL]/data/AutomationDatas/Microsoft.Dynamics.DataEntities.ReturnRental Click Send and you will get an error { \"Message\": \"No HTTP resource was found that matches the request URI 'https://[devaos].cloudax.dynamics.com/data/AutomationDatas/Microsoft.Dynamics.DataEntities.ReturnRental'. No route data was found for this request.\" } The reason is that you set the second argument to true, that means you need an instance for AutomationDatas entity before you can use ReturnRental method. My entity created based on CustGroup table, so to get an instance I need DataAreaId and CustGroupID. The correct endpoint should be [finopsURL]/data/AutomationDatas(dataAreaId='USMF',CustomerGroupId='BRIDGE')/Microsoft.Dynamics.DataEntities.ReturnRental The result { \"@odata.context\": \"https://[devaos].cloudax.dynamics.com/data/$metadata#Edm.String\", \"value\": \"Rental was successfully returned. Thanks for your business\" } ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:1:2","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.2. With Power Automate ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:2:0","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.2.1. With the first example Create a simple Power Automate with Dynamics 365 Finance \u0026 Operations connector, to consume Odata actions we use “Execute action” action following ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:2:1","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":["Integration"],"content":"2.2.2. With the second example when specify action in Execute action, Dynamics 365 Finance \u0026 Operations connector understand that this needs an instance 3. More In Odata actions, you can return a list [SysODataActionAttribute(\"GetColors\", true), SysODataCollectionAttribute(\"return\", Types::Record, \"CarColor\")] public List GetColorsByAvailability(boolean onlyAvailableVehicles) { List returnList = new List(Types::Record); // do something return returnList; } The following example of an OData action takes in list a parameter. [SysODataActionAttribute(\"GetColorsByAvailability\", false), SysODataCollectionAttribute(\"InventSiteIdList\", Types::String), SysODataCollectionAttribute(\"return\", Types::String)] public static str GetColorsByAvailability(List InventSiteIdList) { str strCommaSeperated; List list = new List(Types::String); ListEnumerator ListEnumerator; ListEnumerator = InventSiteIdList.getEnumerator(); while (ListEnumerator.moveNext()) { strCommaSeperated += strFmt('%1, ', ListEnumerator.current()) ; } return strCommaSeperated; } In those examples,the SysODataCollectionAttribute class enables OData to expose strongly typed collections from X++. This class takes in three parameters: The name of the parameter that is a list (Use return for the return value of the method.). The X++ type of the members of this list. The public name of the OData resource that is contained in the collection. You can find actions that are defined on data entities by searching for the SysODataActionAttribute attribute in metadatasearch. If you want to check how many Odata actions available for an entity, you can go here and search for an entity. https://[devaos].cloudax.dynamics.com/data/$metadata \u003cAction Name=\"removeDeleteCT\" IsBound=\"true\"\u003e \u003cParameter Name=\"AutomationData\" Type=\"Collection(Microsoft.Dynamics.DataEntities.AutomationData)\"/\u003e \u003cParameter Name=\"_entityName\" Type=\"Edm.String\"/\u003e \u003c/Action\u003e \u003cAction Name=\"assginUserToCompany\" IsBound=\"true\"\u003e \u003cParameter Name=\"AutomationData\" Type=\"Collection(Microsoft.Dynamics.DataEntities.AutomationData)\"/\u003e \u003cParameter Name=\"_networkAlias\" Type=\"Edm.String\"/\u003e \u003cParameter Name=\"_company\" Type=\"Edm.String\"/\u003e \u003c/Action\u003e \u003cAction Name=\"ReturnRental\" IsBound=\"true\"\u003e \u003cParameter Name=\"AutomationData\" Type=\"Microsoft.Dynamics.DataEntities.AutomationData\"/\u003e \u003cReturnType Type=\"Edm.String\"/\u003e \u003c/Action\u003e \u003cAction Name=\"addToAllUserGroups\" IsBound=\"true\"\u003e \u003cParameter Name=\"AutomationData\" Type=\"Collection(Microsoft.Dynamics.DataEntities.AutomationData)\"/\u003e \u003cParameter Name=\"_userId\" Type=\"Edm.String\"/\u003e \u003c/Action\u003e At the time I’m writing this post, Odata actions does not support COC extension (A 18, P 42). So if you write some thing like this, it won’t work. [ExtensionOf(dataentityviewstr(CustCustomerGroupEntity))] final class CustCustomerGroupEntity_KA_Extension { [SysODataActionAttribute(\"ReturnRental\", false)] public static str ReturnRental() { return \"Rental was successfully returned. Thanks for your business\"; } } Thank you for reading. ","date":"May 25, 2021","objectID":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/:2:2","tags":["Power Automate","Postman","OData","API Development"],"title":"All about Odata actions in Dynamics 365 Finance And Operations","uri":"/2021-05-25-all-about-odata-actions-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme. ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:0:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Headings The following HTML \u003ch1\u003e—\u003ch6\u003e elements represent six levels of section headings. \u003ch1\u003e is the highest section level while \u003ch6\u003e is the lowest. H1 ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:1:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"H2 ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:2:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"H3 H4 H5 H6 ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:2:1","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat. Itatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat. ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:3:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Blockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations. Blockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote. Blockquote with attribution Don’t communicate by sharing memory, share memory by communicating. — Rob Pike1 ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:4:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Tables Tables aren’t part of the core Markdown spec, but Hugo supports supports them out-of-the-box. Name Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:5:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Code Blocks Code block with backticks \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\" /\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block indented with four spaces \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block with Hugo’s internal highlight shortcode \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Gist ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:6:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:7:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format. H2O Xn + Yn = Zn Press CTRL+ALT+Delete to end the session. Most salamanders are nocturnal, and hunt for insects, worms, and other small creatures. The above quote is excerpted from Rob Pike’s talk during Gopherfest, November 18, 2015. ↩︎ ","date":"September 15, 2020","objectID":"/markdown-syntax-guide/:8:0","tags":null,"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":null,"content":"Dual-write has been around for almost two years now. It’s one of the ways of integrating Dynamics 365 Finance and Operations and Dataverse along with Virtual Entities. The standard solution comes with many out-of-the-box entities available to synchronize. This has been one of the great improvements since Dual-write was made available in preview, when Juanan and I demoed it in the 2019 Dynamics Saturday in Madrid. Develop custom Data Entities for Dual-write 1 This is how Dual write really works But what if we need to develop a new custom Data Entity in MSDyn365FO and use it in Dual-write? It’s easy but there’s some things we need to remember when doing it. ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:0:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Dual-write Dual-write is a bidirectional integration that will synchronously write in Dataverse when data is created, updated or deleted in MSDyn365FO in near-real-time. On the Finance and Operations side it uses data entities to export data to Dataverse. Right now there’s a set of several OOB entities that come ready to be synchronized, and thanks to Initial Sync we can populate data in Dataverse choosing FnO as the source when starting the sync, or also choose Dataverse as the source. If you want to learn more about Dual-write you can: Read the docs which have plenty of information. Read the docs. Always. Guidance for Dual-Write setup System requirements and prerequisites Watch some of Faisal Fareed‘s sessions about Dual-write: DynamicsCon 2020: The Power of Dual-write or Scottish Summit 2021: D365 FO integration with Dataverse – Dual write, Virtual Entities, OR Data Integrator. He’s got some more which you can find on Youtube. ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:1:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Create the Data-entity In Visual Studio we need to create the entity from our table. I’ve created a new table called AASBookTable with just four fields: BookId, Author, Name and ISBN. Its primary key is the BookId field which is also its alternate key and will be used as natural key in the entity. Next, we create the data entity and make sure we’re marking the “Enable data management capabilities” checkbox: Develop custom Data Entities for Dual-write 2 Enable data management capabilities must be checked If the entity doesn’t have data management enabled it won’t be displayed in the list in the Dual-write tables setup. ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:2:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Create a table in Dataverse Now we need to create a table in our Dataverse environment. This table must have at least some of the fields we want to synchronize to Dataverse AND a company field. The company concept doesn’t exist in Dataverse/CRM but thanks to the OOB mappings and Initial Sync we can solve this with just a few clicks and will have a company table in Dataverse with all our FnO legal entities. Develop custom Data Entities for Dual-write 3 Company field related to table company Following my example I’ve created a table with the same four fields and a company field with the data type Lookup and its related table Company, where the FnO legal entities are synchronized. As I said, if we don’t create this field we won-t be able to setup Dual-write for this table. ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:3:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Create table map Our table and data entity are ready, and now we need to create a mapping between them in the Dual-write workspace in FnO. Click the “Add table map” button: Develop custom Data Entities for Dual-write 4 Dynamics 365 Dual-write add table map A new dialog will open and we need to select the FnO entity and the Dataverse table: Develop custom Data Entities for Dual-write 5 Entity map Select the entity and table we’ve created and click save. Then we can define the field mapping: Develop custom Data Entities for Dual-write 6 Dynamics 365 Dual-write field maps Because I’ve created both it’s clear what to map. And after doing this we can click save and it’s done, right? No! WRONG! If we do just this we’ll get an error, this error: Project validation failed. SourceEntitySchema: Books has a primaryCompanyField set to DataAreaId and DestinationEntitySchema: cr008_bookses doesn’t have primary company field set. Dual-write only supports mapping between cross-company entities or company-specific entities from both sides..keys are missing for either AX or CRM.keys are missing for either CRM or AX Or we can also get an error regarding a missing integration key for the company field. In the end both are caused because we’ve missed defining the integration key for this new Dataverse table: ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:4:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Integration key Go back to the main Dual-write form and click on the “Integration key” button: Develop custom Data Entities for Dual-write 7 Dual-write integration key The integration key will be the same as the FnO data entity key, plus the company if your data entity has a company context. Remember that when we create indexes in FnO the DataAreaId field isn’t included in the field, but it is in the SQL Server index along the partition field. The integration key for our custom Dual-write mapping will look like this: Develop custom Data Entities for Dual-write 8 Dual/write integration key Remember we’ve added the company field to our Dataverse table? You can see in the image above that the field includes the relation to the Company table in Dataverse. We won’t be able to save the field mapping if we create the key using our Dataverse table’s company field instead of its Company table relation, like this: Develop custom Data Entities for Dual-write 9 Dual/write integration key See the difference? In the first image the field reads c008_company.cdm_companycode while in the second one it’s c008_company. If we set the integration key using the field in our table instead of the related table and save the fields’ mapping we’ll get an error saying the company is missing in the key because it’s expecting the relation! ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:5:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Action! The table and field mappings are ready, just click run and go create a new book in the FnO form: Develop custom Data Entities for Dual-write 10 Finance and Operations form Then we go to our Dataverse table and check its data… Develop custom Data Entities for Dual-write 11 Dataverse table data It’s there! And of course it’s working in both directions. If I create a record in Dataverse it’ll be created in FnO too. I’ll use the Excel add-in to add a new book: Develop custom Data Entities for Dual-write 12 Dataverse Excel add-in And after refreshing the form in FnO we can see it there too: Develop custom Data Entities for Dual-write 13 This is a really simple example of how we can create a custom table, use it in a data entity and then use this entity in our dual-write setup. It’s something that can be easily done but we need to remember the “company thing”, otherwise this will never work! Dual-write is even easier to configure nowadays thanks to LCS allowing us to create and link a new Dataverse environment when we deploy a new Finance and Operations environment. ","date":"May 2, 2021","objectID":"/2021-05-02-develop-custom-data-entities-for-dual-write/:6:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Dual-write","ALM","Data Entities"],"title":"Develop custom Data Entities for Dual-write","uri":"/2021-05-02-develop-custom-data-entities-for-dual-write/"},{"categories":null,"content":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure DevOps Azure DevOps will be the service we will use for source control. Microsoft Dynamics 365 for Finance and Operations supports TFVC out of the box as its version-control system. But Azure DevOps does not only offer a source control tool. Of course, developers will be the most benefited of using it, but from project management to the functional team and customers, everybody can be involved in using Azure DevOps. BPM synchronization and task creation, team planning, source control, automated builds and releases, are some of the tools it offers. All these changes will need some learning from the team, but in the short-term all of this will help to better manage implementations. As I said it looks like the technical team is the most affected by the addition of source control to Visual Studio, but it’s the most benefited too… ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"First steps To use all the features described in this guide we need to create an Azure DevOps project and connect it to LCS. This will be the first step and it’s mandatory so let’s see how we have to do everything. Create an Azure DevOps organization You might or might not have to do this. If you or your customer already have an account, you can use it and just create a new project in it. Otherwise head to https://dev.azure.com and create a new organization: MSDyn365 \u0026 Azure DevOps ALM 2 Azure DevOps sign up After creating it you need to create a new project with the following options: MSDyn365 \u0026 Azure DevOps ALM 3 Create Azure DevOps project Press the “Create project” button and you’re done. Now let’s connect this Azure DevOps project to our LCS project. When a customer signs up for Finance and Operations the LCS project is of type “Implementation project” is created automatically. Your customers need to invite you to their project. If you’re an ISV you can use the “Migrate, create solutions, and learn” projects. In any of both cases you need to go to “Project settings” and select the “Visual Studio Team Services” Tab. Scroll down and you should see two fields. Fill the field with your DevOps URL without the project part. If you got a https://dev.azure.com/YOUR_ORG URL type you need to change it to https://YOUR_ORG.visualstudio.com: MSDyn365 \u0026 Azure DevOps ALM 4 Azure DevOps setup on LCS And to get the “Personal access token” we go back to our Azure DevOps project, click on the user settings icon, and then select “Personal access tokens”: MSDyn365 \u0026 Azure DevOps ALM 5 We add a new token, set its expiration and give it full access. Finally press the “Create” button and a new dialog will appear with your token, copy it, and paste it in LCS. MSDyn365 \u0026 Azure DevOps ALM 6 MSDyn365 \u0026 Azure DevOps ALM 7 Back to LCS, once you’ve pasted the token press the “Continue” button. On the next step just select your project, press “Continue” and finally “Save” on the last step. If you have any problem you can take a look at the docs where everything is really well documented. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"The build server Once we’ve linked LCS and Azure DevOps we’ll have to deploy the build server. This will be the heart of our CI/CD processes. Even though the build virtual machine has the same topology as a developer box, it really isn’t a developer VM and should never be used as one, do not use it as a developer VM! It has Visual Studio installed in it, the AosService folder with all the standard packages and SQL Server with an AxDB, just like all other developer machines, but that’s not its purpose. We won’t be using any of those features. The “heart” of the build machine is the build agent, an application which Azure DevOps uses to execute the build definition’s tasks from Azure DevOps. We can also use Azure hosted build agents. Azure hosted agents allow us to run a build without a VM, the pipeline runs on Azure. We’ll see this later. The build VM This VM is usually the dev box on Microsoft’s subscription but you can also use a regular cloud-hosted environment as a build VM. When this VM is deployed there’s two things happening: the basic source code structure and the default build definition are created. MSDyn365 \u0026 Azure DevOps ALM 8 MSDyn365 \u0026 Azure DevOps ALM 9 ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Visual Studio We have the basics to start working. Log into your dev VM and start Visual Studio, we must map the Main folder to the development machine’s packages folder. Open the team explorer and select “Connect to a Project…”: MSDyn365 \u0026 Azure DevOps ALM 10 It will ask for your credentials and then show all projects available with the account you’ve used. Select the project we have created in the steps earlier and click on “Connect”: MSDyn365 \u0026 Azure DevOps ALM 11 Now open the “Source Control Explorer”, select the Main folder and click on the “Not mapped” text: MSDyn365 \u0026 Azure DevOps ALM 12 Map the Main folder to the K:\\AosService\\PackagesLocalDirectory folder on your service drive (this could be drive C if you’re using a local VM instead of a cloud-hosted environment): MSDyn365 \u0026 Azure DevOps ALM 13 What we’ve done in this step is telling Visual Studio that what’s in our Azure DevOps project, inside the Main folder, will go into the K:\\AosService\\PackagesLocalDirectory folder of our development VM. The Main folder we have in our source control tree is a regular folder, but we can convert it into a branch if we need it. MSDyn365 \u0026 Azure DevOps ALM 14 MSDyn365 \u0026 Azure DevOps ALM 15 In the image above, you can see the icon for Main changes when it’s converted to a branch. Branches allow us to perform some actions that aren’t available to folders. Some differences can be seen in the context menu: MSDyn365 \u0026 Azure DevOps ALM 16 Folder context menu MSDyn365 \u0026 Azure DevOps ALM 17 Branch context menu For instance, branches can display the hierarchy of all the project branches (in this case it’s only Main and Dev so it’s quite simple). MSDyn365 \u0026 Azure DevOps ALM 18 Properties dialogs are different too. The folder one: MSDyn365 \u0026 Azure DevOps ALM 19 And the branch one, where we can see the different relationships between the other branches created from Main: MSDyn365 \u0026 Azure DevOps ALM 20 This might be not that interesting or useful, but one of the things converting a folder into a branch is seeing where has a changeset been merge into. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Some advice I strongly recommend moving the Projects folder out of the Main branch (or whatever you call it) into the root of the project, at the same level as BuildProcessTemplates and Trunk. In fact, and this is my personal preference, I would keep anything that’s not code outside of a branch. By doing this you only need to take care of the code when merging and branching. Those who have been working with AX for several years were used to not use version-control systems. MSDyn365FO has taken us to uncharted territory, so it is not uncommon for different teams to work in different ways, depending on their experience and what they’ve found in the path. Each team will need to invest some time to discover what’s better for them regarding code, branching and methodologies. Many times, this will be based on experimentation and trial and error, and with the pace of implementation projects trial and error turns out bad. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:5","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Branching strategies I want to make it clear in advance: I’m not an expert in managing code nor Azure DevOps, at all. All that I’ve written here is product of my experience (good and bad) of over 4 years working with Finance and Operations. In this article on branching strategies from the docs there’s more information regarding branching and links to articles of the DevOps team. And there’s even more info in the DevOps Rangers’ Library of tooling and guidance solutions! Main-Release One possible strategy is using a Main and a Release branch. We have already learnt that the Main branch is created when the Build VM is deployed. The usual is that in an implementation project all development will be done on that branch until the Go Live, and just before that a new Release branch will be created. We will keep development work on the Main branch, and when that passes validation, we’ll move it to Release. This branching strategy is really simple and will keep us mostly worry-free. Dev – Main – Release This strategy is similar to the Main – Release one but includes a Dev branch for each developer. This dev branch must be maintained by the developer using it. He can do as many check-ins as he wants during a development, and when it’s done merge all these changes to the Main branch in a single changeset. Of course, this adds some bureaucracy because we also need to forward integrate changes from Main into our Dev branch, but it will allow us to have a cleaner list of changesets when merging them from Main to the Release branch. Whatever branching strategy you choose try to avoid having pending changesets to be merged for a long time. The amount of merge conflicts that will appear is directly proportional to the time the changeset has been waiting to be merged. I wrote all of this based on my experience. It’s obviously not the same working for an ISV than for an implementation partner. An ISV has different needs, it must maintain different code versions to support all their customers and they don’t necessarily need to work in a Main – Release manner. They could have one (or more) branch for each version. However, since the end of overlayering this is not necessary. More ideas about this can be found in the article linked at the beginning. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:1:6","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure Pipelines ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:2:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Builds We’ve already seen that the default build definition has all the default steps active. We can disable (or remove) all the steps we’re not going to use. For example, the testing steps can be removed if we have no unit testing. We can also create new build definitions from scratch, however it’s easier to clone the default one and modify it to other branches or needs. Since version 8.1 all the X++ hotfixes are gone, the updates are applied in a single deployable package as binaries. This implies that the source-controlled Metadata folder will only contain our custom packages and models, no standard packages anymore. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:2:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Continuous Integration Continuous Integration (CI) is the process of automating the build and testing of code every time a team member commits changes to version control. (source) Should your project/team use CI? Yes, yes, yes. This is one of the key feature of using an automated build process. This is how a build definition for CI that will only compile our codebase looks like: MSDyn365 \u0026 Azure DevOps ALM 21 Only the prepare and build steps. Then we need to go to the “Triggers” tab and enable the CI option: MSDyn365 \u0026 Azure DevOps ALM 22 Right after each developer check-in, a build will be queued, and the code compiled. In case there’s a compilation error we’ll be notified about it. Of course, we all build the solutions before checking them in and don’t need this CI build. Right? ![tysonjaja](./MSDyn365 \u0026 Azure DevOps ALM - ariste.info_files/tysonjaja.gif “MSDyn365 \u0026 Azure DevOps ALM 23”) MSDyn365 \u0026 Azure DevOps ALM 23 And because we all know that “Slow and steady wins the race”, but at some point during a project that’s not possible, so this kind of build definition can help us out. Especially when merging code between branches. This will allow us to be 100% sure when creating a DP to release to production that it’ll work. I can tell you that having to do a release to prod in a hurry and seeing the Main build failing is not nice. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:2:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Gated check-ins A gated check-in is a bit different than a CI build. The gated check-in will trigger an automated build BEFORE checking-in the code. If it fails, the changeset is not cheked-in until the errors are fixed and checked-in again. This option might seem perfect for the merge check-ins to the Main branch. I’ve found some issues trying to use it, for example: If multiple merges \u0026 check-ins from the same development are done and the first fails but the second doesn’t, you’ll still have pending merges to be done. You can try batching the builds, but I haven’t tried that. Issues with error notifications and pending code on dev VMs. If many check-ins are made, you’ll end up with lots of queued builds (and we only have one available agent per DevOps project). This can also be solved using the “Batch changes while a build is in progress”. I think the CI option is working perfectly to validate code. As I’ve already said several times, choose the strategy that better suits your team and your needs. Experiment with CI and Gated check-in builds and decide what is better for you. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:2:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Set up the new Azure DevOps tasks for Packaging and Model Versioning Almost all the tasks of the default build definition use PowerShell scripts that run on the Build VM. We can change 3 of those steps for newer tasks. In order to use these newer tasks, we need to install the “Dynamics 365 Unified Operations Tools”. We’ll be using them to set up our release pipeline too so consider doing it now. Update Model Version task This one is the easiest, just add it to your build definition under the current model versioning task, disable the original one and you’re done. If you have any filters in your current task, like excluding any model, you must add the filter in the Descriptor Search Pattern field using Azure DevOps pattern syntax. Create Deployable Package task This task will replace the Generate packages from the current build definitions. To set it up we just need to do a pair of changes to the default values: X++ Tools Path MSDyn365 \u0026 Azure DevOps ALM 24 This is your build VM’s physical bin folder, the AosService folder is usually on the unit K for cloud-hosted VMs. I guess this will change when we go VM-less to do the builds. Update!: the route to the unit can be changed for $(ServiceDrive), getting a path like $(ServiceDrive)\\AOSService\\PackagesLocalDirectory\\bin. Location of the X++ binaries to package MSDyn365 \u0026 Azure DevOps ALM 25 The task comes with this field filled in as $(Build.BinariesDirectory) but this didn’t work out for our build definitions, maybe the variable isn’t set up on the proj file. After changing this to $(Agent.BuildDirectory)\\Bin the package is generated. Filename and path for the deployable package MSDyn365 \u0026 Azure DevOps ALM 26 The path on the image should be changed to $(Build.ArtifactStagingDirectory)\\Packages\\AXDeployableRuntime_$(Build.BuildNumber).zip. You can leave it without the Packages folder in the path, but if you do that you will need to change the Path to Publish field in the Publish Artifact: Package step of the definition. Add Licenses to Deployable Package task This task will add the license files to an existing Deployable Package. Remember that the path of the deployable package must be the same as the one in the Create Deployable Package task. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:2:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure hosted build for Dynamics 365 Finance \u0026 SCM The day we’ve been waiting for has come! The Azure hosted builds are in public preview since PU35!! We can now stop asking Joris when will this be available, because it already is! Check the docs! I’ve been able to write this because, thanks to Antonio Gilabert, we’ve been testing this at Axazure for a few months with access to the private preview. And of course thanks to Joris for inviting us to the preview! MSDyn365 \u0026 Azure DevOps ALM 27 Riding the Azure Pipelines by Caza Pelusas What does this mean? We no longer need a VM to run the build pipelines! Nah, we still need! If you’re running tests or synchronizing the DB as a part of your build pipeline you still need the VM. But we can move CI builds to the Azure hosted agent! You can also read my full guide on MSDyn365FO \u0026 Azure DevOps ALM. Remember this is a public preview. If you want to join the preview you first need to be part of the Dynamics 365 Insider Program where you can join the “Dynamics 365 for Finance and Operations Insider Community“. Once invited you should see a new LCS project called PEAP Assets, and inside its Asset Library you’ll find the nugets in the Nuget package section. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure agents With the capacity to run an extra Azure-hosted build we get another agent to run a pipeline and can run multiple pipelines at the same time. But it still won’t be parallel pipelines, because we only get one VM-less agent. This means we can run a self-hosted and azure hosted pipeline at the same time, but we cannot run two of the same type in parallel. If we want that we need to purchase extra agents. With a private Azure DevOps project we get 2GB of Artifacts space (we’ll see that later) and one self-hosted and one Microsoft hosted agent with 1800 free minutes: MSDyn365 \u0026 Azure DevOps ALM 28 Azure hosted build: Azure DevOps project pricing We’ll still keep the build VM, so it’s difficult to tell a customer we need to pay extra money without getting rid of its cost. Plus we’ve been doing everything with one agent until now and it’s been fine, right? So take this like extra capacity, we can divide the build between both agents and leave the MS hosted one for short builds to squeeze the 1800 free minutes as much as possible. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"How does it work? There’s really no magic in this. We move from a self-hosted agent in the build VM to a Microsoft-hosted agent. The Azure hosted build relies on nuget packages to compile our X++ code. The contents of the PackagesLocalDirectory folder, platform and the compiler tools have basically been put into nugets and what we have in the build VM is now on 3 nugets. When the build runs it downloads \u0026 installs the nugets and uses them to compile our code on the Azure hosted build along the standard packages. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"What do I need? To configure the Azure hosted build we need: The 3 nuget packages from LCS: Compiler tools, Platform X++ and Application X++. nuget.exe A user with rights at the organization level to upload the nugets to Azure DevOps. Some patience to get everything running 🙂 So the first step is going to the PEAP LCS’ Asset Library and downloading the 3 nuget packages: MSDyn365 \u0026 Azure DevOps ALM 29 Nugets for the Azure Hosted Build ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure DevOps artifact All of this can be done on your PC or in a dev VM, but you’ll need to add some files and a VS project to your source control so you need to use the developer box for sure. Head to your Azure DevOps project and go to the Artifacts section. Here we’ll create a new feed and give it a name: MSDyn365 \u0026 Azure DevOps ALM 30 MSDyn365 \u0026 Azure DevOps ALM 31 You get 2GB for artifacts, the 3 nuget packages’ size is around 500MB, you should have no issues with space unless you have other artifacts in your project. Now press the “Connect to feed” button and select nuget.exe. You’ll find the instructions to continue there but I’ll explain it anyway. Then you need to download nuget.exe and put it in the Windows PATH. You can also get the nugets and nuget.exe in the same folder and forget about the PATH. Up to you. Finally, install the credential provider: download this Powershell script and run it. If the script keeps asking for your credentials and fails try adding -AddNetfx as a parameter. Thanks to Erik Norell for finding this and sharing in the comments of the original post! Create a new file called nuget.config in the same folder where you’ve downloaded the nugets. It will have the content you can see in the “Connect to feed” page, something like this: \u003c?xml version\\=\"1.0\" encoding\\=\"utf-8\"?\u003e \u003cconfiguration\\\u003e \u003cpackageSources\\\u003e \u003cclear /\\\u003e \u003cadd key\\=\"AASBuild\" value\\=\"https://pkgs.dev.azure.com/aariste/aariste365FO/\\_packaging/AASBuild/nuget/v3/index.json\" /\\\u003e \u003c/packageSources\\\u003e \u003c/configuration\\\u003e This file’s content has to be exactly the same as what’s displayed in your “Connect to feed” page. And finally, we’ll push (upload) the nugets to our artifacts feed. We have to do this for each one of the 3 nugets we’ve downloaded: nuget.exe push -Source \"AASBuild\" -ApiKey az \u003cpackagePath\u003e You’ll get prompted for the user. Remember it needs to have enough rights on the project. Of course, you need to change “AASBuild” for your artifact feed name. And we’re done with the artifacts. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Prepare Azure DevOps This new agent needs a solution to build our packages. This means we have to create an empty solution in Visual Studio and set the package of the project to our main package. Like this: MSDyn365 \u0026 Azure DevOps ALM 32 Visual Studio solution If you have more than one package or models, you need to add a project to this solution for each separate model you have. We have to create another file called packages.config with the following content: \u003c?xml version\\=\"1.0\" encoding\\=\"utf-8\"?\u003e \u003cpackages\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Platform.DevALM.BuildXpp\" version\\=\"7.0.5644.16778\" targetFramework\\=\"net40\" /\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Application.DevALM.BuildXpp\" version\\=\"10.0.464.13\" targetFramework\\=\"net40\" /\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Platform.CompilerPackage\" version\\=\"7.0.5644.16778\" targetFramework\\=\"net40\" /\u003e \u003c/packages\u003e The version tag will depend on when you’re reading this, but the one above is the correct one for PU35. We’ll need to update this file each time a new version of the nugets is published. And, to end with this part, we need to add the solution, the nuget.config and the packages.config files to TFVC. This is what I’ve done: MSDyn365 \u0026 Azure DevOps ALM 33 Azure DevOps You can see I’ve created a Build folder in the root of my DevOps project. That’s only my preference, but I like to only have code in my branches, even the projects are outside of the branches, I only want the code to move between merges and branches. Place the files and solution inside the Build folder (or wherever you decide). ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:5","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Configure pipeline Now we need to create a new pipeline, you can just import this template from the newly created X++ (Dynamics 365) Samples and Tools Github project. After importing the template we’ll modify it a bit. Initially, it will look like this: MSDyn365 \u0026 Azure DevOps ALM 34 Azure hosted build: Default imported pipeline As you can see the pipeline has all the steps needed to generate the DP, but some of them, the ones contained in the Dynamics 365 tasks, won’t load correctly after the import. You just need to add those steps to your pipeline manually and complete its setup. Pipeline root MSDyn365 \u0026 Azure DevOps ALM 35 You need to select the Hosted Azure Pipelines for the Agent pool, and vs2017-win2016 as Agent Specification. Get sources MSDyn365 \u0026 Azure DevOps ALM 36 Azure hosted build: Our mappings I’ve mapped 2 things here: our codebase in the first mapping and the Build folder where I’ve added the solution and config files. If you’ve placed these files inside your Metadata folder you don’t need the extra mapping. NuGet install Packages This step gets the nugets from our artifacts feeds and the installs to be used in each pipeline execution. MSDyn365 \u0026 Azure DevOps ALM 37 Azure hosted build: nuget install The command uses the config files we have uploaded to the Build folder, and as you can see it’s fetching the files from the $(build.sourcesDirectory)\\Build directory we’ve configured in the Get sources step. If you’ve placed those files in a diferent place you need to change the paths as needed. Update Model Version This is one of the steps that are displaying issues even though I got the Dynamics 365 tools installed from the Azure DevOps marketplace. If you got it right you probably don’t need to change anything. If you have the same issue as me, just add a new step and select the “Update Model Version” task and change the fields so it looks like this: MSDyn365 \u0026 Azure DevOps ALM 38 Azure hosted build: Update Model Version Build solution MSDyn365 \u0026 Azure DevOps ALM 39 Build solution step In the build solution step, you have a wildcard in the solution field: **\\\\*.sln. If you leave this wildcard it will build all the projects you have in the repo and, depending on the number of projects you have, the build could time out. I solve this by selecting a solution, that contains all the models I have, that I have placed in the Build folder in my repo, and update that solution if you add or remove any model. Thanks to Ievgen Miroshnikov for pointing this out! There could be an additional issue with the rnrproj files as Josh Williams points out in a comment. If your project was created pre-PU27 try creating a new solution to avoid problems. Create Deployable Package This is another one of the steps that are not loading correctly for me. Again, add it and change as needed: MSDyn365 \u0026 Azure DevOps ALM 40 Azure hosted build: Create Deployable Package Add Licenses to Deployable Package Another step with issues. Do the same as with the others: MSDyn365 \u0026 Azure DevOps ALM 41 Azure hosted build: Add Licenses to Deployable Package And that’s all. You can queue the build to test if it’s working. For the first runs you can disable the steps after the “Build solution” one to see if the nugets are downloaded correctly and your code built. After that try generating the DP and publishing the artifact. You’ve configured your Azure hosted build, now it’s your turn to decide in which cases will you use the self-hosted or the azure hosted build. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:6","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Update for version 10.0.18 Since version 10.0.18 we’ll be getting 4 NuGet packages instead of 3 because of the Microsoft.Dynamics.AX.Application.DevALM.BuildXpp NuGet size is getting near or over the max size which is 500MB and will come as 2 NuGet packages from now on. You can read about this in the docs. There just 2 small changes we need to do to the pipeline if we’re already using it, one to the packages.config file and another one to the pipeline. packages.config The packages.config file will have an additional line for the Application Suite NuGet. \u003c?xml version\\=\"1.0\" encoding\\=\"utf-8\"?\u003e \u003cpackages\\\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Platform.DevALM.BuildXpp\" version\\=\"7.0.5968.16973\" targetFramework\\=\"net40\" /\\\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Application.DevALM.BuildXpp\" version\\=\"10.0.793.16\" targetFramework\\=\"net40\" /\\\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.ApplicationSuite.DevALM.BuildXpp\" version\\=\"10.0.793.16\" targetFramework\\=\"net40\" /\\\u003e \u003cpackage id\\=\"Microsoft.Dynamics.AX.Platform.CompilerPackage\" version\\=\"7.0.5968.16973\" targetFramework\\=\"net40\" /\\\u003e \u003c/packages\\\u003e Pipeline We need to add a new variable to the pipeline variables called AppSuitePackage with the value Microsoft.Dynamics.AX.ApplicationSuite.DevALM.BuildXpp. MSDyn365 \u0026 Azure DevOps ALM 42 New Azure DevOps pipeline variable And then use it in the build step and change it to: /p:BuildTasksDirectory\\=\"$(NugetsPath)\\\\$(ToolsPackage)\\\\DevAlm\" /p:MetadataDirectory\\=\"$(MetadataPath)\" /p:FrameworkDirectory\\=\"$(NuGetsPath)\\\\$(ToolsPackage)\" /p:ReferenceFolder\\=\"$(NuGetsPath)\\\\$(PlatPackage)\\\\ref\\\\net40;$(NuGetsPath)\\\\$(AppPackage)\\\\ref\\\\net40;$(MetadataPath);$(Build.BinariesDirectory);$(NuGetsPath)\\\\$(AppSuitePackage)\\\\ref\\\\net40\" /p:ReferencePath\\=\"$(NuGetsPath)\\\\$(ToolsPackage)\" /p:OutputDirectory\\=\"$(Build.BinariesDirectory)\" ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:3:7","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure DevTest Labs powered builds The end of Tier-1 Microsoft-managed build VMs is near, and this will leave us without the capacity to synchronize the DB or run tests in a pipeline, unless we deploy a new build VM in our, or our customer’s, Azure subscription. Of course, there might be a cost concern with it, and there’s where Azure DevTest Labs can help us! This post has been written thanks to Joris de Gruyter‘s session in the past DynamicsCon: Azure Devops Automation for Finance and Operations Like You’ve Never Seen! And there’s also been some investigation and (a lot of) trial-and-error from my side until everything has been working. MSDyn365 \u0026 Azure DevOps ALM 43 Configuring the build VM in Azure DevTest Labs If you want to know more about builds, releases, and the Dev ALM of Dynamics 365 you can read my full guide on MSDyn365 \u0026 Azure DevOps ALM. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"But first… What I’m showing in this post is not a perfect blueprint. There’s a high probability that if you try exactly the same as I do here, you won’t get the same result. But it’s a good guide to get started and do some investigation on your own and learn. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure DevTest Labs Azure DevTest Labs is an Azure tool/service that allows us to deploy virtual machines and integrate them with Azure DevOps pipelines, and many other things, but what I’m going to explain is just the VM and pipeline part. What will I show in this post? How to prepare a Dynamics 365 Finance and Operations VHD image to be used as the base to create a build virtual machine from an Azure DevOps pipeline, build our codebase, synchronize the DB, run tests, even deploy the reports, generate the deployable package and delete the VM. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Getting and preparing the VHD This is by far the most tedious part of all the process because you need to download 11 ZIP files from LCS’ Shared Asset Library, and we all know how fast things download from LCS. MSDyn365 \u0026 Azure DevOps ALM 44 How is LCS download speed? And to speed it up we can create a blob storage account on Azure and once more turn to Mötz Jensen‘s d365fo.tools and use the Invoke-D365AzCopyTransfer cmdlet. Just go to LCS, click on the “Generate SAS link” button for each file, use it as the source parameter in the command and your blob SAS URL as the destination one. Once you have all the files in your blob you can download them to your local PC at a good speed. Once you’ve unzipped the VHD you need to change it from Dynamic to Fixed using this PowerShell command: Convert-VHD –Path VHDLOCATION.vhd –DestinationPath NEWVHD.vhd –VHDType Fixed The reason is you can’t create an Azure VM from a dynamically-sized VHD. And it took me several attempts to notice this 🙂 ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Create a DevTest Labs account To do this part you need an Azure account. If you don’t have one you can sign up for a free Azure account with a credit of 180 Euros (200 US Dollars) to be spent during 30 days, plus many other free services during 12 months. Search for DevTest Labs in the top bar and create a new DevTest Lab. Once it’s created open the details and you should see something like this: MSDyn365 \u0026 Azure DevOps ALM 45 Azure DevTest Labs Click on the “Configuration and policies” menu item at the bottom of the list and scroll down in the menu until you see the “Virtual machine bases” section: MSDyn365 \u0026 Azure DevOps ALM 46 DevTest Labs custom image And now comes the second funniest part of the process: we need to upload the 130GB VHD image to a blob storage account! So, click the “Add” button on top and in the new dialog that will open click the “Upload a VHD using PowerShell”. This will generate a PowerShell script to upload the VHD to the DevTest Labs blob. For example: \u003c# Generated script to upload a local VHD to Azure. WARNING: The destination will be publicly available for 24 hours, after which it will expire. Ensure you complete your upload by then. Run the following command in a Azure PowerShell console after entering the LocalFilePath to your VHD. #\u003e Add-AzureRmVhd -Destination \"https://YOURBLOB.blob.core.windows.net/uploads/tempImage.vhd?sv=2019-07-07\u0026st=2020-12-27T09%3A08%3A26Z\u0026se=2020-12-28T09%3A23%3A26Z\u0026sr=b\u0026sp=rcw\u0026sig=YTeXpxpVEJdSM7KZle71w8NVw9oznNizSnYj8Q3hngI%3D\" -LocalFilePath \"\u003cEnter VHD location here\u003e\" Generated script to upload a local VHD to Azure. WARNING: The destination will be publicly available for 24 hours, after which it will expire. Ensure you complete your upload by then. Run the following command in a Azure PowerShell console after entering the LocalFilePath to your VHD. Add-AzureRmVhd \\-Destination \"https://YOURBLOB.blob.core.windows.net/uploads/tempImage.vhd?sv=2019-07-07\u0026st=2020-12-27T09%3A08%3A26Z\u0026se=2020-12-28T09%3A23%3A26Z\u0026sr=b\u0026sp=rcw\u0026sig=YTeXpxpVEJdSM7KZle71w8NVw9oznNizSnYj8Q3hngI%3D\" \\-LocalFilePath \"\u003cEnter VHD location here\u003e\" MSDyn365 \u0026 Azure DevOps ALM 47 DevTest Labs custom image upload An alternative to this is using the Azure Storage Explorer as you can see in the image on the left. You should upload the VHD to the uploads blob. Any of these methods is good to upload the VHD and I don’t really know which one is faster. Once the VHD is uploaded open the “Custom images” option again and you should see the VHD in the drop-down: MSDyn365 \u0026 Azure DevOps ALM 48 DevTest Labs custom image Give the image a name and click OK. What we have now is the base for a Dynamics 365 Finance and Operations dev VM which we need to prepare to use it as a build VM. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Creating the VM We’ve got the essential, a VHD ready to be used as a base to create a virtual machine in Azure. Our next step is finding a way to make the deployment of this VM predictable and automated. We will attain this thanks to Azure ARM templates. Go back to your DevTest Labs overview page and click the “Add” button, on the “Choose base” page select the base you’ve just created, and on the next screen click on the “Add or Remove Artifacts” link: MSDyn365 \u0026 Azure DevOps ALM 49 Add artifacts to the VM Search for WinRM, select “Configure WinRM”, and on the next screen enter “Shared IP address” as the hostname box and click “Add”. Note: if when the VM runs the artifacts can’t be installed check whether the Azure VM Agent is installed on the base VHD. Thanks to Joris for pointing this out! Configure Azure DevOps Agent Service Option A: use an artifact Update: thanks to Florian Hopfner for reminding me this because I forgot… If you choose Option A to install the agent service you need to do some things first! The first thing we need to do is running some PowerShell scripts that create registry entries and environment variables in the VM, go to C:\\DynamicsSDK and run these: Import-Module $(Join-Path \\-Path \"C:\\\\DynamicsSDK\" \\-ChildPath \"DynamicsSDKCommon.psm1\") \\-Function \"Write-Message\", \"Set-AX7SdkRegistryValues\", \"Set-AX7SdkEnvironmentVariables\" Set\\-AX7SdkEnvironmentVariables \\-DynamicsSDK \"C:\\\\DynamicsSDK\" Set\\-AX7SdkRegistryValues \\-DynamicsSDK \"c:\\\\DynamicsSDK\" \\-TeamFoundationServerUrl \"https://dev.azure.com/YOUR\\_ORG\" \\-AosWebsiteName $AosWebsiteName \"AosService\" The first one will load the functions and make them available in the command-line and the other two create the registry entries and environment variables. Now we need to add an artifact for the Azure DevOps agent service. This will configure the agent service on the VM each time the VM is deployed. Search for “Azure Pipelines Agent” and click it. You will see this: MSDyn365 \u0026 Azure DevOps ALM 50 DevTest Labs Azure DevOps Agent We need to fill some information: On “Azure DevOps Organization Name” you need to provide the name of your organization. For example if your AZDO URL is https://dev.azure.com/blackbeltcorp you need to use blackbeltcorp. On “AZDO Personal Access Token” you need to provide a token generated from AZDO. On “Agent Name” give your agent a name, like DevTestAgent. And on “Agent Pool” a name for your pool, a new like DevTestPool or an existing one as Default. On “Account Name” use the same user that we’ll use in our pipeline later. Remember this. And on “Account Password” its password. Using secrets with a KeyVault is better, but I won’t explain this here. And, finally, set “Replace Agent” to true. Option B: Configure Azure DevOps Agent in the VM To do this you have to create a VM from the base image you created before and then go to C:\\DynamicsSDK and run the SetupBuildAgent script with the needed parameters: SetupBuildAgent.ps1 \\-VSO\\_ProjectCollection \"https://dev.azure.com/YOUR\\_ORG\" \\-ServiceAccountName \"myUser\" \\-ServiceAccountPassword \"mYPassword\" \\-AgentName \"DevTestAgent\" \\-AgentPoolName \"DevTestPool\" \\-VSOAccessToken \"YOUR\\_VSTS\\_TOKEN\" WARNING: If you choose option B you must create a new base image from the VM where you’ve run the script. Then repeat the WinRM steps to generate the new ARM template which we’ll see next. ARM template Then go to the “Advanced Settings” tab and click the “View ARM template” button: MSDyn365 \u0026 Azure DevOps ALM 51 Get the ARM template This will display the ARM template to create the VM from our pipeline. It’s something like this: { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"newVMName\": { \"type\": \"string\", \"defaultValue\": \"aariste001\" }, \"labName\": { \"type\": \"string\", \"defaultValue\": \"aristeinfo\" }, \"size\": { \"type\": \"string\", \"defaultValue\": \"Standard\\_B4ms\" }, \"userName\": { \"type\": \"string\", \"defaultValue\": \"","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:5","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Preparing the VM The VHD image you download can be used as a developer VM with no additional work, just run Visual Studio, connect it to your AZDO project and done. But if you want to use it as a build box you need to do several things first. Remember that the default user and password for these VHDs are Administrator and Pass@word1. Disable services First of all we will stop and disable services like the Batch, Management Reporter, SSAS, SSIS, etc. Anything you see that’s not needed to run a build. Create a new SQL user Open SSMS (as an Administrator) and create a new SQL user as a copy of the axdbadmin one. Then open the web.config file and update the DB user and password to use the one you’ve just created. Prepare SSRS (optional) If you want to deploy reports as part of your build pipeline you need to go to SSMS again (and as an Admin again), and open a new query in the reporting DB to execute the following query: execDeleteEncryptedContentPowerShell Scripts The default build definition that runs on a build VM uses several PowerShell scripts to run some tasks. I’m adding an additional script called PrepareForAgent. The scripts can be found in the C:\\DynamicsSDK folder of the VM. PrepareForBuild This script comes with the VM and we need to modify it to avoid one thing: the PackagesLocalDirectory backup which is usually done in the first build. We need to get rid of this or we’ll waste around an hour per run until the files are copied. We don’t need this because our VM will be new each time we run the pipeline! So open the script, go to line 696 and look for this piece of code: # Create packages backup (if it does not exist). $NewBackupCreated \\= Backup-AX7Packages \\-BackupPath $PackagesBackupPath \\-DeploymentPackagesPath $DeploymentPackagesPath \\-LogLocation $LogLocation # Restore packages backup (unless a new backup was just created). if (!$NewBackupCreated) { Restore-AX7Packages \\-BackupPath $PackagesBackupPath \\-DeploymentPackagesPath $DeploymentPackagesPath \\-LogLocation $LogLocation \\-RestoreAllFiles:$RestorePackagesAllFiles } if (!$DatabaseBackupToRestore) { $DatabaseBackupPath \\= Get-BackupPath \\-Purpose \"Databases\" Backup-AX7Database \\-BackupPath $DatabaseBackupPath } else { # Restore a database backup (if specified). Restore-AX7Database \\-DatabaseBackupToRestore $DatabaseBackupToRestore } We need to modify it until we end up with this: if ($DatabaseBackupToRestore) { Restore-AX7Database \\-DatabaseBackupToRestore $DatabaseBackupToRestore } We just need the DB restore part and skip the backup, otherwise we’ll be losing 45 minutes in each run for something we don’t need because the VM will be deleted when the build is completed. Optional (but recommended): install d365fo.tools Just run this: Install-Module -Name d365fo.tools We can use the tools to do a module sync, partial sync or deploy just our reports instead of all. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:6","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Create a new image Once we’ve done all these prepare steps we can log out of this VM and stop it. Do not delete it yet! Go to “Create custom image”, give the new image a name, select “I have not generalized this virtual machine” and click the “OK” button. This will generate a new image that you can use as a base image with all the changes you’ve done to the original VHD. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:7","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Azure DevOps Pipelines We’re ready to setup our new build pipeline in Azure DevOps. This pipeline will consist of three steps: create a new VM, run all the build steps, and delete the VM: MSDyn365 \u0026 Azure DevOps ALM 53 First of all check that your pipeline runs on Azure pipelines (aka Azure-hosted): MSDyn365 \u0026 Azure DevOps ALM 54 DevTest Labs Azure Pipelines The create and delete steps will run on the Azure Pipelines pool. The build step will run on our DevTestLabs pool, or the name you gave it when configuring the artifact on DevTest Labs or the script on the VM. Create Azure DevTest Labs VM Create a new pipeline and choose the “Use the classic editor” option. Make sure you’ve selected TFVC as your source and click “Continue” and “Empty job”. Add a new task to the pipeline, look for “Azure DevTest Labs Create VM”. We just need to fill in the missing parameters with our subscription, lab, etc. MSDyn365 \u0026 Azure DevOps ALM 55 Create VM Azure DevTest Labs Remember this step must run on the Azure-hosted pipeline. Build This is an easy one. Just export a working pipeline and import it. And this step needs to run on your self-hosted pool: MSDyn365 \u0026 Azure DevOps ALM 56 Runs on self-hosted pool Optional: use SelectiveSync (not recommended, see next option) You can replace the Database Sync task for a PowerShell script that will only sync the tables in your models: MSDyn365 \u0026 Azure DevOps ALM 57 SelectiveSync.ps1 Thanks Joris for the tip! Optional: use d365fo.tools to sync your packages/models This is a better option than the SelectiveSync above. You can synchronize your packages or models only to gain some time. This cmdlet uses sync.exe like Visual Studio does and should be better than SelectiveSync. Add a new PowerShell task, select Inline Script and this is the command: Invoke-D365DbSyncModule -Module \"Module1\", \"Module2\" -ShowOriginalProgress -Verbose Optional: use d365fo.tools to deploy SSRS reports If you really want to add the report deployment step to your pipeline you can save some more extra time using d365fo.tools and just deploy the reports in your models like we’ve done with the DB sync. Run this in a new PowerShell task to do it: Publish-D365SsrsReport -Module YOUR\\_MODULE -ReportName \\* Delete Azure DevTest Labs VM It’s almost the same as the create step, complete the subscription, lab and VM fields and done: MSDyn365 \u0026 Azure DevOps ALM 58 Delete VM And this step, like the create one, will run on the Azure-hosted agent. Dependencies and conditions When all three steps are configured we need to add dependencies and conditions to some of them. For example, to make sure that the delete VM step runs when the build step fails, but it doesn’t when the create VM step fails. Build The build step depends on the create VM step, and will only run if the previous step succeeds: MSDyn365 \u0026 Azure DevOps ALM 59 Build step dependencies and conditions Delete VM The delete step depends on all previous steps and must run when the create VM step succeeds. If the create step fails there’s no VM and we don’t need to delete it: MSDyn365 \u0026 Azure DevOps ALM 60 Dependencies and conditions on delete VM step This is the custom condition we’ll use: and(always(), eq(dependencies.Job\\_1.status, 'Succeeded')) If you need to know your first step’s job name just export the pipeline to YAML and you’ll find it there: MSDyn365 \u0026 Azure DevOps ALM 61 Export pipeline to YAML MSDyn365 \u0026 Azure DevOps ALM 62 Job name on YAML If this step fails when the pipeline is run, wait to delete the VM manually, first change the VM name in the delete step, save your pipeline and then use the dropdown to show the VMs in the selected subscription, and save the pipeline. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:8","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Run the build And, I think, we’re done and ready to run our Azure DevTest Labs pipeline for Dynamics 365 Finance and Operations… click “Run pipeline” and wait… MSDyn365 \u0026 Azure DevOps ALM 63 Tadaaaa!! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:9","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Times The pipeline from the image above is one with real code from a customer but I can’t compare the times with the Azure-hosted builds because there’s no sync, or tests there. Regarding the build time the Azure-hosted takes one minute less, but it needs to install the nugets first. But for example this is a comparison I did: MSDyn365 \u0026 Azure DevOps ALM 64 Azure DevTest Labs B2ms vs B4ms It takes around 1 hour to create the VM, build, do a full DB synch, deploy reports, run tests, generate a Deployable Package and, finally, delete the VM: MSDyn365 \u0026 Azure DevOps ALM 65 If you skip deploying the SSRS reports your build will run in 15 minutes less, that’s around 45 minutes. If you use the partial sync process instead of a full DB sync it’ll be 5-7 minutes less. This would leave us with a 35-40 minutes build. Comparison 1 MSDyn365 \u0026 Azure DevOps ALM 66 No DB Sync The image above shows a simple package being compiled, without any table, so the selective sync goes really fast. The build times improve with VM size. Comparison 2 MSDyn365 \u0026 Azure DevOps ALM 67 Same code Full DB Sync This one is compiling the same codebase but is doing a full DB sync. The sync time improves in the B4ms VM compared to the B2ms but it’s almost the same in the B8ms. Build times are better for larger VM sizes. Comparison 3 MSDyn365 \u0026 Azure DevOps ALM 68 Real code + full sync And in the image above we see a more realistic build. The codebase is larger and we’re doing a full DB sync. Similar as the comparison before there a good enhancement between a B2ms and a B4ms, but not between a B4ms and B8ms. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:10","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Show me the money! I think this is the interesting comparison. How did a Tier-1 MS-hosted build VM cost? Around 400€? How does it compare to using the Azure DevTest Labs alternative? There’s only one fix cost when using Azure DevTest Labs: the blob storage where the VHD is uploaded. The VHD’s size is around 130GB and this should have a cost of, more or less, 5 euros/month. Keep in mind that you need to clean up your custom images when yours is prepared, the new ones are created as snapshots and also take space in the storage account. Then we have the variable costs that come with the deployment of a VM each build but it’s just absurd. Imagine we’re using a B4ms VM, with a 256GB Premium SSD disk, we would pay 0.18€/hour for the VM plus the proportional part of 35.26€/month of the SSD disk, which would be like 5 cents/hour? But this can run on a B2ms VM too which is half the compute price of the VM, down to 9 cents per hour. If we run this build once a day each month, 30 times, the cost of a B4ms would be like… 7€? Add the blob storage and we’ll be paying 12€ per month to run our builds with DB sync and tests. Is it cheaper than deploying a cloud-hosted environment, and starting and stopping it using the new d365fo.tools Cmdlets each time we run the build? Yes it is! Because if we deploy a CHE we’ll be paying the price of the SSD disk for the whole month! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:11","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Some final remarks I have accomplished this mostly through trial-and-error. There’s lots of enhancements and best practices to be applied to all the process, specially using an Azure Key Vault to store all the secrets to be used in the Azure DevOps Agent artifact and the pipeline. This in another clear example that X++ developers need to step outside of X++ and Dynamics 365 FnO. We’re not X++ only developers anymore, we’re very lucky to be working on a product that is using Azure. I’m sure there’s scenarios where using DevTest Labs to create a build VM is useful. Maybe not for an implementation partner, but maybe it is for an ISV partner. It’s just an additional option. The only bad thing to me is that we need to apply the version upgrades manually to the VHDs because they’re published only twice a year. As I said at the beginning of the post, it may have worked to me with all these steps, but if you try you maybe need to change some things. But it’s a good way to start. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:4:12","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Add and build .NET projects I bet that most of us have had to develop some .NET class library to solve something in Dynamics 365 Finance and Operations. You create a C# project, build it, and add the DLL as a reference in your FnO project. Don’t do that anymore! You can add the .NET project to source control, build it in your pipeline, and the DLL gets added to the deployable package! I’ve been trying this during the last days after a conversation on Yammer, and while I’ve managed to build .NET and X++ code in the same pipeline, I’ve found some issues or limitations. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:5:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Build .NET in your pipeline Note: what I show in this post is done using the Azure-hosted pipeline but it should also be possible to do it using a self-hosted agent (aka old build VM). The build step of the pipeline invokes msbuild.exe which can build .NET code. If we check the logs of the build step we will see it: MSDyn365 \u0026 Azure DevOps ALM 69 msbuild.exe builds C# projects and our X++ ones too! Remember that X++ is part of the .NET family after all… a second cousin or something like it. MSDyn365 \u0026 Azure DevOps ALM 70 Build folder If you’ve read the blog post about Azure-hosted builds you must’ve seen I’m putting the solution that references all my models in a folder called Build at the root of my source control tree (left image). That’s just a personal preference that helps me keep the .config files and the solution I use to build all the models in a single, separate place. By using a solution and pointing the build process to use it I also keep control of what’s being built in a single place. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:5:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Add a C# project to FnO Our first step will usually be creating a Finance and Operations project. Once it’s created we right-click on the solution and select “Add new project”. Then we select a Visual C# Class Library project: MSDyn365 \u0026 Azure DevOps ALM 71 C# project in Dynamics 365 MSDyn365 \u0026 Azure DevOps ALM 72 Now we should have a solution with a FnO Project and a C# project (right image). To demo this I’ll create a class called Calculator with a single method that accepts two decimal values as parameters and returns it’s sum. An add method. public class Calculator { public decimal Add(decimal a, decimal b) { return a + b; } } public class Calculator { public decimal Add(decimal a, decimal b) { return a + b; } } Now compile the C# project alone, not the whole solution. This will create the DLL in the bin folder of the project. We have to do this before adding the C# project as a reference to the FnO project. Right click on the References node of the FnO project and select “Add Reference…”: MSDyn365 \u0026 Azure DevOps ALM 73 Add reference to FnO project A window will open and you should see the C# project in the “Projects” tab: MSDyn365 \u0026 Azure DevOps ALM 74 Add C# project reference to FnO project Select it and click the Ok button. That will add the C# project as a reference to our FnO project, but we still need to do something or this won’t compile in our pipeline. We have to manually add the reference to the project that has been created in the AOT. So, right-click on the reference and select “Add to source control”: MSDyn365 \u0026 Azure DevOps ALM 75 Add the reference to source control In the FnO project add a Runnable Class, we’ll call the C# library there: using AASBuildNetDemoLibrary; class AASBuildNetTest { public static void main(Args \\_args) { var calc = new Calculator(); calc.Add(4, 5); } } using AASBuildNetDemoLibrary; class AASBuildNetTest { public static void main(Args \\_args) { var calc \\= new Calculator(); calc.Add(4, 5); } } Add the solution to source control if you haven’t, make sure all the objects are also added and check it in. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:5:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Build pipeline If I go to my Azure DevOps repo we’ll see the following: MSDyn365 \u0026 Azure DevOps ALM 76 Projects and objects You can see I’ve checked-in the solution under the Build folder, as I said earlier this is my personal preference and I do that to keep the solutions I’ll use to build the code under control. In my build pipeline I make sure I’m using this solution to build the code: MSDyn365 \u0026 Azure DevOps ALM 77 Build Dynamics 365 solution Run the pipeline and when it’s done you can check the build step and you’ll see a line that reads: Copying file from \"D:\\\\a\\\\9\\\\s\\\\Build\\\\AASBuildNetDemo\\\\AASBuildNetDemoLibrary\\\\bin\\\\Debug\\\\AASBuildNetDemoLibrary.dll\" to \"D:\\\\a\\\\9\\\\b\\\\AASDemo\\\\bin\\\\AASBuildNetDemoLibrary.dll\". And if you download the DP, unzip it, navigate to AOSService\\Packages\\files and unzip the file in there, then open the bin folder, you’ll see our library’s DLL there: MSDyn365 \u0026 Azure DevOps ALM 78 Victory! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:5:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Things I don’t like/understand/need to investigate I’ve always done this with a single solution and only one C# project. I have some doubts about how this will work with many C# projects, models, solutions, etc. For example, if a model has a dependency on the DLL but it’s built before the DLL the build will fail. I’m sure there’s a way to set an order to solve dependencies like there is for FnO projects within a solution. Or maybe I could try building all the C#/.NET projects before, pack them in a nuget and use the DLLs later in the FnO build, something similar to what Paul Heisterkamp explained in his blog. Anyway, it’s your choice how to manage your C# projects and what solution fits your workflow the best, but at least you’ve got an example here 🙂 ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:5:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Setup Release Pipelines We’ve seen how the default build definition is created and how we can modify it. Now we’ll see how to configure our release pipelines! The release pipelines allow us to automatically deploy our Deployable Packages to a Tier 2+ environment. This is part of the Continuous Delivery (CD) strategy. We can only do this for the UAT environments, it’s not possible to automate the deployment to the production environment. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:6:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Setting up Release Pipeline in Azure DevOps for Dynamics 365 for Finance and Operations To configure the release pipeline, we need: AAD app registration LCS project An Azure DevOps project linked to the LCS project above A service account I recommend a service account to do this, with a non-expiring password and no MFA enabled. It must have enough privileges on LCS, Azure and Azure DevOps too. This is not mandatory and can be done even with your user (if it has enough rights) for testing purposes, but if you’re setting this up don’t use your user and go for a service account. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:6:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"AAD app creation The first step to take is creating an app registration on Azure Active Directory to upload the generated deployable package to LCS. Head to Azure portal and once logged in go to Azure ActiveDirectory, then App Registrations and create a new Native app: MSDyn365 \u0026 Azure DevOps ALM 79 Next go to “Settings” and “Required permissions” to add the Dynamics Lifecycle Services API: MSDyn365 \u0026 Azure DevOps ALM 80 In the dialog that will open change to the “APIs my organization uses” tab and select “Dynamics Lifecycle Services”: MSDyn365 \u0026 Azure DevOps ALM 81 Select the only available permission in the next screen and click on the “Add permissions” button. Finally press the “Grant admin consent” button to apply the changes. This last step can be easily forgotten and the package upload to LCS cannot be done if not granted. Once done take note of the Application ID, we’ll use it later. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:6:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Create the release pipeline in DevOps Go to Azure DevOps, and to Pipelines -\u003e Releases to create the new release. Select “New release pipeline” and choose “Empty job” from the list. On the artifact box select the build which will be used for this release definition: MSDyn365 \u0026 Azure DevOps ALM 82 Pick the build definition you want to use for the release in “Source”, “Latest” in “Default version” and push “Add”. Upload to LCS The next step we’ll take is adding a Task with the release pipeline for Dynamics. Go to the Tasks tab and press the plus button. A list with extension will appear, look for “Dynamics 365 Unified Operations Tools”: MSDyn365 \u0026 Azure DevOps ALM 83 If the extension hasn’t been added previously it can be done in this screen. In order to add it, the user used to create the release must have admin rights on the Azure DevOps account, not only in the project in which we’re creating the pipeline. When the task is created we need to fill some parameters:![Release Dynamics Operations](./MSDyn365 \u0026 Azure DevOps ALM - ariste.info_files/Captura-de-pantalla-2019-02-03-a-les-0.43.11-1024x508.png#center.webp “MSDyn365 \u0026 Azure DevOps ALM 84”) MSDyn365 \u0026 Azure DevOps ALM 84 Apply deployable package This step is finally available for self-service environments! If you already set this for a regular environment you can still change the task to the new version. MSDyn365 \u0026 Azure DevOps ALM 85 Azure DevOps asset deployment The new task version 1 works for both type of environments: Microsoft managed (regular environments) and self-service environments. The task version 0 is the old one and will only work with regular environments. You can safely switch your deploy tasks to version 1. What’s different in task version 1? I guess that some work behind it that we don’t see to make it support self-service, but in the UI we only see a new field called “Name for the update“. MSDyn365 \u0026 Azure DevOps ALM 86 Name for the update field This field is needed only for the self-service environments deployments, it will be ignored for regular ones, and corresponds to the field with the same name that appears on LCS when we apply an update to a sandbox environment: MSDyn365 \u0026 Azure DevOps ALM 87 Name for this update in LCS The default field’s value is the variable $(Release.ReleaseName) that is the name of the release, but you can change it, for example I’ll be using a pattern like PREFIX BRANCH $(Build.BuildNumber) to have the same name we have for the builds and identifying what we’re deploying to prod quickier. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:6:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Creating the LCS connection The first step in the task is setting up the link to LCS using the AAD app we created before. Press New and let’s fill the fields in the following screen: MSDyn365 \u0026 Azure DevOps ALM 88 It’s only necessary to fill in the connection name, username, password (from the user and Application (Client) ID fields. Use the App ID we got in the first step for the App ID field. The endpoint fields should be automatically filled in. Finally, press OK and the LCS connection is ready. In the LCS Project Id field, use the ID from the LCS project URL, for example in https://lcs.dynamics.com/V2/ProjectOverview/1234567 the project is is 1234567. Press the button next to “File to upload” and select the deployable package file generated by the build: MSDyn365 \u0026 Azure DevOps ALM 89 If the build definition hasn’t been modified, the output DP will have a name like AXDeployableRuntime_VERSION_BUILDNUMBER.zip. Change the fixed Build Number for the DevOps variable $(Build.BuildNumber) like in the image below: MSDyn365 \u0026 Azure DevOps ALM 90 The package name and description in LCS are defined in “LCS Asset Name” and “LCS Asset Description”. For these fields, Azure DevOps’ build variables and release variables can be used. Use whatever fits your project, for example a prefix to distinguish between prod and pre-prod packages followed by $(Build.BuildNumber), will upload the DP to LCS with a name like Prod 2019.1.29.1, using the date as a DP name. Save the task and release definition and let’s test it. In the Releases select the one we have just created and press the “Create a release” button, in the dialog just press OK. The release will start and, if everything is OK we’ll see the DP in LCS when it finishes: MSDyn365 \u0026 Azure DevOps ALM 91 The release part can be automated, just press the lightning button on the artifact and enable the trigger: MSDyn365 \u0026 Azure DevOps ALM 92 And that’s all! Now the build and the releases are both configured. Once the deployment package is published the CI scenario will be complete. More automation! I’ve already explained in the past how to automate the builds, create the CI builds and create the release pipelines on Azure DevOps, what I want to talk about in this post is about adding a little bit more automation. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:6:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Builds In the build definition go to the “Triggers” tab and enable a scheduled build: MSDyn365 \u0026 Azure DevOps ALM 93 This will automatically trigger the build at the time and days you select. In the example image, every weekday at 16.30h a new build will be launched. But everyday? Nope! What the “Only schedule builds if the source or pipeline has changed” checkbox below the time selector makes is only triggering the build if there’s been any change to the codebase, meaning that if there’s no changeset checked-in during that day no build will be triggered. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:7:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Releases First step done, let’s see what can we do with the releases: MSDyn365 \u0026 Azure DevOps ALM 94 The release pipeline in the image above is the one that launches after the build I’ve created in the first step. For this pipeline I’ve added the following: MSDyn365 \u0026 Azure DevOps ALM 95 The continuous deployment trigger has been enabled, meaning that after the build finishes this release will be automatically run. No need to define a schedule but you could also do that. MSDyn365 \u0026 Azure DevOps ALM 96 As you can see, the schedule screen is exactly the same as in the builds, even the changed pipeline checkbox is there. You can use any of these two approaches, CD or scheduled release, it’s up to your project or team needs. With these two small steps you can have your full CI and CD strategy automatized and update a UAT environment each night to have all the changes done during that day ready for testing, with no human interaction! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:8:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"But I like to add some human touch to it If you don’t like not knowing if an environment is being updated… well that’s IMPOSSIBLE because LCS will SPAM you to make sure you know what’s going on. But if you don’t want to be completely replaced by robots you can add approvals to your release flow: MSDyn365 \u0026 Azure DevOps ALM 97 Clicking the left lightning + person button on your release you can set the approvers, a person or a group (which is quite practical), and the kind of approval (all or single approver) and the timeout. You will also receive an email with a link to the approval form: MSDyn365 \u0026 Azure DevOps ALM 98 And you can also postpone the deployment! Everything is awesome! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:9:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Extra bonus! A little tip. Imagine you have the following release: MSDyn365 \u0026 Azure DevOps ALM 99 This will update 3 environments, but will also upload the same Deployable Package three times to LCS. Wouldn’t it be nice to have a single upload and that all the deployments used that file? Yes, but we can’t pass the output variable from the upload to other stages 🙁 Yes that’s unfortunately right. But we can do something with a little help from our friend Powershell! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:10:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Update a variable in a release What we need to do is create a variable in the release definition and set its scope to “Release”: MSDyn365 \u0026 Azure DevOps ALM 100 Then, for each stage, we need to enable this checkbox in the agent job: MSDyn365 \u0026 Azure DevOps ALM 101 I explain later why we’re enabling this. We now only need to update this variable after uploading the DP to LCS. Add an inline Powershell step after the upload one and do this: # Populate store value to update pipeline $assetId\\= \"$(GoldenUpload.FileAssetId)\" Write\\-Output ('##vso\\[task.setvariable variable=localAsset\\]{0}' \\-f $assetId) #region variables $ReleaseVariableName \\= 'axzfileid' $releaseurl \\= ('{0}{1}/\\_apis/release/releases/{2}?api-version=5.0' \\-f $($env:SYSTEM\\_TEAMFOUNDATIONSERVERURI), $($env:SYSTEM\\_TEAMPROJECTID), $($env:RELEASE\\_RELEASEID) ) #endregion #region Get Release Definition Write\\-Host \"URL: $releaseurl\" $Release \\= Invoke\\-RestMethod \\-Uri $releaseurl \\-Headers @{ Authorization \\= \"Bearer $env:SYSTEM\\_ACCESSTOKEN\" } #endregion #region Output current Release Pipeline #Write-Output ('Release Pipeline variables output: {0}' -f $($Release.variables | #ConvertTo-Json -Depth 10)) #endregion #Update axzfileid with new value $release.variables.($ReleaseVariableName).value \\= $assetId #region update release pipeline Write\\-Output ('Updating Release Definition') $json \\= @($release) | ConvertTo\\-Json \\-Depth 99 $enc \\= \\[System.Text.Encoding\\]::UTF8 $json\\= $enc.GetBytes($json) Invoke\\-RestMethod \\-Uri $releaseurl \\-Method Put \\-Body $json \\-ContentType \"application/json\" \\-Headers @{Authorization \\= \"Bearer $env:SYSTEM\\_ACCESSTOKEN\" } #endregion You need to change the following: Line 2: $assetId= “$(GoldenUpload.FileAssetId)”. Change $(GoldenUpload.FileAssetId) for your output variable name. Line 6: $ReleaseVariableName = ‘axzfileid’. Change axzfileid for your Release variable name. And you’re done. This script uses Azure DevOps’ REST API to update the variable value with the file id, and we enabled the OAuth token checkbox to allow the usage of this API without having to pass any user credentials. This is not my idea obviously, I’ve done this thanks to this post from Stefan Stranger’s blog. Now, in the deploy stages you need to retrieve your variable’s value in the following way: MSDyn365 \u0026 Azure DevOps ALM 102 Don’t forget the ( ) or it won’t work! And with these small changes you can have a release like this: MSDyn365 \u0026 Azure DevOps ALM 103 With a single DP upload to LCS and multiple deployments using the file uploaded in the first stage. With approvals, and delays, and emails, and everything! LCS DB API ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:11:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Call the LCS Database Movement API from your Azure DevOps Pipelines ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:12:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"What for? Basically, automation. Right now the API only allows the refresh from one Microsoft Dynamics 365 for Finance and Operations environment to another, so the idea is having fresh data from production in our UAT environments daily. I don’t know which new operations the API will support in the future but another idea could be adding the DB export operation (creating a bacpac) to the pipeline and having a copy of prod ready to be restored in a Dev environment. Don’t forget that the API has a limit of 3 refresh operations per environment per 24 hours. Don’t do this on a CI build! (it makes no sense either). Probably the best idea is to run this nightly with all your tests, once a day. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:12:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Calling the API I’ll use PowerShell to call the API from a pipeline. PowerShell has a command called Invoke-RestMethod that makes HTTP/HTTPS requests. It’s really easy and we just need to do the same we did to call the API in my post. Getting the token $projectId \\= \"1234567\" $tokenUrl \\= \"https://login.microsoftonline.com/common/oauth2/token\" $clientId \\= \"12345678-abcd-432a-0666-22de4c4321aa\" $clientSecret \\= \"superSeCrEt12345678\" $username \\= \"youruser@tenant.com\" $password \\= \"strongerThan123456\" $tokenBody \\= @{ grant\\_type \\= \"password\" client\\_id \\= $clientId client\\_secret \\= $clientSecret resource \\= \"https://lcsapi.lcs.dynamics.com\" username \\= $username password \\= $password } $tokenResponse \\= Invoke\\-RestMethod \\-Method 'POST' \\-Uri $tokenUrl \\-Body $tokenBody $token \\= $tokenResponse.access\\_token To get the token we’ll use this script. Just change the variables for the ones of your project, AAD App registration, user (remember it needs access to the preview) and password and run it. If everything is OK you’ll get the JSON response in the $tokenResponse variable and from there you can get the token’s value using dot notation. Requesting the DB refresh $projectId \\= \"1234567\" $sourceEnvironmentId \\= \"fad26410-03cd-4c3e-89b8-85d2bddc4933\" $targetEnvironmentId \\= \"cab68410-cd13-9e48-12a3-32d585aaa548\" $refreshUrl \\= \"https://lcsapi.lcs.dynamics.com/databasemovement/v1/databases/project/$projectId/source/$sourceEnvironmentId/target/$targetEnvironmentId\" $refreshHeader \\= @{ Authorization \\= \"Bearer $token\" \"x-ms-version\" \\= '2017-09-15' \"Content-Type\" \\= \"application/json\" } $refreshResponse \\= Invoke\\-RestMethod $refreshUrl\u0026nbsp;\\-Method 'POST' \\-Headers $refreshHeader This will be the call to trigger the refresh. We’ll need the token we’ve just obtained in the first step to use it in the header and the source and target environment Ids. If it’s successful the response will be a 200 OK. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:12:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Add it to your pipeline Adding this to an Azure DevOps pipeline is no mistery. Select and edit your pipeline, I’m doing it on a nigthly build (it’s called continuous but it’s not…) that runs after the environment has been updated with code, and add a new PowerShell task: MSDyn365 \u0026 Azure DevOps ALM 104 Select the task and change it to “Inline”: MSDyn365 \u0026 Azure DevOps ALM 105 Then just paste the script we’ve created in the Script field and done! You’ll get a refresh after the tests! You can also run this on your release pipeline BUT if you do it after the deploy step remember to mark the “Wait for Completion” option or the operation will fail because the environment will already be servicing! And even then it could fail if the servicing goes over the timeout time. So… don’t run this on your release pipeline! And that’s all. Let’s which new operations will be added to the API and what we can do with them. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:12:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Use d365fo.tools in your Azure Pipeline Thanks to Mötz’s comment pointing me to how to add d365fo.tools to a hosted pipeline I’ve created a pipeline which will install the tools and run the commands. It’s even easier to do than with the Invoke-RestMethod. But first… Make sure that in your Azure Active Directory app registration you’ve selected “Treat application as a public client” under Authentication: MSDyn365 \u0026 Azure DevOps ALM 106 The task First we need to install d365fo.tools and then we can use its commands to call the LCS API: Install\\-PackageProvider nuget \\-Scope CurrentUser \\-Force \\-Confirm:$false Install\\-Module \\-Name AZ \\-AllowClobber \\-Scope CurrentUser \\-Force \\-Confirm:$False \\-SkipPublisherCheck Install\\-Module \\-Name d365fo.tools \\-AllowClobber \\-Scope CurrentUser \\-Force \\-Confirm:$false Get\\-D365LcsApiToken \\-ClientId \"{YOUR\\_APP\\_ID}\" \\-Username \"{USERNAME}\" \\-Password \"{PASSWORD}\" \\-LcsApiUri \"https://lcsapi.lcs.dynamics.com\" \\-Verbose | Set\\-D365LcsApiConfig \\-ProjectId 1234567 Invoke\\-D365LcsDatabaseRefresh \\-SourceEnvironmentId \"958ae597-f089-4811-abbd-c1190917eaae\" \\-TargetEnvironmentId \"13cc7700-c13b-4ea3-81cd-2d26fa72ec5e\" \\-SkipInitialStatusFetch As you can see it a bit easier to do the refresh using d365fo.tools. We get the token and pipeline the output to the Set-D365LcsApiConfig command which will store the token (and others). This also helps to not having to duplicate AppIds, users, etc. and as you can see to call the refresh operation we just need the source and target environment Ids! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:12:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Automating Prod to Dev DB copies The new LCS DB API endpoint to create a database export has been published! With it we now have a way of automating and scheduling a database refresh from your Dynamics 365 FnO production environment to a developer or Tier 1 VM. MSDyn365 \u0026 Azure DevOps ALM 107 Using the LCS DB API ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:13:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"The bacpac issue One of the main setbacks we currently have with prod DB refreshes is that it’s not a quick thing to do because you need to: Refresh a Tier 2+ environment with prod’s DB Export a bacpac from the Tier 2+ environment Restore the bacpac on a Tier 1 VM. This happens because Tier 2+ environments use Azure SQL as the DB engine and Tier 1 VMs use SQL Server. The time it takes to complete the process depends on the size of the database and the performance of the VM you’ll restore it to. But it’s not a fast process at all. For a 60GB database you’ll get a bacpac around 7GB that will take: 1 to 2 hours to refresh to UAT 2 to 4 hours for the bacpac to be exported At least 4 hours to restore it to a Tier 1 VM. That’s between 7 and 11 hours until you have the DB on a developer machine. Once it’s there you can quickly get a BAK and share it. But you might need the time of a full working day to have that data available. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:13:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Save us LCS DB API! Thanks to the new LCS DB API’s endpoint we can perform all these steps automatically, and with the help of d365fo.tools it’ll be even easier. But first… Due to the extensive time it takes to complete all the process, we first have to decide a schedule (daily, weekly, etc.) and then this schedule must be compatible with the release cadence to UAT/Prod, because only one operation at a time can be done. There’s still another problem but I’ll talk about it after seeing the scripts. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:13:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"My proposal To do the last part of the LCS DB API flow from prod to dev, we need a Tier 1 VM where the bacpac will be restored. My idea is using the build VM on Microsoft’s subscription and an Azure DevOps pipeline to run all the scripts that will restore the DB in that VM. It’s an underused machine and it fits perfectly to this purpose. I want to clarify why I’ve thought about doing this using the build VM. In most cases this VM will be doing nothing during the night, maybe only running some tests, and it’s during that period of time when I suggest doing all this. But be aware that depending on your DB size this won’t be possible or you’ll run out of space after 2 o 3 restores. So think about deploying an extra VM and install an agent there to do this, whatever you do don’t mess with the build VM if you don’t know what you’re doing! Try this on a dev VM or anywhere else if you’re afraid of breaking something. Remember you’ll lose the capacity to generate DPs and run pipelines if this environments breaks! This post is just an example of a possible solution, you need to decide what suits you best! End of the update. As I said before I’ll be using Mötz Jensen‘s d365fo.tools, we could do everything without them but that would be a bit stupid because using the tools is easier, faster and makes everything clearer. I’ve separated all the steps in 3 Powershell scripts: execute the refresh, export the bacpac and restore the bacpac. Refresh database This will refresh the prod environmnet to a Tier 2+: $clientId \\= \"ab12345-6220-4566-896a-19a4ad41783f\" $userName \\= \"admin@tenant\" $passWord \\= \"admin123456\" $projectId \\= \"1234567\" $sourceEnvId \\= \"958bc863-f089-4811-abbd-c1190917eaae\" $targetEnvId \\= \"13aa6872-c13b-4ea3-81cd-2d26fa72ec5e\" Get-D365LcsApiToken \\-ClientId $clientId \\-Username $userName \\-Password $passWord \\-LcsApiUri \"https://lcsapi.lcs.dynamics.com\" \\-Verbose | Set\\-D365LcsApiConfig \\-ProjectId $projectId Invoke-D365LcsDatabaseRefresh \\-SourceEnvironmentId $sourceEnvId \\-TargetEnvironmentId $targetEnvId \\-SkipInitialStatusFetch Export database This part will trigger the bacpac export from the Tier 2+ environment which we’ve just refreshed: $sourceEnvId \\= \"958bc863-f089-4811-abbd-c1190917eaae\" $targetEnvId \\= \"13aa6872-c13b-4ea3-81cd-2d26fa72ec5e\" Get-D365LcsApiConfig | Invoke-D365LcsApiRefreshToken | Set\\-D365LcsApiConfig Invoke-D365LcsDatabaseExport \\-SourceEnvironmentId $targetEnvId \\-BackupName $bacpacName Restore bacpac And the final step will download the bacpac and restore it to a new database: $currentDate \\= Get-Date \\-Format yyyymmdd $bacpacName \\= \"UAT{0}\" \\-f $currentDate $downloadPath \\= \"D:\\\\UAT{0}.bacpac\" \\-f $currentDate $newDBName \\= \"AxDB\\_{0}\" \\-f $currentDate Get-D365LcsApiConfig | Invoke-D365LcsApiRefreshToken | Set\\-D365LcsApiConfig $backups \\= Get-D365LcsDatabaseBackups $fileLocation \\= $backups\\[0\\].FileLocation Invoke-D365AzCopyTransfer \\-SourceUri $fileLocation \\-DestinationUri $downloadPath Import-D365Bacpac \\-ImportModeTier1 \\-BacpacFile $downloadPath \\-NewDatabaseName $newDBName Using it in an Azure DevOps pipeline MSDyn365 \u0026 Azure DevOps ALM 108 Azure DevOps pipeline This is it. Create a Powershell script, place it in the Build VM and call it in your pipeline. This is only valid for the agent hosted in the build VM. Everything can probably be run in an Azure hosted agent, but I’ll not cover it here because I think that using the build VM, where we can restore the DB, is more useful to us. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:13:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Timing These 3 scripts will call the LCS DB API to refresh, export and restore the DB. But there’s the timing issue. Refreshing the database takes some time and exporting it too. You need to find a way to control the status of the operations. The LCS DB API offers an operation you can use to get the status of the ongoing operation. Using d365fo.tools: Get-D365LcsDatabaseRefreshStatus \\-OperationActivityId 123456789 \\-EnvironmentId \"99ac6587-c13b-4ea3-81cd-2d26fa72ec5e\" You can choose to control that inside your Powershell scripts, but if we use the agent on the build VM that means we cannot use it for anything else until everything is done. That’s why I separated the process in 3 steps. You can manually schedule 3 pipelines, one for each step at the times you know each stage ends. Then you can choose the order: export, restore, refresh or refresh, export, restore. You could also use Windows Task Scheduler and forget about AZDO Pipelines, but we’re not doing that because we love pipelines. And that’s all, we finally have a way of moving data without having to do it manually, we can schedule it, but we need to take some decisions on how we’ll do things. And I’ll leave that up to you 🙂 Secure your Azure Pipelines with Azure Key Vault But creating a pipeline with a password in plain sight was not very secure. How could we add extra security to a pipeline? Once again we can turn to an Azure tool to help us, the Azure Key Vault. Azure Key Vault A Key Vault is a service that allows us to safely store certificates or secrets and later use them in our applications and services. And like many other Azure services it has a cost but it’s really low and, for a normal use, you will be billed like a cent or none a month. Don’t be stingy with security! You might already know about Azure Key Vault because we can use it in Microsoft Dynamics 365 for Finance and Operations under System Administration. For example it’s how the company certificates for the Spanish SII or Brazilian NF-e are stored and later retrieved to call the web services. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:13:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Securing your Azure DevOps Pipelines Thanks to the Azure Key Vault task (which is open source like many other tasks) getting a secret from a Key Vault has no secret (badum tssss). ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:14:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Create a Key Vault Go to your Azure subscription and look for Key Vaults in the top search bar. If you don’t have an Azure subscription you can get one free with a credit of 170€/200$ for 30 days and try this or other things. In the Key Vault page click on “Create key vault” and fill the fields MSDyn365 \u0026 Azure DevOps ALM 109 You can go through other tabs but I will just click “Review \u0026 Create” to create the vault. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:14:1","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Add the task to DevOps Now go to Azure DevOps and create a new pipeline or edit an existing one. Add a task to the agent job and look for azure key vault: MSDyn365 \u0026 Azure DevOps ALM 110 It’s possible that you might need to get the task from the marketplace first, if so remember you need to have enough right on the organization and not only the AZDO project you’re in. Now go to the task and select your subscription: MSDyn365 \u0026 Azure DevOps ALM 111 Once selected click the “Authorize” button. This will create a service principal in your subscription, we’ll use it later. After authorizing you just need to select the key vault you’ve created in the first step. And back to Azure. ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:14:2","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Setup and secret creation Go to your key vault, “Access policies” and click “Add Access Policy”: MSDyn365 \u0026 Azure DevOps ALM 112 When we authorized the task to access our Azure subscription it created a service principal now we need to select it to list and get the secrets to be able to use them in our pipeline. Click on “Select principal”: MSDyn365 \u0026 Azure DevOps ALM 113 In the search bar type your subscription’s name, the principal should start with it and end with the same ID of your subscription. Select it and click the “Select” button at the bottom: MSDyn365 \u0026 Azure DevOps ALM 114 Now click on the “Secret permissions” lookup and under “Secret Management Operations” select Get and List: MSDyn365 \u0026 Azure DevOps ALM 115 If you want to also use certificates or keys you should do the same. Finally click the “Add” button and don’t forget to click “Save”!! Otherwise nothing will be saved: MSDyn365 \u0026 Azure DevOps ALM 116 Now we can create a secret in the key vault. Go to secrets and click on “Generate/Import”, complete the fields and finally click on the “Create” button: MSDyn365 \u0026 Azure DevOps ALM 117 ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:14:3","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"Using the secrets in your pipelines We’re ready to use the secret in our pipeline. I will add a PowerShell task to call the LCS DB API using d365fo.tools but I’ll change all the variables to the secrets: # Write your PowerShell commands here. Install\\-PackageProvider nuget \\-Scope CurrentUser \\-Force \\-Confirm:$false Install\\-Module \\-Name AZ \\-AllowClobber \\-Scope CurrentUser \\-Force \\-Confirm:$False \\-SkipPublisherCheck Install\\-Module \\-Name d365fo.tools \\-AllowClobber \\-Scope CurrentUser \\-Force \\-Confirm:$false Get\\-D365LcsApiToken \\-ClientId \"$(myAppId)\" \\-Username \"$(myUserName)\" \\-Password \"$(mySecretPassword)\" \\-LcsApiUri \"https://lcsapi.lcs.dynamics.com\" \\-Verbose | Set\\-D365LcsApiConfig \\-ProjectId $(myProjectId) Get\\-D365LcsDatabaseBackups As you can see now even the AAD App Id is masked. What the Azure Key Vault task does is getting the secrets from Azure and storing them in variables when the pipeline runs: MSDyn365 \u0026 Azure DevOps ALM 118 Then we can access it’s value with the $(variableName) notation in the PowerShell script. If you try to print the secrets’ values using the Write-Host command all you’ll get will be three asterisks, so you can see that using the Key Vault is more than safe. If we check the result of running the Get-D365LcsDatabaseBackups command we’ll see how good is this: MSDyn365 \u0026 Azure DevOps ALM 119 The ProjectId value is not printed because it was one of our secret values! And this is how you can add extra security to your Dev ALM! ","date":"May 1, 2021","objectID":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/:14:4","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","DevOps","ALM","AUTOMATED TEST"],"title":"Dynamics 365 for Finance \u0026 Operations and Azure DevOps","uri":"/2021-05-01-dynamics-365-for-finance-operations-and-azure-devops/"},{"categories":null,"content":"\r ","date":"April 30, 2021","objectID":"/2021-04-30-github-git-cheat-sheet/:0:0","tags":["Github","Cheat Sheet","Git"],"title":"Github Git Cheat Sheet","uri":"/2021-04-30-github-git-cheat-sheet/"},{"categories":null,"content":"Open Windows PowerShell in Admin mode Navigate to the PowerShell scripts cd K:\\AosService\\PackagesLocalDirectory\\Plugins\\AxReportVmRoleStartupTask\\ Execute the below commands: For deploying all SSRS reports ./DeployAllReportsToSSRS.ps1 -PackageInstallLocation “K:\\AosService\\PackagesLocalDirectory” For deploying the specific reports ./DeployAllReportsToSSRS.ps1 -Module ApplicationSuite -ReportName \u003cReportName\u003e -PackageInstallLocation “K:\\AosService\\PackagesLocalDirectory” Example: ./DeployAllReportsToSsrs.ps1 -Module MaxCustomization -ReportName MaxCheque_US.Report -PackageInstallLocation \"K:\\AosService\\PackagesLocalDirectory\" ./DeployAllReportsToSsrs.ps1 -Module ApplicatoinSuite -ReportName Cust* -PackageInstallLocation \"C:\\AosService\\PackagesLocalDirectory\" ","date":"January 17, 2021","objectID":"/2021-01-27-deploy-ssrs-reports-in-dynamics-365-finance-scm-using-powershell/:0:0","tags":["SSRS","Dynamics 365 Finance \u0026 Operation","Deploy"],"title":"Deploy SSRS reports in Dynamics 365 Finance, SCM using Powershell","uri":"/2021-01-27-deploy-ssrs-reports-in-dynamics-365-finance-scm-using-powershell/"},{"categories":null,"content":"A new article for you the community. More specifically, all project managers, functional and technical consultants, as well as customer-side decision-makers on the deployment of Dynamics 365 Finance and Operations. I told myself that it would be important to offer you a global article on all the testing capabilities (manual or automatic) for Dynamics 365 Finance and Operations. It is the result of quite a long work but which I hope will help you to improve your code delivery and upgrade processes. As you know, updates to version 10.x are monthly and therefore require operational tests on a regular basis ! I don’t know for you, but for some customers that I know it can take almost 1 week or more for 3 consultants… In addition, if you want to be in an agile process of continuous delivery in production, it is often necessary to take time with the Key Users or the IT team to ensure that we do not have a regression in any part of the ERP. The more development you add, the longer and more difficult it will be to test all of your processes: this will therefore lower the quality of your deployments and repetitions of bugs in the chain: which will necessarily have a cost but also psychological in trust of the tool and your team. For my part, I know that this part is often the least urgent in a process, however if this is done from the start of your GoLive and in continuity, you will gain enormously, therefore automating your tests as much as possible to allow time your team to manage more strategic cases (training, designs) that a machine will not be able to automate. This is the motto of the PowerAutomate tool of the PowerPlatform : “Take Care of what’s important. Automate the rest” Before going into the details of each testing feature that you can use with Dynamics 365 for Finance and Operations, it is important to clarify a few things, such as : You CAN’T test everything… well automatically in fact. As you will see in this article, testing some SSRS Reports, layouts, interfaces or other tools will be very complicated to achieve, and a machine is not a human… So keep in mind that all these features will help you to automate as much as possible long tests process, but you will need to do something… Like of course analyzing Plan test reports, see errors log, correct them, tests manual process : but at the end, maybe you will gain 90% of your testing time ! So clearly I invite you to use all the elements that I will present to you. I will not go very deeper in each parts, because it will be too long ! So of course, you can go directly in each Microsoft documentations to go further in details. But keep in mind, that all documentations are presented separately and it seemed important to me to report everything to you in a single document. Data integration testing Do not use RSAT (as you will see after) for integration tests, instead rely on the data management framework (also known as DIXF). The Data task automation framework enables you to configure and automate the testing of your data integration scenarios. Now, we can go ! So, in Dynamics 365 Finance and Operations, you have 3 parts of testing. While the functional validation of an ERP application can’t be fully data agnostic, there are multiple phases and approaches for testing. These testing phases include: SysTest framework ATL frameowrk Regression Suite Automation Tool (RSAT) ","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:0:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"Overview SysTest framework – The SysTest framework is reliable for writing unit tests. Because unit tests are generally testing a method or function, they should always be data agnostic and dependent only on the input data that is provided as part of the test. ATL framework – Microsoft has an ATL framework that is an abstraction on the SysTest framework and makes functional test writing much more simple and reliable. This framework should be used for writing component tests or simple integration tests. RSAT – The RSAT is used for integration tests and business cycle tests. The business cycle tests, also called the regression validation tests, are dependent on existing data. However, these tests can become data agnostic if you consider additional factors. Where unit tests and component tests are low level and can fully be data agnostic (not dependent on existing dataset), the business cycle or regression validation tests are dependent on some existing data. This data includes setup, configuration settings (parameters), and master data (customer, vendors, items, etc.), but never transaction data. Make sure that during the test, if any of these are being changed, that they are reverted back as part of the final test. Select master data based on certain criteria instead of selecting a particular record. For example, if you want to select an item based on its dimension values and stock availability, filter the product list with those values, select the first item, and copy the number to be used for future tests. If it’s a simple master data line such as customer, vendor, or item, it can be created as part of the automation and used in future tests through chaining. Enter the unique identifiers, such as invoice numbers, through the number sequence or by using Microsoft Excel functions such as =TEXT(NOW(),“yyyymmddhhmm”). This function will provide a unique number every minute, which allows you to track when the action happened. This can be used for variables such as product receipt numbers and vendor invoice numbers. These tests continue to work on the same database again and again, without requiring any restoration. Always set the Edit mode of the environment to Read or Edit as the first test case because the default option is Auto. The Auto options always uses the previous setting and can cause unreliable tests. You can change it in the TEST account that will be used in RSAT (User Option) Only validate after you filter on a particular transaction instead of generic validation. For example, for the number of records, filter for the transaction number or the transaction date so that the validation excludes all other transactions. If you are checking a customer balance or budget check, save the value first and then add your transaction value to validate the expected result instead of validating a fixed expected value. ![rsat-data-agnostic-testing-01.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/rsat-data-agnostic-testing-01.png#center) ","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:1:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"1/ LCS \u003c=\u003e BPM \u003c=\u003e AzureDevOps (via Task Recorder) You aren’t required to use the Business process modeler (BPM) tool in LCS. However, BPM is the recommended tool if you want to enable the management and distribution of test libraries across projects and tenants. These capabilities are especially useful for Microsoft partners and independent software vendors (ISVs). BPM enables the distribution of test libraries as part of LCS solutions. If you are not using BPM, you can manually create test cases in Azure DevOps and attach developer recording files to your Azure DevOps test cases. You can create developer recording files directly from the Task recorder pane. On my side, I will show you how to create BPM in LCS before going to record all my process with the Task Recorders. So, go to your LCS project first. I will assume also that you have already connect LCS and Azure DevOps together. You can after go to the Business Process Modeler part. ![Screenshot 2020-04-20_21-19-53-857.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_21-19-53-857.png#center) As you will notice here, you have your own BPM and also some done by Microsoft. Of course, in your own company/customer, it’s somehow complicated to have a standard \u0026 global but it will be helpful to check the Microsoft BPM to see how it works. ![Screenshot 2020-04-20_21-21-34-605.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_21-21-34-605.png#center) On my side I will create a complete new one to handle testing purpose. “Normally” before a GoLive it’s a task very highly recommended to do with your Key Users, Project Manager and Functional Consultant. ![Screenshot 2020-04-20_21-25-13-784.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_21-25-13-784.png#center) So as you can see, I’ve created a very basic one, just for an example. My process is only to model my customer creation process. After you can add other child flows, dependent processes etc… Also in BPM, you can have a VISIO model of Flow charts, of all your process in the ERP, has defined in LCS. It can be also a good way to add requirements in AzureDevOps before jumping to do customization. Clearly it’s high level definition, but useful also to not forget some specific process, as well as doing some tutorials practices based on that : as you will see also in Task Recorder, you can do your training documentation with screenshots. That’s why if you do it at the very beginning stage of your implementation, all these process conception will help you not just for testing purpose after or before GoLive !! If you want to learn more, you’ll to go there in the Microsoft documentation below : Learn more on BPM in LCS Now that I’ve done my BPM in LCS, i will need to go to FinOps instance to record all my process flow. Quick tips : Download the Extension to have the featue for Google Chrome to take screenshots (good way for training documentation) : https://chrome.google.com/webstore/detail/d365-for-finance-and-oper/inifapcodikhojbnbafaalgbgkfmnlob/related?hl=en-GB Go like in an UAT instance, where you have some DEMO data in it or maybe already a copy of your production/live database. Of course, the mandatory data is to have all your reference and master data in it in order to have a whole complete process. (like for my customer flow : Customer Group, Tax Group etc…) When you are in FinOps, go to the top right ! ![Screenshot 2020-04-20_21-43-54-968.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_21-43-54-968.png#center) Click on “Create recording” Give it a name and description if you want. (good if you have multiple different type of flows to create a customer) - activate take screenshots option if you also intend to generate documentation, in addition to being a","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:2:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"2/ RSAT - Regression Suite Automation Tool Overview The Regression suite automation tool (RSAT) significantly reduces the time and cost of user acceptance testing (UAT). UAT is typically required before you take a Microsoft application update, or before you apply custom code and configurations to your production environment. RSAT lets functional power users record business tasks by using Task recorder and then convert the recordings into a suite of automated tests, without having to write source code. For more information about Task recorder, see Task recorder resources. RSAT is fully integrated with Microsoft Azure DevOps for test execution, reporting, and investigation. Test parameters are decoupled from test steps and stored in Microsoft Excel files. RSAT usage is described here in this schema : ![end-to-end.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/end-to-end.png#center) First, you will need to install it :) Windows 10 and needed also Excel app. Download RSAT But before going to RSAT directly, go back to your Azure DevOps, you will need a Personal Access Token. ![Sans titre.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Sans+titre.png#center) ![Screenshot 2020-04-20_23-51-45-050.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-51-45-050.png#center) Create a new one for RSAT, and make him as expiration date in 1 year, to be safe :) After you need to configure it, to link of course on which environment you need to do your automate testing and. also the Azure DevOps project in which you have setup all test cases. ![RSAT-1.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/RSAT-1.png#center) Change your Azure DevOps URL, put your Personal Access Token generated before, you will now use your Project and the Test Plan created in Azure DevOps before. ![RSAT-2.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/RSAT-2.png#center) After it’s a little more complicated. Put your hostname, the URL of your FinOps instance without HTTPS. For the SOAP Hostname, it’s the same but with aossoap between the firstpart of your hostname and .sandbox part. Like me below : ![RSAT-3.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/RSAT-3.png#center) Put your admin user name email address. The account that will launch every test in your instance. And the company name / legal entity. Keep in mind that we can change on every test the legal entity in a parameter file. For the Thumbprint, it’s a certificate to generate on your computer. Click on new. Copy the number. You will need a technical guy to put it in the environment where you plan to execute the TEST. In the wif.config located in K:\\AosService\\WebRoot -\u003e Don’t forget to apply on each AOS Server ! \u003cauthority name=\"CN=127.0.0.1\"\u003e\r\u003ckeys\u003e\r\u003cadd thumbprint=\"xxxxxxxxxxxxxxxxxxxxxxxxx\" /\u003e\r\u003c/keys\u003e\r\u003cvalidIssuers\u003e\r\u003cadd name=\"CN=127.0.0.1\" /\u003e\r\u003c/validIssuers\u003e\r\u003c/authority\u003e Save a Working Directory folder and also Default Browser to Google Chrome. Don’t forget after configuration to click on Save As, in order to save the configuration and maybe share it for other consultants in your project. Load your test plan and click after on Generate Test Execution and Parameters files. ![RSAT-3.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/RSAT-3(1).png#center) ![You need to have all your test cases here and now you can check on each the Parameter files and change everything needed.](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/RSAT-4.png#center) You need to have all your test cases here and now you can check on each the Parameter files and change everything needed. ![RSAT-5.png#center](./Automate your tests for Dynamics 365 F","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:3:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"3/ SysTestFramework and ATL : Acceptance test library ![54.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/54.png#center) ","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:4:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"Key concepts Use SysTest Framework to author unit/component test code. Test isolation Test module creation to manage test code and FormAdaptors. Import Task Recorder recordings into Visual Studio to generate test code. Overview of the ATL framework Integrate a Test module with a build machine. Clearly this part is mostly for developers, but I think it’s useful also for project manager or functional consultant to know which unit test in the code can be done, despite the RSAT tool that we see before. In fact, all task recorders can be a good start to include it in the Development machine to generate simple test case, but I will show also other Framework that developers can use to be more confident before pushing a new development in a TEST environment… So, first best practice, before going to start writing tests, you will need a new model for that ! To achieve that, go to your Visual Studio and create a new one like me : ![Screenshot 2020-04-20_22-43-39-536.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_22-43-39-536.png#center) Important after, select your reference package. Like me, I select my main package of custom codes - solution to TEST ![Screenshot 2020-04-20_22-44-11-534.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_22-44-11-534.png#center) Check : Create new project, it will here where you will place all your unit tests - and don’t of course make it as the default model for new projects. ![Screenshot 2020-04-20_22-44-49-881.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_22-44-49-881.png#center) After the model is created, change the reference packages, to include ALL FormsAdaptators models, and the main one : Test essentials model ! Also put your main VS project as the Startup object ! ![Screenshot 2020-04-20_22-46-10-271.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_22-46-10-271.png#center) So now, you have your TEST model, all referenced packages included, include your main one of course. You can now built custom test unit code with SysTestFramework; On my side, I will use the Task Recorder Add-in in VS, but of course, you can built your own one without addin. Especially to test custom method on a custom class etc… To generate test class automatically, click on Addins / Import Task Recording ![Screenshot 2020-04-20_22-56-02-444.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_22-56-02-444.png#center) Import the file that you have in the AzureDevOps Unit Test case that we see before (like me : Recording.xml) : as you can see BPM / LCS and Azure DevOps is not only for RSAT ! Select of course your new model for testing purpose. ![Screenshot 2020-04-20_23-01-07-796.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-01-07-796.png#center) You will have a new generate class, like me Change just the top of the class, like adding a SysTestCategory, it will be helpful by doing some filters in the BUILD pipeline of Azure DevOps. Select the legal entity where you want to achieve your test and also add an AutoRollback statement in order to erase all your data after testing process. This class is of course simulate each UI testing, as well as data / business process testing. ![Screenshot 2020-04-20_23-03-17-041.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-03-17-041.png#center) You can of course directly after run \u0026 check if your TEST is OK in your DEV environment by going in the Test Explorer view. ![Screenshot 2020-04-20_23-04-06-977.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:5:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"4/ Change your BUILD \u0026 Release pipeline in AzureDevOps Now go to your AzureDevOps project, on the BUILD pipeline part. We will change the pipeline to include automate testing from SysTest Framework or ATL that we saw before. On my side, I’ve got a BUILD Main, only one. So of course, change \u0026 adapt on your needs. Enable the 3 tasks at the end : Test Setup, Execute and End Tests. ![Screenshot 2020-04-20_23-22-37-415.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-22-37-415.png#center) For these 3 steps, don’t need to change large setup, Just use Task version 2.* and the only change is on the Variable part, to include the SysTestCategory that I had before, remember :) also added my main model.dll that host all my test class. ![Screenshot 2020-04-20_23-22-51-535.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-22-51-535.png#center)![Screenshot 2020-04-20_23-23-24-739.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-23-24-739.png#center)![Screenshot 2020-04-20_23-23-38-414.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-23-38-414.png#center)![Screenshot 2020-04-20_23-24-24-388.png#center](./Automate your tests for Dynamics 365 Finance and Operations — PowerAzure365_files/Screenshot+2020-04-20_23-24-24-388.png#center) So here we are you are a Pro of Automate testing in Dynamics 365 Finance and Operations. To conclude, we can also use PowerAutomate with AzureDevops : doing a morning a test plan report email ? Also create an adaptive card for deployment approval on release pipeline after seeing the test report ? Well as you can see, you have now all in your hands features to achieve a lot automate testing. ","date":"January 1, 2021","objectID":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/:6:0","tags":["Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","AUTOMATED TEST"],"title":"AUTOMATE YOUR TESTS FOR DYNAMICS 365 FINANCE AND OPERATIONS","uri":"/2021-01-01-automate-your-tests-for-dynamics-365-finance/"},{"categories":null,"content":"Microsoft provides a versioned set of capabilities that you can currently use to copy databases between environments, and to list and download database backups. what you can do with Database movement API so far: List database backups Create database refresh Create a database export Get operation activity status More supported actions will be added in later releases. The endpoint uses impersonation authentication base, please follow to register a new application by using the Azure portal 1. Postman environment setup Open Postman -\u003e manage environments -\u003e Add tenant_id: {tenant_id get from AAD} client_id: {get from the application that you have created before} client_secret: {get from the application that you have created before} username: {LCS user name with owner permission} password: {LCS user password} grant_type: password resource: https://lcsapi.lcs.dynamics.com projectId: {Your LCS Project ID} bearerToken: {this will be populated when authentication} {:.border} 2. Authentication with Postman You get the authentication bearer with POST method and https://login.microsoftonline.com/{{tenant_id}}/oauth2/token endpoint. In the request Body, please do following: {:.border} Click Send, and you will have access token to start using the API. {:.border} 3. Cosnume the APIs with Postman To call the Database Movement API, you attach the access token as a bearer token to the authorization header in your HTTP request. So in Postman, modify the headers tab like bellow Authorization:Bearer {{bearerToken}} x-ms-version:'2017-09-15' Content-Type:application/json {:.border} ","date":"August 17, 2020","objectID":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/:0:0","tags":["Database Movement API","Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Postman"],"title":"Testing Dynamics 365 Finance Database Movement API with Postman","uri":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/"},{"categories":null,"content":"3.1. List database backups GET https://lcsapi.lcs.dynamics.com/databasemovement/v1/databases/project/{{projectId}} And we’ll get a JSON with a list of the DB backups on our LCS Asset Library: { \"DatabaseAssets\": [ { \"Id\": \"12314234-862e-4a6a-800d-0c64e982284a\", \"ProjectId\": 123123, \"OrganizationId\": 123124, \"Name\": \"backup\", \"FileName\": \"ATbackup.bacpac\", \"FileDescription\": \"\", \"FileLocation\": \"https://uswedpl1catalog.blob.core.windows.net/product-ax7productname/******\", \"ModifiedDateTime\": \"2020-08-17T09:52:50.077\", \"CreatedDateTime\": \"2020-08-17T09:52:45.297\", \"CreatedByName\": null, \"ModifiedByName\": null } ], \"IsSuccess\": true, \"OperationActivityId\": \"5053e0dd-66e3-4832-a9f8-1e2d621562e1\", \"ErrorMessage\": null, \"VersionEOL\": \"9999-12-31T23:59:59.9999999\" } ","date":"August 17, 2020","objectID":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/:1:0","tags":["Database Movement API","Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Postman"],"title":"Testing Dynamics 365 Finance Database Movement API with Postman","uri":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/"},{"categories":null,"content":"3.2. Create database refresh POST https://lcsapi.lcs.dynamics.com/databasemovement/v1/refresh/project/{projectId}/source/{sourceEnvironmentId}/target/{targetEnvironmentId} { \"IsSuccess\": true, \"OperationActivityId\": \"55eb4327-9346-4c7b-82bd-fe8ef15112c6\", \"ErrorMessage\": null, \"VersionEOL\": \"9999-12-31T23:59:59.9999999\" } ","date":"August 17, 2020","objectID":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/:2:0","tags":["Database Movement API","Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Postman"],"title":"Testing Dynamics 365 Finance Database Movement API with Postman","uri":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/"},{"categories":null,"content":"3.3. Create a database export POST https://lcsapi.lcs.dynamics.com/databasemovement/v1/export/project/{projectId}/environment/{environmentId}/backupName/{backupName} { \"IsSuccess\": true, \"OperationActivityId\": \"55eb4327-9346-4c7b-82bd-fe8ef15112c6\", \"ErrorMessage\": null, \"VersionEOL\": \"9999-12-31T23:59:59.9999999\" } ","date":"August 17, 2020","objectID":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/:3:0","tags":["Database Movement API","Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Postman"],"title":"Testing Dynamics 365 Finance Database Movement API with Postman","uri":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/"},{"categories":null,"content":"3.4. Get operation activity status GET https://lcsapi.lcs.dynamics.com/databasemovement/v1/fetchstatus/project/{projectId}/environment/{environmentId}/operationactivity/{operationactivityId} { \"IsSuccess\": true, \"OperationActivityId\": \"6a90b45f-1764-4077-b924-3f4671540237\", \"ErrorMessage\": null, \"VersionEOL\": \"9999-12-31T23:59:59.9999999\", \"ProjectId\": \"12345\", \"EnvironmentId\": \"5362377c-bc37-4f92-b30e-fe0c1e664cc0\", \"ActivityId\": \"55eb4327-9346-4c7b-82bd-fe8ef15112c6\", \"CompletionDate\": null, \"OperationStatus\": \"InProgress\" } ","date":"August 17, 2020","objectID":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/:4:0","tags":["Database Movement API","Dynamics 365 Finance","Dynamics 365 Supply Chain Management","Dynamics 365 Commerce","Postman"],"title":"Testing Dynamics 365 Finance Database Movement API with Postman","uri":"/2020-08-17-testing-dynamics-365-finance-database-movement-api-with-postman/"},{"categories":null,"content":"Today, we published the 2020 release wave 2 plans for Microsoft Dynamics 365 and Microsoft Power Platform, a compilation of new capabilities that will be released between October 2020 and March 2021. This second release wave of the year offers hundreds of new features and enhancements, demonstrating our continued investment to power digital transformation for our customers and partners. ","date":"August 15, 2020","objectID":"/2020-08-15-dynamics365/:0:0","tags":null,"title":"Microsoft Dynamics 365","uri":"/2020-08-15-dynamics365/"},{"categories":null,"content":"Highlights from Dynamics 365 Dynamics 365 Sales includes updates for more simplified experiences; including collaboration tools, a new mobile experience for quick access to customer information, and new enhancements to forecasting to natively create and manage bottom-up sales forecast processes. Dynamics 365 Sales Insights continues investments in digital selling across multiple areas: sales acceleration, conversation intelligence, relationship intelligence, and advanced forecasting and pipeline intelligence with predictive lead and opportunity scorings to help sales teams uncover top deals. Dynamics 365 Customer Service expands agent productivity capabilities enabling agents to engage in multiple sessions simultaneously. Omnichannel for Customer Service is enhanced with additional extensibility options to enable integration with mobile applications, Microsoft bot framework, and outbound messaging channels. Dynamics 365 Customer Service Insights adds new capabilities to help agents using similar case suggestions to resolve customer issues quickly and easily. A new analytical view for customer service managers helps them focus on key support areas that need attention. These highlights will also be included directly in the core Customer Service Hub app so that users can get insights in context without having to switch between applications. Dynamics 365 Remote Assist expands its range of scenarios beyond calls, allowing technicians to perform activities such as capture service and repairs data, perform surveys and walk-throughs independently, and derive service insights from their service operations. Availability to non-AR enabled devices with modified functionality further empowers technicians to solve problems faster the first time in more environments. Dynamics 365 Field Service continues to add intelligence capabilities including a new Field Service dashboard for monitoring key KPIs and work order completion metrics. There are many user experience enhancements to enable proactive service delivery. The Field Service mobile app is enhanced with capabilities such as push notifications and real-time location sharing. This release wave also includes scheduling enhancements such as multi-day manual scheduling and enhanced skill-based matching. Dynamics 365 Marketing improves the customer journey design experience, for example layout options, zoom, and performance improvements. Integration with Microsoft Teams live events and meetings allows users to create and host live events as a webinar provider. Segmentation is enhanced with a new natural language experience to create and consume customer segments, helping eliminate the specialized skills needed to build complex segments. Dynamics 365 Customer Insights continues to enhance data ingestion and unification, segmentation, and extensibility capabilities using Microsoft Power Platform to enable and extend line-of-business experiences. For example, users can gain deeper customer insights with Microsoft Power BI, build custom apps with Microsoft Power Apps, and trigger workflows based on insights and signals using Microsoft Power Automate. Dynamics 365 Human Resources expands leave and absence, and benefits management capabilities to transform the employee experience. Employees and managers will be able to manage leave and absence directly from Microsoft Teams. We continue to build an HCM ecosystem enabling integrations to recruiting and payroll partners. Dynamics 365 Commerce continues to expand capabilities enabling marketers and non-developers to easily create and manage e-commerce sites with built-in experimentation capabilities. We are improving in-store and curbside pickup scenarios to help customers thrive in the face of the COVID impact. In addition, we are making it easier to increase engagement and conversions online and in-store with AI-powered “shop similar looks” recommendations and intelligent search experiences through Bing for Commerce. Dynamics 365 Connected Store adds","date":"August 15, 2020","objectID":"/2020-08-15-dynamics365/:1:0","tags":null,"title":"Microsoft Dynamics 365","uri":"/2020-08-15-dynamics365/"},{"categories":null,"content":"Highlights from Power Platform Power Apps includes significant improvements for Power Apps developers of all skill levels, improving the sophistication and usability of apps that are created across the web and mobile devices. Makers will be able to create Power Apps directly within Microsoft Teams in order to easily customize the Teams experience. Makers will also be able to add custom pages to model-driven apps using the app designer, bringing together the best of canvas and model capabilities, including creating custom layouts and components. Power Apps portals adds Microsoft Power Virtual Agents as a component in the Power Apps portals studio, as well as support for code components created using Power Apps component framework. AI Builder introduces new AI scenarios for receipt scanning and translation, and improvements to connect to remote training data. The AI builder home page and model details page are updated to improve discoverability and integration with Power Apps and Power Automate. Power BI is investing in three key areas that drive a data culture: amazing data experiences, modern enterprise BI, and insights where decisions are made. Power BI Desktop includes many new capabilities for users to create content quickly and easily, enabling authors to empower their users, enterprise grade content creation, and AI-infused authoring experiences. Power BI Mobile adds split view support for iPad and Power BI Service integrates with Azure Synapse to automatically create and manage materialized views on larger Power BI models as well as enhanced integration with SharePoint lists to build additional custom reports. We continue to enhance our Data protection capabilities enabling customers to classify and label sensitive data. Power Automate enhancements will combine the best of WinAutomation with the cloud-based AI builder and connector-based capabilities in automated flows. This new version will offer customers a way to automate everything from Office apps to legacy terminal applications that haven’t been updated in decades. In addition, enhancements to automated flows running in the cloud will include richer automation and approval experiences. Power Virtual Agents brings expanded capabilities in the authoring experience including tools to create richer content, Adaptive Cards capabilities, topic suggestions from documents, improved Power Automate integration, voice integration with smart speakers, theming to customize the look and feel of the bot, and much more. For a complete list of new capabilities, please check out the Dynamics 365 and Power Platform 2020 release wave 2 plans. ","date":"August 15, 2020","objectID":"/2020-08-15-dynamics365/:2:0","tags":null,"title":"Microsoft Dynamics 365","uri":"/2020-08-15-dynamics365/"},{"categories":null,"content":"Early access period Starting August 3, 2020, customers and partners will be able to validate the latest features in a non-production environment. These features include user experience enhancements that will be automatically enabled for users in production environments during October 2020. Take advantage of the early access period, try out the latest updates in a non-production environment, and get ready to roll out updates to your users with confidence. To see the early access features, check out the Dynamics 365 and Power Platform pages. For questions, please visit the Early Access FAQ page. We’ve done this work to help you—our partners, customers, and users—drive the digital transformation of your business on your terms. Get ready and learn more about latest product updates and plans, and share your feedback in the community forum for Dynamics 365 or Power Platform. ","date":"August 15, 2020","objectID":"/2020-08-15-dynamics365/:3:0","tags":null,"title":"Microsoft Dynamics 365","uri":"/2020-08-15-dynamics365/"},{"categories":null,"content":" In GOLD, export GOLD bak file In MIG, stop all services: Batch, DIXF, MR In MIG, backup AXDB MIG in MIG, AxDB to AxDB_Orgi In MIG, Create AxDB_New In MIG,resotre GOLD to AxDB_New AxDB_Gold to AxDB Start all the services and resett IIS in LCS DB Sync ALTERDATABASEAxDBSETSingle_userWithRollbackimmediatealterdatabaseAxDBModifyname=AxDB_OrigalterdatabaseAxDB_OrigSETMULTI_USERalterdatabaseAxDB_GoldModifyname=AxDBselect*from[USERINFO]","date":"July 14, 2020","objectID":"/2020-07-14-database-movement-tier1-to-tier1/:0:0","tags":null,"title":"Database movement from Tier 1 to Tier 1","uri":"/2020-07-14-database-movement-tier1-to-tier1/"},{"categories":null,"content":"\r\rMarkmap\r\r* {\rmargin: 0;\rpadding: 0;\r}\r#mindmap {\rdisplay: block;\rwidth: 100vw;\rheight: 100vh;\r}\r\r\r\r\r((t,a,e,n)={const{Markmap:o,loadPlugins:s}=window.markmap;(a?a(s,e,n):Promise.resolve()).then(()={o.create(\"svg#mindmap\",null,t)})})({\"t\":\"root\",\"d\":0,\"v\":\"\",\"c\":[{\"t\":\"heading\",\"d\":1,\"v\":\"1. Introduction\",\"c\":[{\"t\":\"list_item\",\"d\":2,\"v\":\"Experience using SharePoint Online at the intermediate level\"},{\"t\":\"list_item\",\"d\":2,\"v\":\"Ability to program with JavaScript, TypeScript, and Node.js\"},{\"t\":\"list_item\",\"d\":2,\"v\":\"Experience using Visual Studio Code at the intermediate level\"},{\"t\":\"list_item\",\"d\":2,\"v\":\"Access to a Microsoft 365 tenant\"}]},{\"t\":\"heading\",\"d\":1,\"v\":\"2. SharePoint Framework overview \u0026 extensibility options\",\"c\":[{\"t\":\"heading\",\"d\":2,\"v\":\"2.1. SharePoint Framework extensibility principles\"},{\"t\":\"heading\",\"d\":2,\"v\":\"2.2. SharePoint Framework overview\",\"c\":[{\"t\":\"list_item\",\"d\":3,\"v\":\"Client-side development. Run in the browser. There's no server-side component in a SharePoint Framework component.\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"Can create server-side components, host by yourself.\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"JavaScript, HTML, CSS, and images.\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"Framework is backwards compatible\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"JavaScript web frameworks like React.\"}]},{\"t\":\"heading\",\"d\":2,\"v\":\"2.3. Supported custom component types\",\"c\":[{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.1. Client-side web parts\",\"c\":[{\"t\":\"paragraph\",\"d\":4,\"v\":\"Client-side web parts are supported in all environments supported by the SharePoint Framework, including SharePoint Server 2016, SharePoint Server 2019 and SharePoint Online.\"}]},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.2. Adding SPFx web parts to pages\"},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.3. SharePoint Framework extensions\",\"c\":[{\"t\":\"list_item\",\"d\":4,\"v\":\"delegate controls and ScriptLink\"},{\"t\":\"list_item\",\"d\":4,\"v\":\"client-side rendering (CSR) and JSLink\"},{\"t\":\"list_item\",\"d\":4,\"v\":\"custom actions\"}]},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.4. Application customizers\"},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.5. Field customizer\"},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.6. Command sets\"},{\"t\":\"heading\",\"d\":3,\"v\":\"2.3.7. Library components\",\"c\":[{\"t\":\"paragraph\",\"d\":4,\"v\":\"Library components are only supported in SharePoint Online.\"}]}]},{\"t\":\"heading\",\"d\":2,\"v\":\"2.4. SharePoint Framework availability\"},{\"t\":\"heading\",\"d\":2,\"v\":\"2.5. SharePoint Framework and SharePoint on-premises deployments\"}]},{\"t\":\"heading\",\"d\":1,\"v\":\"3. Create and deploy SharePoint Framework solutions\",\"c\":[{\"t\":\"heading\",\"d\":2,\"v\":\"3.1. Tooling for SPFx development\",\"c\":[{\"t\":\"bullet_list\",\"d\":3,\"v\":\"\",\"c\":[{\"t\":\"list_item\",\"d\":4,\"v\":\"build process and tooling\"},{\"t\":\"list_item\",\"d\":4,\"v\":\"web frameworks\"},{\"t\":\"list_item\",\"d\":4,\"v\":\"code editors\"}]},{\"t\":\"heading\",\"d\":3,\"v\":\"3.1.1. Build process and tooling\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.1.2. Web frameworks\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.1.3. Code editors\"}]},{\"t\":\"heading\",\"d\":2,\"v\":\"3.2. Server-side tool comparison\"},{\"t\":\"heading\",\"d\":2,\"v\":\"3.3. Exploring the SharePoint Framework core development and build tools\",\"c\":[{\"t\":\"heading\",\"d\":3,\"v\":\"3.3.1. Node.js\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.3.2. NPM: Node Package Manager\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.3.3. Yeoman\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.3.4. Gulp\"},{\"t\":\"heading\",\"d\":3,\"v\":\"3.3.5. TypeScript\"}]},{\"t\":\"heading\",\"d\":2,\"v\":\"3.4. SharePoint Framework project structure\",\"c\":[{\"t\":\"list_item\",\"d\":3,\"v\":\".vscode: This folder contains Visual Studio Code specific files.\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"config: This folder contains configuration files used by the project's various build tasks. You'll edit these files as necessary depending on the types of components you're creating and for specific situations, such as the site to test extensions or adding references to external libraries.\"},{\"t\":\"list_item\",\"d\":3,\"v\":\"dist: This folder, created automatically when you bundle the project, contains the JavaScript bundle and manifest created by the build process tha","date":"July 8, 2020","objectID":"/2020-07-08-ms-600-extending-sharepoint/:0:0","tags":null,"title":"MS-600 Extending Sharepoint","uri":"/2020-07-08-ms-600-extending-sharepoint/"},{"categories":null,"content":"For the upcoming Dynamics 365 Finance Updates, Visual Studio 2017 and .NET runtime 4.7.2 required for PU36/10.0.12 or higher; New VMs deployed with PU36/10.0.12 or higher will have Visual Studio 2017 as well as .NET runtime 4.7.2 already installed. For your dev/test/build Tier1 VMs, Microsoft recommends just redeploying a new VM, and you will be all set! If you cannot deploy new VMs, please follow below steps to update .NET runtime, VS 2017 before installing PU36/10.0.12 or higher, this will be applied for cloud-hosted environment ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:0","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"1. Download VS Professional 2017 15.9 here and install it ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:1","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"2. The .NET runtime download is available here by clicking on the Download .NET Framework 4.7.2 Runtime and running the installation, restart required. ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:2","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"3. Go to Dynamics Lifecycle Services and download PU36/10.0.12 or any higher package which is a part of the Platform and application binary, the VSIX file is located in the DevToolsService\\Scripts folder. {:.border} You need to install Microsoft.Dynamics.Framework.Tools.Installer and then Microsoft.Dynamics.Framework.Tools.InternalDevTools. After the installation, open the VS2017 if you should see Dynamics 365 menu extension like below {:.border} ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:3","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"4. If you try to access the client before applying the package you will get the error like below in event viewer and unable to access the environment, so you need to apply an update first. AX is shutting down due to an error. Serialization version mismatch detect, make sure the runtime dlls are in sync with the deployed metadata. Version of file ‘194’. Version of dll ‘193’. {:.error} ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:4","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"5. In LCS, navigate to your cloud-hosted environment, and apply Platform and application binary package PU36/10.0.12 or higher. After completed upgrading, you will be able to access the environment client. Overall, there is no change in the compiler, metadata; this is only an update to the Visual Studio extensions and NET runtime for the tier1 VMs. ","date":"June 30, 2020","objectID":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/:0:5","tags":["Visual Studio 2017",".NET 4.7.2","PU36","app 10.0.12"],"title":"How to upgrade to Visual Studio 2017, .NET 4.7.2 for PU36/10.0.12 and higher","uri":"/2020-06-30-how-to-upgrade-to-visual-studio-2017-.net-4.7.2/"},{"categories":null,"content":"Example two: A new Forms response is submitted then Flow promts for an approval request before a new record is created in Vendors table In the last example, we created a simple Flow to create a new Vendor Account from submitted Forms responses. The process was made as simple as it could be: When a new Forms response if submitted, a new Vendor Account will be created on D365FO client. To make the process more reliable, we will now add an approval step to the Flow. It means before a new Vendor Account is created, the user will have the right to Approve or Reject the request. ","date":"June 28, 2020","objectID":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/:0:0","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 2)","uri":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/"},{"categories":null,"content":"Step 1: Add a new step to the Flow The flow that we have is like this. The old flow {:.border} We will add a step right before the new record is created. Add a new step {:.border} We will go with Approval \u003e Start and wait for an approval. Add approval request {:.border} This step will offer several types of approval in which the most common ones are All users must approve or First approve/reject from any user. To make it simple, we will go with First approval because in this example, we will have only one user. As straightforward as they seem, the fields explain themselves. We will start an approval request, set a title for it and assign it to a user (only users in the same organisation as you). Single approval {:.border} Note 2-1 Almost all fields including Title, Details, etc. are fully customisable by using Dynamic content. The flow now will look like this. Revised flow {:.border} ","date":"June 28, 2020","objectID":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/:0:1","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 2)","uri":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/"},{"categories":null,"content":"Step 2: Testing out Trigger a test run of the flow. Test run {:.border} Test run triggered {:.border} The test run is ready, waiting for the input from MS Forms. Test run ready {:.border} Submit a new response. Form new response {:.border} The flow will run. The process will show that an approval is being waited from the assigned user. Waiting for an approval {:.border} An approval request will be sent to the mailbox of the assigned user. That user can check the request in Office.com \u003e Outlook. Approval request {:.border} Upon approval, the flow will finish its pending step and a new record will be created. Flow finishes {:.border} Example three: From the created record in Vendors table, add related records in other tables In the last example, we added an Approval step to the Flow which will allow users to give Approve or Reject action toward the request coming from the Form. We can actually utilise the Flow one step further: To create additional records on different tables that might depend on the created record in VendTable. To make it easier to understand, the process is like this: Create a new Vendor Account by using input from the Form. Create a new Bank Account with the Bank Account ID exactly similar to the Vendor Account. Add some contact details to the Vendor Account. Which entities should we target to? They are: For Vendor Bank Account: VendorBankAccounts For Vendor Contact Details: PartyContacts You can play around in Visual Studio to get used to looking for an Entity that might fulfil the requirements of your intergration. Check out the next part of this article to get some quick tips into that. Assuming that we now have a Flow as we configured in the last two examples, we can add some more steps like these underneath. ","date":"June 28, 2020","objectID":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/:0:2","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 2)","uri":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/"},{"categories":null,"content":"Step 1: Add a new step to add a new record to VendorBankAccounts and PartyContacts Given the case that we had a Vendor Account and Bank Account for that Vendor Account, the records would be like this. Relation in SSMS The relation should be: VendTable.AccountNum = VendBankAccount.VendAccount On the client, the information should be illustrated like this. Vendor Bank Account And, when checking the Bank Account details, we would find. Vendor Bank Details Now, to do so, we will add a new step right after the creation of VendTable record. A new step Instance = Environment URL (same as any other steps) Entity name = VendorBankAccounts (check my post about good tips with Visual Studio to know how to find the Data Entity) Supplier account = Supplier account from last step Bank account= Supplier account from last step (Because I would like to have same Vendor Account and Bank Account) When saying “from the last step”, I meant this. Selecting Dynamic Content from former steps In MS FLow, any steps that are already executed will have outputs. We, in this step, are taking the Supplier Account from the last step of creating a new record in VendTable . This dynamic content was generated when the new record is created. Note 3-1 Keep in mind that if the last step is not “Creating a new record”, chance is that you cannot take the output from it because there’s simply none. Click on Show advanced options so we can add more information to the Vendor Bank Account. Select Show advanced options Add more details to the bank account: Name = Bank account name chosen from the Form using Dynamic Content (we don’t want to copy any more values from the VendTable record - we actually will specify a bank account name when composing a response on the Form) Bank account number = Bank account number chosen from the Form using Dynamic Content Add more details to bank account We finished with Vendor Bank Account. We will do just the same with the record in PartyContacts. Party ID = Party ID from VendTable record Contact number/address = Email from the Form (in this case, I would like to add an email address - it is totally up to you to opt to add phone number, Skype, Twitter and some other contact detail that D365FO is supporting) Purpose = I am “hard-coding” this \"Business\" (the supported purpose of Contact can be found on Vendor Card on D356FO client - this purpose should mainly be used when sending emails, i.e. D365FO want to send Purchase Order Confirmation to any email addresses with purpose \"Invoice\") Vendor Contact Details ","date":"June 28, 2020","objectID":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/:0:3","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 2)","uri":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/"},{"categories":null,"content":"Step 2: Testing out Form input. Company details Bank details Contact details Results on D365FO client. Contact details Bank account Bank account details There you go, simple integration between MS Forms, MS Automate and D365FO client. I am seeing that Microsoft is improving such by adding more actions on MS Automate. I believe we will be able to do many more jobs with the built-in utilities of MS Automate. How to determine the Data Entity that should be used in the Power Automate The names of the target entity on D365FO client and being found in Power Automate should be different. You can always find them out by testing several import/export but, with the help of Visual Studio, you will be able to save a lot of time. This, however, requires a certain extent of experience working with data integration on D365FO. Given the case that we would like to import data to All Vendors, we will start our search in Workspaces \u003e Data Management \u003e Data Entities. Apply several filters here and there, and looking for potential ones that we usually do, we will finally end our search at the VendVendorV2Entity Data Entities {:.border} Making our way to Visual Studio, it is not a difficult task for us to find out the Entity. VendVendorV2Entity {:.border} Check out the Properties, we will need to get details in the Public group. Properties {:.border} In Public: Is Public: If it is Yes, the entity can be found in Power Automate; otherwise, No. Public Collection Name: Entity name on Power Automate. The information should be displayed here: Info on Automate {:.border} Furthermore, by checking the Entity’s fields, we can get the information of mapping between the Entity and the physical table VendTable. Entity fields {:.border} Give yourself some time to play around between MS Forms, MS Automate and Visual Studio. You will finally see the relations between them. ","date":"June 28, 2020","objectID":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/:0:4","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 2)","uri":"/2020-06-28-dynamics-365-finops-data-integration-using-microsoft-forms-part-2/"},{"categories":null,"content":"With any D365FO users, Data Management workspace and Data Entities should have become one of the most used and well-known tools in the system. We all agree how powerful such integration framework is, especially when it comes to a large number of records that we would need to import into different tables. The classic method that we have been utilizing is to include all source data in a single (or multiple, much depending on the purpose and order of data integration) Excel sheet, trigger an import execution, pass any validation layers that present and ultimately have the data available on D365FO. Now, I would like to propose another method that might come useful in some circumstances: Using Microsoft Forms. The trio {:.border} When This method should be at its finest when you are planning to outsource the input to any external users. Imagine you are a company who is using D365FO to leverage your daily work. You now want to add many local vendors to your system in form of new Vendor Accounts. It is fine to collect all information from them (i.e. Vendor Company’s name, their address, their contact details and so on), put everything in an Excel sheet and import it. Yet, chance is that it would take (a lot of) time for you to finish this task. You would then be very likely to try coming up with some methods to cut down time for it. That demand should raise two questions: How can we let the vendors enter their information by themselves? And, how can we then have all such information in our system? What What should be needed? Microsoft Forms: To establish a process in which you will publish a prepared form. Any vendors out there will have the access to it and they can fill any fields on in. Microsoft Power Automate aka. Microsoft Flow: To set up a protocol to push the input information (form responses) to the target (D365FO Data Entities). (Optional) Access to Visual Studio on your virtual machine: To help you determine the target Data Entities more easily and efficiently. How The flow should go like this. The Biggest FLow {:.border} To make it short, when a response is submitted in Microsoft Form, the Flow in MS Power Automate is triggered automatically. An approval request will be sent to your Outlook mailbox and if it is approved, a new record will be created in the target data entity. Let go through three examples in the next articles in the series (from the simplest to a more complicated) so we will see the logic behind this process. As easy as it sounds, in this example, we will create a new Vendor Account from Microsoft Forms with only a small number of fields being populate. Note To help simplify the example, the number of fields is minimised. In other words, we will import just enough fields so the new Vendor Account is valid. Given that, only Vendor Account and Vendor Group are chosen to be imported. ","date":"May 24, 2020","objectID":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/:0:0","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 1)","uri":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/"},{"categories":null,"content":"Step 1: Create a MS Form To do so, we will access Microsoft Forms and create a new form. To make the new form usable, we will create two questions asking for inputs of Vendor Account and Vendor Group. Example 1 Form {:.border} Note all information on the form is customisable. Note 1-1 We can make the questions…any questions that suit the purpose of the form. Say, in reality, the question can be \"What is your company's name?\" if you want to send this form to any external vendor users. The question does not change the usability of the returned response’s value. It can still be mapped to VendAccount not matter what the question is. Note 1-2 The second question is being set in form of a Choice question. The given choices should match with available Vendor Group values found on your D365FO client. If this question is a Text one, chance is that its response might not match with any available Vendor Group values, thus, will return an error during Flow runtime. Vendor Groups can be found under Account Payable \u003e Vendors \u003e Vendor Groups. In this example, TopVendor and Others are two available Vendor Groups in my D365FO client. Vendor Groups {:.border} ","date":"May 24, 2020","objectID":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/:1:0","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 1)","uri":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/"},{"categories":null,"content":"Step 2: Create a MS Flow To do so, we will access Microsoft Power Automate and create a new flow. We will go with an Automated one in this case. Automated flow {:.border} Search for form and choose the trigger When a new response is submitted. Hit Create to create a new flow. Form trigger {:.border} Choose the form that we just created using the dropdown list. Choose form {:.border} Press New step, search for form and go with Get response details. New step: Get response details {:.border} In the new step, choose the Form ID. As soon as we move the cursor to the Response ID field, the FLow will suggest the Dynamics content that we can use. In this case, there should be only one dynamic content, which is List of response notifications Response ID. We will go with it by choosing it. Get response details {:.border} After doing so, the flow should look like this. Form done {:.border} Now, the reponse details will be sent from the Form to the Flow when a new response is submitted. Next, we will set up the step to create a new Vendor Account. Create a new step, search for dynamics and go with Dynamics 365 for Finance and Operations. Dynamics 365 FinOps {:.border} Choose Create record action. Create record action {:.border} Choose the Dynamics 365 FinOps Instance from the dropdown list. If your client does not appear here, choose Enter custom value. For privacy, environments' name will be censored in our example. Set D365FO instance {:.border} The Instance should be the link to your D365FO client. Set Entity name VendorsV2. Set Instance and Entity {:.border} Note 1-3 Later in this series, we will see how to find the exact Entity name using Visual Studio. Also, we will see in which condition, the Entity can be used in Power Automate. Populate the fields that we want to import. In this example, we will populate only 3 fields: Group (VendorGroupID), Company (DataAreaId) and Supplier Account (VendorAccountNumber). Dynamic content will be suggested automatically when the cursor is placed in each field. Map Form fields with Automate fields {:.border} We can map Form fields with Automate fields or hardcode in these fields: Group = Response of What is the Vendor Group? question. Company = (hardcode) usmf. Supplier Account = Response of What is the Vendor Account? question. Name = Supplier Account = Response of What is the Vendor Account? question (Show advanced option on the Flow to find the field Name (VendorOrganisationName)). These fields should be required when creating a new Vendor Account on D365FO client. Map Form fields with Automate fields {:.border} We are done here with the set up. ","date":"May 24, 2020","objectID":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/:2:0","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 1)","uri":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/"},{"categories":null,"content":"Step 3: Testing out On Forms, choose the form that we just created, click on Preview so we can submit a form response. Map Form fields with Automate fields {:.border} Check out All Vendors (VendTableListPage) on the client to find a new Vendor Account is created. Map Form fields with Automate fields {:.border} Note 1-4 Use Test option in Power Automate to follow the process of the Flow. This, in other words, is so-called \"Run Flow with Debug\" option. ","date":"May 24, 2020","objectID":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/:3:0","tags":["Microsoft Forms","Power Automate","PowerApps","Data Entities","integration framework"],"title":"Dynamics 365 FinOps Data Integration using Microsoft Forms (Part 1)","uri":"/2020-05-24-dynamics-365-finops-data-integration-using-microsoft-forms-part-1/"},{"categories":null,"content":"You will got an error like this when doing Database Synchronization after changing the data type of the field on the table: InvalidOperationException: Table … : Converting Field ‘..’ of Type ‘..’ to ‘..’ is not support. Please drop the original field, sync the table and add new field with same name if needed. {:.error} Solution: Drop the table and delete references from SQLDictionary DROPTABLEAXDB.dbo.NAMEOFTABLEDELETEFROMAXDB.dbo.SQLDICTIONARYWHERETABLEIDIN(SELECTTABLEIDFROMSQLDICTIONARYWHERENAME='NAMEOFTABLE'ANDFIELDID=0) Restart IIS In VS 2015, run DB sync again. Thank you for reading. ","date":"May 10, 2020","objectID":"/2020-05-10-database-sync-after-data-type-on-field-has-been-changed/:0:0","tags":["DB sync","Dynamics 365 finance and operations","InvalidOperationException"],"title":"Database Sync after data type on field has been changed","uri":"/2020-05-10-database-sync-after-data-type-on-field-has-been-changed/"},{"categories":null,"content":"1. Download Dynamics 365 finance and operations VHD files Go to the LCS main page and select Shared asset library or go to Shared Asset Library. Select the asset type Downloadable VHD. Find the VHD you are looking for based on the desired Finance and Operation version. The VHD is divided into multiple file parts that you need to download. For example, the asset files that start with “VHD - 10.0.5” are the different files you need in order to install version 10.0.5. Download all files (parts) associated with the desired VHD to a local folder. After the download is complete, run the executable file that you downloaded, accept the software license agreement, and choose a file path to extract the VHD to. This creates a local VHD file that you can use to run a local virtual machine. Sign in to the VM by using the following credentials: User name: Administrator Password: pass@word1 Provision the administrator user. ","date":"April 6, 2020","objectID":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/:1:0","tags":["onebox vhd","Dynamics 365 finance and operations","upgrade","LCS","OneBox"],"title":"Getting onebox VHD Dynamics 365 finance and operations virtual machine","uri":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/"},{"categories":null,"content":"2. Rename VM Rename and restart the machine before you start development or connect to Azure DevOps. Update the server name in SQL Server To be able to login, Start SQL Server with administrator or using the user axdbadmin has password AOSWebSite@12 Run following query sp_dropserver[old_name]sp_addserver[new_name],local Restart SQL service Open Reporting Services Configuration Manager for SQL Server 2016, then Select Database, select Change Database, and use the new server name. Update the Azure Storage Emulator From the Start menu, open Microsoft Azure Storage Emulator - v4.0, and run the following commands. AzureStorageEmulator.exe start If you got an error Port conflict with existing application, please check this post. This command verifies that the emulator is running. AzureStorageEmulator.exe status Update the server name AzureStorageEmulator.exe init -server new_name For more information about Azure storage emulator please follow https://docs.microsoft.com/en-us/azure/storage/common/storage-use-emulator Update financial reporting Open a Microsoft Windows PowerShell command window as an admin, and run the following command. This command contains the default passwords that might have to be updated. Be sure to replace new_name with the new name. cd \u003cupdate folder\u003e\\MROneBox\\Scripts\\Update .\\ConfigureMRDatabase.ps1 -NewAosDatabaseName AxDB -NewAosDatabaseServerName new_name -NewMRDatabaseName ManagementReporter -NewAxAdminUserPassword AOSWebSite@123 -NewMRAdminUserName MRUser -NewMRAdminUserPassword MRWebSite@123 -NewMRRuntimeUserName MRUSer -NewMRRuntimeUserPassword MRWebSite@123 -NewAxMRRuntimeUserName MRUser -NewAxMRRuntimeUserPassword MRWebSite@123 ","date":"April 6, 2020","objectID":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/:2:0","tags":["onebox vhd","Dynamics 365 finance and operations","upgrade","LCS","OneBox"],"title":"Getting onebox VHD Dynamics 365 finance and operations virtual machine","uri":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/"},{"categories":null,"content":"3. Location of packages, source code, and other AOS configurations On a VM, you can find most of the application configuration by opening the web.config file of AOSWebApplication. Start IIS. Go to Sites \u003e AOSWebApplication. Right-click, and then click Explore to open File Explorer. Open the web.config file in Notepad or another text editor. The following keys are of interest to many developers and administrators: Aos.MetadataDirectory – This key points to the location of the packages folder that contains platform and application binaries, and also source code. (Source code is available only in development environments.) Typical values are: c:\\packages, c:\\AosServicePackagesLocalDirectory, and J:AosServicePackagesLocalDirectory. DataAccess.Database – This key holds the name of the database. Aos.AppRoot – This key points to the root folder of the Application Object Server (AOS) web application. ","date":"April 6, 2020","objectID":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/:3:0","tags":["onebox vhd","Dynamics 365 finance and operations","upgrade","LCS","OneBox"],"title":"Getting onebox VHD Dynamics 365 finance and operations virtual machine","uri":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/"},{"categories":null,"content":"4. Redeploying or restarting the runtime on the VM To restart the local runtime and redeploy all the packages, follow these steps. Open File Explorer, and go to C:\\CustomerServiceUnit. Right-click AOSDeploy.cmd, and then click Run as administrator. This process might take a while. The process is completed when the cmd.exe window closes. If you just want to restart AOS (without redeploying the runtime), run iisreset from an administrator Command Prompt window, or restart AOSWebApplication from IIS. ","date":"April 6, 2020","objectID":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/:4:0","tags":["onebox vhd","Dynamics 365 finance and operations","upgrade","LCS","OneBox"],"title":"Getting onebox VHD Dynamics 365 finance and operations virtual machine","uri":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/"},{"categories":null,"content":"5. Update to the latest version Please check this document https://docs.microsoft.com/en-us/dynamics365/fin-ops-core/dev-itpro/deployment/install-deployable-package That’s it, thank you for reading. ","date":"April 6, 2020","objectID":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/:5:0","tags":["onebox vhd","Dynamics 365 finance and operations","upgrade","LCS","OneBox"],"title":"Getting onebox VHD Dynamics 365 finance and operations virtual machine","uri":"/2020-04-06-getting-onebox-vhd-dynamics-365-finance-and-operations-virtual-machine/"},{"categories":null,"content":"The Microsoft Azure storage emulator is a tool that emulates the Azure Blob, Queue, and Table services for local development purposes. You can test your application against the storage services locally without creating an Azure subscription or incurring any costs. When you’re satisfied with how your application is working in the emulator, switch to using an Azure storage account in the cloud. In Dynamics 365 finance and operations onebox environment, we also use Microsoft Azure Storage Emulator for same purposes. There is a common problem when you try to start its service or using Data entity Import/Export {:.border} Port conflict with existing application {:.error} ","date":"April 5, 2020","objectID":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/:0:0","tags":["Azure Storage Emulator","Dynamics 365 finance and operations","Port","OneBox"],"title":"Azure Storage Emulator 'Port conflict with existing application', Dynamics 365 finance and operations","uri":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/"},{"categories":null,"content":"Reason By default, Azure storage emulator is using port number 10000, 10001, 10002 for Blob, Queue and Table services respectively. And there is a progress/system takes those ports already, so you are not able to start its service. We can simply use this command in CMD to see which one has conflict netstat -p tcp -ano | findstr :10001 {:.border} The process ID 4 is currently taking port 10001. ","date":"April 5, 2020","objectID":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/:1:0","tags":["Azure Storage Emulator","Dynamics 365 finance and operations","Port","OneBox"],"title":"Azure Storage Emulator 'Port conflict with existing application', Dynamics 365 finance and operations","uri":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/"},{"categories":null,"content":"Resolution You can either terminate the conflict program or change the default port for Azure Storage Emulator. ","date":"April 5, 2020","objectID":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/:2:0","tags":["Azure Storage Emulator","Dynamics 365 finance and operations","Port","OneBox"],"title":"Azure Storage Emulator 'Port conflict with existing application', Dynamics 365 finance and operations","uri":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/"},{"categories":null,"content":"To determine the conflict program we can use this command in CMD Run following command to check which application/process has the same port, then simply go to task manager and terminate it. tasklist /fi \"pid eq 4\" {:.border} ","date":"April 5, 2020","objectID":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/:2:1","tags":["Azure Storage Emulator","Dynamics 365 finance and operations","Port","OneBox"],"title":"Azure Storage Emulator 'Port conflict with existing application', Dynamics 365 finance and operations","uri":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/"},{"categories":null,"content":"To change the default port for Azure storage Emulator Go to your storage emulator default installation folder, which is located at C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\Storage Emulator, open the AzureStorageEmulator.exe.config by notepad and edit the port number to different number {:.border} When done, try to start its service again using AzureStorageEmulator.exe start {:.border} Thank you for reading. ","date":"April 5, 2020","objectID":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/:2:2","tags":["Azure Storage Emulator","Dynamics 365 finance and operations","Port","OneBox"],"title":"Azure Storage Emulator 'Port conflict with existing application', Dynamics 365 finance and operations","uri":"/2020-04-05-azure-storage-emulator-port-conflict-with-existing-application/"},{"categories":null,"content":"class MaxGeneratePO { public static void main(Args _args) { int i = 0; // number of purchase orders NumberSeq numberSeq; PurchTable purchTable; PurchLine purchLine; InventDim inventDim; while (i \u003c= 3) { ttsBegin; MaxGeneratePO createPO = new MaxGeneratePO(); numberSeq = NumberSeq::newGetNum(PurchParameters::numRefPurchId()); numberSeq.used(); purchTable.PurchId = numberSeq.num(); purchTable.initValue(); purchTable.initFromVendTable(VendTable::find('US-101')); if (!purchTable.validateWrite()) { throw Exception::Error; } purchTable.insert(); inventDim.clear(); purchLine.clear(); purchLine.initValue(); purchLine.PurchId = purchTable.PurchId; purchLine.ItemId = 'D0002'; inventDim.InventSiteId = \"1\"; inventDim.InventLocationId = \"11\"; purchLine.InventDimId=InventDim::findOrCreate(inventDim).inventDimId ; purchLine.createLine(true, true, true, true, true, true); purchLine.PurchQty = 5; purchLine.PurchUnit = \"ea\"; purchLine.PurchPrice = createPO.randomAmount(); // get random amount nubmer purchLine.LineAmount = purchLine.calcLineAmount(); purchLine.update(); //PO confirm PurchFormLetter purchFormLetter; PurchFormLetter purchFormLetterPack; purchFormLetter = PurchFormLetter::construct(DocumentStatus::PurchaseOrder); purchFormLetter.update(purchTable, strFmt(\"ConNum_%1\", purchTable.PurchId), systemDateGet(), PurchUpdate::All, AccountOrder::None, NoYes::No, NoYes::no); //Product receipt createPO.proceed(purchTable.PurchId, purchLine.ItemId,purchLine.InventDimId,purchLine.PurchQty,strFmt(\"RptNum_%1\", purchTable.PurchId)); //Post PO createPO.postPOInvoice(purchTable.PurchId, strFmt(\"RptNum_%1\", purchTable.PurchId)); info(strFmt(\"Purchase order '%1' has been created\", purchTable.PurchId)); ttsCommit; i++; } } public boolean proceed(PurchId _purchId, ItemId _itemId,inventDimId _inventDimId, PurchQty _qty, PackingSlipId _productReceiptNumber) { return this.generateProductReceipt(_purchId, this.addToPurchLineList(_purchId, _itemId, _inventDimId, _qty), _productReceiptNumber); } public boolean generateProductReceipt(PurchId _purchId, List _purchLineList, PackingSlipId _productReceiptNumber) { boolean ret = true; PurchFormLetter purchFromLetter; PurchTable purchTable = PurchTable::find(_purchId); try { ttsbegin; purchFromLetter = PurchFormLetter::construct(DocumentStatus::PackingSlip); purchFromLetter.createFromLines(true); purchFromLetter.parmLineList(_purchLineList.pack()); purchFromLetter.update(purchTable, _productReceiptNumber, DateTimeUtil::getToday(DateTimeUtil::getUserPreferredTimeZone()), PurchUpdate::All); ttscommit; } catch { ret = false; } return ret; } public List addToPurchLineList(PurchId _purchId, ItemId _itemId,inventDimId _inventDimId, PurchQty _qty) { List purchLineList = new List(Types::Record); PurchLine purchLine = PurchLine::findItemIdInventDimId(_purchId, _itemId, _inventDimId); if(purchLine \u0026\u0026 _qty \u003e 0) { purchLine.PurchReceivedNow = _qty; purchline.modifiedField(fieldNum(PurchLine, PurchReceivedNow)); purchLineList.addEnd(purchLine); } return purchLineList; } public void postPOInvoice(PurchId purchId, PackingSlipId packingSlipId) { TmpFrmVirtual tmpFrmVirtualVend; PurchFormLetter_Invoice purchFormLetter; VendPackingSlipJour vendPackingSlipJour; SysQueryRun chooseLinesQuery; SysQueryRun chooseLinesPendingInvoiceQuery; container conTmpFrmVirtual; List selectedList = new List(Types::Record); select firstonly vendPackingSlipJour where vendPackingSlipJour.PurchId == purchId \u0026\u0026 vendPackingSlipJour.PackingSlipId == packingSlipId; if (vendPackingSlipJour) { tmpFrmVirtualVend.clear(); tmpFrmVirtualVend.TableNum = vendPackingSlipJour.TableId; tmpFrmVirtualVend.RecordNo = vendPackingSlipJour.RecId; tmpFrmVirtualVend.NoYes = NoYes::Yes; tmpFrmVirtualVend.Id = vendPackingSlipJour.PurchId; tmpFrmVirtualVend.insert(); } chooseLinesQuery = new SysQueryRun(queryStr(PurchUpdate)); chooseLinesQuery.query().addDataSource(tableNum(VendInvoiceInfoTable)).enabled(false); // chooseLinesPendingInvoiceQuery needs to be initialized, although it ","date":"January 25, 2020","objectID":"/2020-01-25-create-po-confirm-receipt-post/:0:0","tags":["Create Purchase order X++","Coding","integration"],"title":"Create Purchase Orders - Confirm - Product receipt - Post PO using X++","uri":"/2020-01-25-create-po-confirm-receipt-post/"},{"categories":null,"content":"When you consume a custom data entity, you get an error errorSystem.ArgumentOutOfRangeException : Length cannot be less than zero” and it works fine for standard data entities. {:.error} {:.border} The reason is the temporary XML file where the metadata stored which mismatches with the metadata from https://\u003cyourenvironment\u003e.cloudax.dynamics.com/data/$metadata You can follow this post to understand how to create the XML file. If you try to regenerate the metadata by saving the ODataClient.tt file, the XML will be accumulated, and the error keeps happening. The resolution here is simply delete it and regenerate metadata again by saving the ODataClient.tt file {:.border} Thank you for reading. ","date":"December 17, 2019","objectID":"/2019-12-17-dynamics-365-finance-and-operations-odata-consuming-length-cannot-be-less-than-zero/:0:0","tags":["Length cannot be less than zero","OData","BATCH","integration",".NET"],"title":"Dynamics 365 finance and operations ODATA consuming - Length cannot be less than zero","uri":"/2019-12-17-dynamics-365-finance-and-operations-odata-consuming-length-cannot-be-less-than-zero/"},{"categories":null,"content":"In this article, we will go through how to enable Power BI embedded in Dynamics 365 finance and operations version 10 in a cloud-hosted environment (customer managed). From the previous version of FinOps, Power BI embedded uses workspace collections at Azure to display the report, since the workspace collections have been deprecated, Microsoft also disables power BI embedded in cloud-hosted environments. You can only enable Power BI embedded in multiple boxes environments like UAT and production. ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:0:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"1. Create workspace collections Although the workspace collections have been deprecated, it does not show in the Azure portal and you could not create it by using the Azure portal, but you can create and manage by using Azure CLI. Open PowerShell and run following // Allow policy set-executionpolicy remotesigned //Install AzureRM Install-Module -Name AzureRM -AllowClobber // Login to Azure using credentials Login-AzureRmAccount // select the subscription ID Select-AzureRmSubscription -SubscriptionId $subscriptionId $ResourceGroupName = “MaxWorkspaceCollections” $Location = \"Southeast Asia\" // Create workspace collections New-AzPowerBIWorkspaceCollection -ResourceGroupName $ResourceGroupName -WorkspaceCollectionName $WorkSpaceCollectionName -Location $Location // Obtain the access keys Get-AzPowerBIWorkspaceCollection -ResourceGroupName $ResourceGroupName -name \"\u003cyourWorkspacename\u003e\" ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:1:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"2. Create AxWD Azure SQL Database We must use the Azure SQL Database for the AxDW in Dynamics 365 finance and operations cloud-hosted environment. Please follow this document to create Azure SQL DB. We need at least 5 GB storage for Database, for Pricing tier, I will recommend using from S1, and name the database AxDB This is my DB property {:.border} I’m using Premium tier because I want to use the Columnstore Clustered indexes in Database; it helps performance a little bit faster. Once you have the Azure SQL Database, we can use SSMS to connect to the database and create a user for that DB. You need to get the user and password information in LCS, where the cloud-hosted provisioned. {:.border} UseMasterCREATELOGINaxdwadminWITHPASSWORD='';CREATELOGINaxdwruntimeuserWITHPASSWORD='';UseAxDwCREATEUSERaxdwadminFROMLOGINaxdwadmin;CREATEUSERaxdwruntimeuserFROMLOGINaxdwruntimeuser;ALTERROLEdb_ownerADDMEMBERaxdwadmin;ALTERROLEdb_datareaderADDMEMBERaxdwruntimeuser;","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:2:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"3. Configuring to enable Analytical Workspaces and Reports What you are having now Power BI Embedded Service details from step 1 Workspace Collection Name: The name of the Workspace Collection created when deploying the Power BI Embedded Service Access Key1: The secret key #1 used to access the Power BI Embedded service Access Key2: The secret key #2 used to access the Power BI Embedded service Entity Store Database Service details from step 2 Database name: AxDW Server name: Azure SQL Server name (*.database.windows.net) Server admin login: Username supplied in the SQL Server settings Password: Account password supplied when configuring SQL Server Run Notepad in administrator mode, open web.config from K:\\AOSService\\webroot in Dynamics 365 for finance and operations environment. Update the configuration settings: \u003cadd key=\"BiReporting.DW\" value=\"[Database name]\" /\u003e \u003cadd key=\"BiReporting.DWServer\" value=\"[Server name]\" /\u003e \u003cadd key=\"BiReporting.DWRuntimeUser\" value=\"[Server Admin login]\" /\u003e \u003cadd key=\"BiReporting.DWRuntimePwd\" value=\"[Password]\" /\u003e Update the Power BI Embedded Service configuration settings: \u003cadd key=\"PowerBIEmbedded.AccessKey\" value=\"[Access Key1]\" /\u003e \u003cadd key=\"PowerBIEmbedded.AccessKey2\" value=\"[Access Key2]\" /\u003e \u003cadd key=\"PowerBIEmbedded.ApiUrl\" value=\"https://api.powerbi.com\" /\u003e \u003cadd key=\"PowerBIEmbedded.IsPowerBIEmbeddedEnabled\" value=\"true\" /\u003e \u003cadd key=\"PowerBIEmbedded.WorkspaceCollectionName\" value=\"[Workspace Collection Name]\" /\u003e After that, you need to restart IIS and Dynamics 365 for finance and operations batch service ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:3:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"4. Refresh data entity store to AxDW In Dynamics 365 for finance and operations, navigate to System administration \u003e Setup \u003e Entity Store, select all the entity store, and click refresh. Allow this process to complete in the background (~5 - 10mins). You can monitor the status of the background process using the Batch jobs. Once the Progress is made, you can check the event message in the same form to make sure the refreshing working properly {:.border} ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:4:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"5. PowerBI configuration (this is optional) Configuring power BI for the workspace; please follow the document here This is what you should have after the setup {:.border} ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:5:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"Check the result If you want to check the result, go to Workspaces \u003e Customer credit and collections \u003e Analytics all companies {:.border} Thank you for reading. ","date":"December 17, 2019","objectID":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/:6:0","tags":["Power BI Embedded","Reports","cloud hosted","integration","Workspaces collections","AXDW","Entity Store","Azure SQL Database"],"title":"Enable Power BI Embedded in cloud hosted Dynamics 365 finance and operations 8.0 +","uri":"/2019-12-18-enable-power-bi-embedded-in-cloud-hosted-dynamics-365-finance-and-operations-8.0-/"},{"categories":null,"content":"1. Authentication We need an authentication to connect Dynamics 365 finance and operations from .Net application by using service principal. How to create an app registration in Azure https://docs.microsoft.com/en-us/azure/active-directory/develop/app-registrations-training-guide-for-app-registrations-legacy-users You also need to add required permissions for Dynamics 365 finance and operations, please follow https://docs.microsoft.com/en-us/dynamics365/fin-ops-core/dev-itpro/data-entities/services-home-page#register-a-web-application-with-aad This is what you should have {:.border} 2. Register your external application ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:0","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"a. In the FinOps application, go to System administration \u003e Setup \u003e Azure Active Directory applications. ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:1","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"b. Select New. ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:2","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"c. Fill in the fields for the new record: In the Client Id field, enter the application ID that you registered in Azure AD. In the Name field, enter a name for the application. In the User ID field, select an appropriate service account user ID. For this example, we have selected the Admin user. However, as a better practice, you should provision a dedicated service account that has the correct permissions for the operations that must be performed. When you’ve finished, select Save. You’ve now finished setting up the prerequisites. After the external application retrieves an Azure AD authentication token, it should now be able to use the token in an authorization HTTP header to make subsequent service calls via OData or SOAP, for example. 3. OData client configuration Download the project here https://github.com/microsoft/Dynamics-AX-Integration Open ServiceSamples solution. We cannot use existing proxies and classes, so I need to regenerate them again. Under ODataUtility project, delete ODataClient.tt and ODataClient.ttinclude. To regenerate Odata client, right click on ODataUtility project \u003e Add \u003e New item, search for OData in Online and rename it to ODataClient.tt. Open ODataClient.tt, in MetadataDocumentUri add “https://.cloudax.dynamics.com/data/$metadata” If you save the ODataClient.tt file, it will generate Odata proxies and classes. From PU12 onward, there are so many entities so you will get an error after compiling Combined length of user strings used by the program exceeds allowed limit. Try to decrease use of string literals. {:.error} There are 2 ways to fix it ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:3","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"a. Using temporary file The simplest way to fix is add TempFilePath, ensure that you have write permission for this path, this is what you got {:.border} Save the ODataClient.tt and there will be Test1.xml file created to store metadata, there should be a bug while generating the xml file, one more step you need to do is replace the double quote to single quote (a global replace of \"\" with \" ), and this is what you have {:.border} You can build the project without problem. ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:4","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"b. Remove unused entities Another work-around that works too, edit the ODataClient.ttinclude so that it parses only some of the entities that you want to use, this reducing the error. For instance, change the following foreach statement Original code: {% highlight csharp %} foreach (IEdmEntitySet entitySet in container.EntitySets()) { IEdmEntityType entitySetElementType = entitySet.EntityType(); string entitySetElementTypeName = GetElementTypeName(entitySetElementType, container); string camelCaseEntitySetName = entitySet.Name;\rif (this.context.EnableNamingAlias)\r{\rcamelCaseEntitySetName = Customization.CustomizeNaming(camelCaseEntitySetName);\r}\r } {% endhighlight %} Modified code: {% highlight csharp %} foreach (IEdmEntitySet entitySet in container.EntitySets()) { IEdmEntityType entitySetElementType = entitySet.EntityType(); string entitySetElementTypeName = GetElementTypeName(entitySetElementType, container); string camelCaseEntitySetName = entitySet.Name;\r//start of manual fix //only process entity names that containin a specific string, to reduce the string size\rif (((camelCaseEntitySetName.Contains(\"CUST\")) || (camelCaseEntitySetName.Contains(\"VEND\"))) || (camelCaseEntitySetName.Contains(\"SALES\")))\r{\r// emd of manual fix\rif (this.context.EnableNamingAlias)\r{\rcamelCaseEntitySetName = Customization.CustomizeNaming(camelCaseEntitySetName);\r}\r}\r } {% endhighlight %} 4. Authentication configuration Under AuthenticationUtility project, you need to modify ClientConfiguration.cs follow, you can get all related information for the first step. {:.border} From now, you can freely test the integrations under ODataConsoleApplication project. If you are testing with a custom data entity and you get this error System.ArgumentOutOfRangeException : Length cannot be less than zero. {:.error} Please check this post. Thank you for reading. ","date":"December 16, 2019","objectID":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/:0:5","tags":["Postman","OData","BATCH","integration",".NET"],"title":"Consuming Dynamics 365 Finance and Operations OData services from .NET","uri":"/2019-12-16-consuming-dynamics-365-finance-and-operations-odata-services-from-net/"},{"categories":null,"content":"In Dynamics 365 finance and operations, Business events provide a mechanism that lets external systems receive notifications from FinOps applications. In this way, the systems can perform business actions in response to business events. There are 3 types of business events: Application business events, Workflow business events, and Alerts as business events. You can also implement a new business event. Business events can be consumed using Microsoft Flow and Azure messaging services, and we use endpoint to manage the destinations for sending business events to, Microsoft supports many endpoints: Azure Service Bus Queue, Azure Service Bus Topic, Azure Event Grid, Azure Event Hub, HTTPS, Microsoft Flow. In this article I will show how to send business event to HTTPs endpoint that leveraging on Azure functions. The scenario: Once a free text invoice is posted, Business event will be triggered and send messages to the HTTPs endpoint. ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:0:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"1. HTTPs and Azure function Ideally, I will create a new Azure function which has HTTPs endpoint to subscribe the business events in FinOps. To create Azure function please follow this https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-first-azure-function Here is the simple line of code {% highlight csharp %} using System.Net; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Primitives; using Newtonsoft.Json; public static async Task Run(HttpRequest req, ILogger log) { log.LogInformation(“Dynamics 365 finance and operations notifications”); string requestBody = await new StreamReader(req.Body).ReadToEndAsync(); log.LogInformation(requestBody); return (ActionResult)new OkObjectResult($“Hello world”); } {% endhighlight %} This basically listens the JSON messages from Business events and display the Json message at Console. From the Azure function you can get the HTTPs endpoint, save it for later reference. {:.border} ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:1:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"2. Application registration int AAD We need an application to authenticate with FinOps and Azure function HTTPs. Go to Azure portal \u003e AAD \u003e App registrations \u003e New registration {:.border} Name of the application. Depend on you have multitenant or not Dynamics 365 finance and operations URL ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:2:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"API Permissions Go to the newly created application \u003e API permissions and adding permission as below {:.border} ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:2:1","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"Secrets Go to Certificates \u0026 secrets menu item and create a new client secret {:.border} After this you will have Application Id and Application Secret, save it for later. ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:2:2","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"3. Key Vaults In Azure portal create a new keyVault to store the HTTPs endpoint URL information {:.border} ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:3:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"Access policy Click next to create access policy (you also can set up this later after creating Key Vault) {:.border} Select all the permissions in Key, Secret and Certificate, In select principal choose the application you have created before. {:.border} ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:3:1","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"Key Vault secret Go to the newly created Key vault \u003e secrets \u003e generate a new one {:.border} Value is the endpoint URL for D365 to call the one we got from the first step. After this step you will have the Key vault DNS name https://maxfokeyvault.vault.azure.net/ and Key Vault secret name D365VaultSecretName That information will be needed for Business events configuration in Dynamics 365 finance and operations ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:3:2","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"4. Creating HTTPs endpoint Go to System administrator \u003e Business events \u003e Business events catalog, Click on Endpoints in Endpoint type choose HTTPS and click Next. Fill all the required information that you got from above steps. Click on Business events catalog, look for business event Id CustFreeTextInvoicePostedBusinessEvent, check the record and click Active; from there choose legal entity and the Endpoint that we have just created. {:.border} After that, if you check on Active events tab, there will be a new record created. That’s it, now I will create a free text invoice and post it, this is what I got from the console log in Azure. {:.border} With the JSON messages, you can deserialize it and save to Cosmos DB or do whatever in Azure function. ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:4:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"5. About platform changes Before PU26, Business event run in batch, following menu System admin \u003e Business events \u003e Start business events batch job {:.border} {:.border} {:.border} In BusinessEventsParameters, the value will be Enabled = 0 , BatchEnabled = 1. After PU26, the sending business events will be triggered directly from FinOps, you won’t find the menu System admin \u003e Business events \u003e Start business events batch job In BusinessEventsParameters, the value will be Enabled = 1 , BatchEnabled = 0. If you have just upgraded from PU26 to higher version, the Business events are not getting triggered because the value might not be changed in BusinessEventsParameters and there is no batch. You should check this table according to the situation. Thank you for reading. ","date":"November 5, 2019","objectID":"/2019-11-05-business-events-and-https-endpoint/:5:0","tags":["Postman","Business events","BATCH","integration","Azure"],"title":"Business events and HTTPs endpoint","uri":"/2019-11-05-business-events-and-https-endpoint/"},{"categories":null,"content":"Got inspired by this topic, I’d like to write this article to show you how to post multiple records in single request by using Postman. Generally, batch requests are supported in the OData service, The easiest way is you can use the C# code approach from github and the excel add-ins in Dynamics 365 for finance and operations use Odata batch to communicate in a single request but how can we leverage it in Postman. Using Excel add-in then add 2 customer groups records and submit to Dynamics 365 for finance and operations, while you are doing that using fiddler on the same box to see how the odata batch framework works. This can be done from POSTMAN too and you need to use header and body as you see in Fiddler. For basic setting up Dynamics 365 for finance and operations and Postman please follow this offical document ","date":"October 15, 2019","objectID":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/:0:0","tags":["Postman","ODATA","BATCH","integration","d365"],"title":"Insert multiple records in single request using Odata from Postman","uri":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/"},{"categories":null,"content":"1. Get Dynamics 365 for finance and operations authorization This is a result \r\r","date":"October 15, 2019","objectID":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/:0:1","tags":["Postman","ODATA","BATCH","integration","d365"],"title":"Insert multiple records in single request using Odata from Postman","uri":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/"},{"categories":null,"content":"2. Create a new POST request in Postman with header \r\rURL: {{resource}}/data/$batch Content-Type: multipart/mixed;boundary=batch_d63a-e9be-2927 ","date":"October 15, 2019","objectID":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/:0:2","tags":["Postman","ODATA","BATCH","integration","d365"],"title":"Insert multiple records in single request using Odata from Postman","uri":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/"},{"categories":null,"content":"3. Modify the Body in Postman I will place 2 records for customer groups \r\rFull text here --batch_d63a-e9be-2927 Content-Type: multipart/mixed; boundary=changeset_2499-90ab-7b93 --changeset_2499-90ab-7b93 Content-Type: application/http Content-Transfer-Encoding: binary POST CustomerGroups?cross-company=true HTTP/1.1 Content-ID: 1 Accept: application/json;q=0.9, */*;q=0.1 OData-Version: 4.0 Content-Type: application/json OData-MaxVersion: 4.0 {\"CustomerGroupId\":\"1060\",\"Description\":\"Wholesales customers\",\"PaymentTermId\":\"Net30\",\"IsSalesTaxIncludedInPrice\":\"No\",\"dataAreaId\":\"usmf\"} --changeset_2499-90ab-7b93-- --batch_d63a-e9be-2927 Content-Type: multipart/mixed; boundary=changeset_b573-33b2-85ff --changeset_b573-33b2-85ff Content-Type: application/http Content-Transfer-Encoding: binary POST CustomerGroups?cross-company=true HTTP/1.1 Content-ID: 2 Accept: application/json;q=0.9, */*;q=0.1 OData-Version: 4.0 Content-Type: application/json OData-MaxVersion: 4.0 {\"CustomerGroupId\":\"1070\",\"Description\":\"Wholesales customers1\",\"PaymentTermId\":\"Net30\",\"IsSalesTaxIncludedInPrice\":\"No\",\"dataAreaId\":\"usmf\"} --changeset_b573-33b2-85ff-- Click send and this is what you got from response \r\rFull Response {% highlight json %} –batchresponse_45e87829-5a26-480e-8aaa-8a08c7a82c60 Content-Type: multipart/mixed; boundary=changesetresponse_27ed7621-d939-40b7-9f8b-be0421ff0cea –changesetresponse_27ed7621-d939-40b7-9f8b-be0421ff0cea Content-Type: application/http Content-Transfer-Encoding: binary Content-ID: 1 HTTP/1.1 201 Created ETag: W/“JzEsNjg3MTk0Nzk4MzUn” Location: https: //fodevb2819a3b6966913ddevaos.cloudax.dynamics.com/data/CustomerGroups(dataAreaId=‘usmf’,CustomerGroupId=‘1060’) Content-Type: application/json; odata.metadata=minimal OData-Version: 4.0 { “@odata.context”: “https://fodevb2819a3b6966913ddevaos.cloudax.dynamics.com/data/$metadata#CustomerGroups/$entity\", “@odata.etag”: “W/\"JzEsNjg3MTk0Nzk4MzUn\"”, “dataAreaId”: “usmf”, “CustomerGroupId”: “1060”, “ClearingPeriodPaymentTermName”: “”, “DefaultDimensionDisplayValue”: “”, “CustomerAccountNumberSequence”: “”, “IsSalesTaxIncludedInPrice”: “No”, “Description”: “Wholesales customers”, “WriteOffReason”: “”, “PaymentTermId”: “Net30”, “TaxGroupId”: \"” } –changesetresponse_27ed7621-d939-40b7-9f8b-be0421ff0cea– –batchresponse_45e87829-5a26-480e-8aaa-8a08c7a82c60 Content-Type: multipart/mixed; boundary=changesetresponse_541a7d21-af21-4d66-b410-fb4165599b54 –changesetresponse_541a7d21-af21-4d66-b410-fb4165599b54 Content-Type: application/http Content-Transfer-Encoding: binary Content-ID: 2 HTTP/1.1 201 Created ETag: W/“JzEsNjg3MTk0Nzk4MzYn” Location: https: //fodevb2819a3b6966913ddevaos.cloudax.dynamics.com/data/CustomerGroups(dataAreaId=‘usmf’,CustomerGroupId=‘1070’) Content-Type: application/json; odata.metadata=minimal OData-Version: 4.0 { “@odata.context”: “https://fodevb2819a3b6966913ddevaos.cloudax.dynamics.com/data/$metadata#CustomerGroups/$entity\", “@odata.etag”: “W/\"JzEsNjg3MTk0Nzk4MzYn\"”, “dataAreaId”: “usmf”, “CustomerGroupId”: “1070”, “ClearingPeriodPaymentTermName”: “”, “DefaultDimensionDisplayValue”: “”, “CustomerAccountNumberSequence”: “”, “IsSalesTaxIncludedInPrice”: “No”, “Description”: “Wholesales customers1”, “WriteOffReason”: “”, “PaymentTermId”: “Net30”, “TaxGroupId”: \"” } –changesetresponse_541a7d21-af21-4d66-b410-fb4165599b54– –batchresponse_45e87829-5a26-480e-8aaa-8a08c7a82c60– {% endhighlight %} Check the data in Dynamics 365 for finance and operations \r\rThank you for reading. ","date":"October 15, 2019","objectID":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/:0:3","tags":["Postman","ODATA","BATCH","integration","d365"],"title":"Insert multiple records in single request using Odata from Postman","uri":"/2019-10-15-insert-multiple-records-in-single-request-using-odata-from-postman/"},{"categories":null,"content":"In this article, I will show the procedure for the SSRS Reports development and customization in Dynamics 365 finance and operations (Version 8.1 and above). The scenario is you would like to extend the customer account statement report with 2 main tasks Create custom design for the report Expand the standard report data sets Same with AX 2012 version, there is no change on how you developer a new SSRS report with query based and report data provider. But if you want to extend or modify the standard one you need to understand how to use extensions in general, Event handlers and Chain of Command. The steps ","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:0","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"1. Adding a new field The main temp table is CustAccountStatementExtTmp, right click and create an extension; I’m going to add a new string field MaxTxT \r\r","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:1","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"2. Duplicate the report Duplicate the CustAccountStatementExt report in the Application explorer \u003e AOT \u003e Reports \u003e CustAccountStatementExt as shown in below screen shot: \r\rRename the report and provide any appropriate name: MaxCustAccountStatementExt ","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:2","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"3. Modify the report design, right click on report dataset and choose restore to refresh the new field \r\rOpen report designer and add that field into a table \r\r","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:3","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"4. Create a new Extension class that extends the standard report controller class. class MaxCustAccountStatementExtController_Ext extends CustAccountStatementExtController{} {% highlight csharp %} //Add construct public static MaxCustAccountStatementExtController_Ext construct() { return new MaxCustAccountStatementExtController_Ext(); } {% endhighlight %} Copy the main method from the standard controller class and add references to the new Controller class {% highlight csharp %} public static void main(Args _args) { SrsPrintMgmtFormLetterController controller = new MaxCustAccountStatementExtController_Ext(); controller.parmReportName(PrintMgmtDocType::construct(PrintMgmtDocumentType::CustAccountStatement).getDefaultReportFormat()); controller.parmArgs(_args); MaxCustAccountStatementExtController_Ext::startControllerOperation(controller, _args); } protected static void startControllerOperation(SrsPrintMgmtFormLetterController _controller, Args _args) { _controller.startOperation(); } {% endhighlight %} Optional method, determine which default design for report {% highlight csharp %} protected void outputReport() { SRSCatalogItemName reportDesign; reportDesign = ssrsReportStr(MaxCustAccountStatementExt,Report); this.parmReportName(reportDesign); this.parmReportContract().parmReportName(reportDesign); formletterReport.parmReportRun().settingDetail().parmReportFormatName(reportDesign); super(); } {% endhighlight %} ","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:4","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"5. Create new report handler class class MaxCustAccountStatementHandler {} We have two different ways to Populate the data in the Report handler class: Add a temp table Inserting event, row-by-row calculations. {% highlight csharp %} [DataEventHandlerAttribute(tableStr(CustAccountStatementExtTmp), DataEventType::Inserting)] public static void CustAccountStatementExtTmpInsertEvent(Common c, DataEventArgs e) { CustAccountStatementExtTmp tempTable = c; tempTable.MaxTxT = “Hello world”; } {% endhighlight %} Add a data processing post-handler, inserting operations that use a single pass over the result set of the standard solution. {% highlight csharp %} [PostHandlerFor(classStr(CustAccountStatementExtDP), methodstr(CustAccountStatementExtDP, processReport))] public static void TmpTablePostHandler(XppPrePostArgs arguments) { CustAccountStatementExtDP dpInstance = arguments.getThis() as CustAccountStatementExtDP; CustAccountStatementExtTmp tmpTable = dpInstance.getCustAccountStatementExtTmp(); ttsbegin; while select forUpdate tmpTable { tmpTable.MaxTxT = “Hello world”; tmpTable.update(); } ttscommit; } {% endhighlight %} ","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:5","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"6. Add a delegate handler method to start to use your custom report. In this example, extend the getDefaultReportFormatDelegate method in the PrintMgtDocTypeHandlerExt class by using the following code. {% highlight csharp %} class MaxPrintMgtDocTypeHandlersExt { [SubscribesTo(classstr(PrintMgmtDocType), delegatestr(PrintMgmtDocType, getDefaultReportFormatDelegate))] public static void getDefaultReportFormatDelegate(PrintMgmtDocumentType _docType, EventHandlerResult _result) { switch (_docType) { case PrintMgmtDocumentType::CustAccountStatement: _result.result(ssrsReportStr(MaxCustAccountStatementExt, Report)); break; } } } {% endhighlight %} ","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:6","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"7. Create extension for the existing menu items Navigating to the CustAccountStatementExt output menu item and create extension. \r\rAlso make sure to set the value of the Object property to MaxCustAccountStatementExtController_Ext to redirect user navigation to the extended solution. That’s all, this is what you should have \r\r","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:7","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"8. Update the Print management settings to use the custom business document Go to Account payable \u003e Inquiries and reports \u003e Setup \u003e Forms \u003e Form setup Click Print Management, find the document configuration settings, and then select the custom design \r\r\r\r","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:8","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"9. Run report and test the result \r","date":"October 10, 2019","objectID":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/:0:9","tags":["COC","Extension","SSRS"],"title":"Extend the standard reports in Dynamics 365 finance and operations","uri":"/2019-10-10-extend-the-standard-reports-in-dynamics-365-finance-and-operations/"},{"categories":null,"content":"The following reports provide details about technical objects available in Dynamics 365 for Finance Operations version 10.0. This version was released in May 2019 and has a build number of 10.0.2. ","date":"September 28, 2019","objectID":"/2019-09-28-technical-referece-report-data-entites-d365/:0:0","tags":["Technical reference","Data entity"],"title":"Technical reference - Data entity - Dynamics 365 finance and operations","uri":"/2019-09-28-technical-referece-report-data-entites-d365/"},{"categories":null,"content":"You can either execute the script for cloud-hosted, onebox VHD, or UAT environment. This is not applied with one-box Microsoft hosted environment. Open PowerShell, run following script K:\\AOSService\\webroot\\bin\\Microsoft.Dynamics.AX.Deployment.Setup.exe -bindir \"K:\\AosService\\PackagesLocalDirectory\" metadatadir \"K:\\AosService\\PackagesLocalDirectory\" -sqluser \"axdbadmin\" -sqlserver \".\" -sqldatabase \"AxDB\" -setupmode \"sync\" -syncmode \"fullall\" -isazuresql \"false\" -sqlpwd \"************\" -logfilename \"C:\\Temp\\dbsync.log\" For example K:\\AOSService\\webroot\\bin\\Microsoft.Dynamics.AX.Deployment.Setup.exe -bindir \"K:\\AosService\\PackagesLocalDirectory\" metadatadir \"K:\\AosService\\PackagesLocalDirectory\" -sqluser \"axdbadmin\" -sqlserver \".\" -sqldatabase \"AxDB\" -setupmode \"sync\" -syncmode \"fullall\" -isazuresql \"false\" -sqlpwd \"AOSWebSite@123\" -logfilename \"C:\\Temp\\dbsync.log\" AX DB user you can get from LCS, if you want to sync Azure DB please change -isazuresql to True ","date":"August 5, 2019","objectID":"/2019-08-05-database-sync-d365fo/:0:0","tags":["database synchronization","Power shell"],"title":"Dynamics 365 for finance and operations database synchronization using command line","uri":"/2019-08-05-database-sync-d365fo/"},{"categories":null,"content":"When we write a code, or make a customization to Dynamics 365 For Operation which is using X++ should make use of Exception Handling to provide some context for the message or a different more useful message. In this article, I will be exploring how I can come up with a uniform way to catch multiple types of exception that can be raised in X++. ","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:0","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"1. Exception type There are many several types of exception and the type differs depending on what caused the error. Much of exception types are determined by the kernel and are not normally thrown by application code. All exception types, however, can be caught, and it is the developers’ responsibility to decide which exceptions need to be handled. The exception type is identified using the system-based enumeration called an exception. Because it is a system Enum, it cannot be modified, so users cannot add new exception types. The following table shows the exception literals that are the values of the Exception enumeration. \r\r","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:1","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"2. Key commands The Try command signifies the start of a block of code that you want to control with the X++ exception handling system. Any exceptions that are thrown in that block of code can be caught and handled accordingly. The block of code inside the Try statement must be contained between brackets ( { } ). Catch statements come after the block of code and define what code is executed when each exception is thrown. You do not have to define a catch statement for every possible exception; however, each try statement must have at least one catch statement. A Retry command tells the system to go back to the Try statement and attempt to execute the code again. Any data that was loaded before the Try command will remain as it was, but any data retrieved or modified after the Try statement will be refreshed. When a deadlock exception is thrown, all locks on tables that this process holds are released, which may allow the other process or processes that are also deadlocked to continue. By calling a retry, the process can attempt to update the record again and may now be able to complete. It is a best practice that a retry uses a counter so that the number of retries can be controlled, and a user does not become stuck in a loop. The final keyword is now available to follow the try and catch keywords. The semantics are identical to the semantics in C#. The statements provided in the final clause is executed irrespective of whether the try block threw any exceptions. ","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:2","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"3. Code Statement We will use these lines of code example here for testing Exception handling {% highlight csharp %} class CustCreateCustomer { public static void main(Args _args) { CustCreateCustomer custCreateCustomer = new CustCreateCustomer(); custCreateCustomer.run(); } public void run()\r{\rDialog dlg = new Dialog(\"Create new customer\");\rDialogField dlgCust;\rDialogField dlgGrp;\rCustTable custTable;\rdlgCust = dlg.addField(extendedTypeStr(CustVendAc), \"Customer account\");\rdlgGrp = dlg.addField(extendedTypeStr(CustGroupId));\rif (dlg.run())\r{\rtry\r{\rcustTable.AccountNum = dlgCust.value();\rcustTable.CustGroup = dlgGrp.value();\rif (!custTable.validateWrite())\r{\rthrow error(\"Please enter all required fields.\");\r}\relse\r{\rcustTable.insert();\r}\r}\rcatch (Exception::Error)\r{\rerror(\"An error occurred. Please try again\");\r}\r}\r}\r } {% endhighlight %} This code will try to create a customer after revived inputted value from users, this code also handling errors when user do not input enough information. A Throw statement is used to throw an error that can be caught by a Catch statement. When the system throws an exception ttsabort is called automatically, and so does not have to be called in a Catch statement. ","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:3","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"4. Optimistic Concurrency Exceptions The optimistic concurrency check (OCC) is a performance enhancing function within Microsoft Dynamics 365 For Operation. It presumes that any record retrieved from the database is not updated until it is proven to be updated by the database. This means that fewer locks must be placed on records in the database. This allows for faster access for other users. This also means that one user can update a record after another user has retrieved it from the database. This can cause data inconsistency. If the second user then also tries to update the record, an UpdateConflict exception is thrown. The system does this by comparing the recVersion field on the record buffer at runtime and the actual record in the database. The recVersion field value is changed every time that an update is successfully made to a record. There are two main table update exceptions, UpdateConflict and DeadLock. An update conﬂict occurs due to the optimistic concurrency failing, whereas a deadlock is the classic database scenario where both transactions have each locked a table that the other needs. Update conﬂicts are normally handled within the insert, delete, and update methods of a table. The BOM table is a good example of this. You may also hard to find many examples where this has been used. We use this pattern only if we deem it to be required. The code within the table’s update method also updates other records, so it has been written to handle update conﬂicts. The following code is an example of how to handle the UpdateConflict exception that might be thrown. {% highlight csharp %} public void update() { #OCCRetryCount try { ttsbegin; // code that updates records in other tables super(); // do the update // other code that updates records in other tables ttscommit; } //Deadlock catch (Exception::Deadlock) { retry; } //UpdateConflict catch (Exception::UpdateConflict) { if (appl.ttsLevel() == 0) { if (xSession::currentRetryCount() \u003e= #RetryNum) { throw Exception::UpdateConflictNotRecovered; } else { retry; } } else { throw Exception::UpdateConflict; } } } {% endhighlight %} If a conflict due to OCC occurs, the system throws the UpdateConflict exception and it is caught by the catch statement. The other new element here is ttsLevel. Since transactions can be nested, we do want the exception to falling through to the parent transaction if one exists. If ttsabort is issued (directly or due to a throwing error) at any level, the whole transaction will be rolled back; we can’t roll back just the level where the error is thrown. The code checks the current TTS level. If it is not Zero, in other words, it is still in a TTS transaction, it throws another UpdateConflict exception to the next Catch list of the next outer Try statement in scope. This continues until it is no longer inside a TTS transaction. We must make sure that when the code is retired, all data is refreshed. It is important that we don’t retry indefinitely, as this may cause the client to hang. To control this, we use xSession::currentRetryCount() to get the number of retries and check this against the #RetryNum macro. The macro defines the standard number of retries deemed appropriate by Microsoft, which is five. then the UpdateConflictNotRecovered exception is thrown. This means the whole transaction is aborted and stops retrying. ","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:4","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"5. Conclusion We do not, in any case, want an error to be thrown that stops the form from opening. Also, if there is an error, we need to decide whether the user actually needs to know that an error occurred. It may be enough for our purposes that the fields don’t appear, and we can use the debugger to trace through the code to determine why. Thank you for reading! ","date":"August 7, 2017","objectID":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/:0:5","tags":["Exception Handling","Dynamics 365 for finance and operations","X++"],"title":"Exception Handling in Dynamics 365 For Finance and Operation","uri":"/2017-08-07-exception-handling-in-dynamics-365-for-finance-and-operation/"},{"categories":null,"content":"1. Overview Management Reporter in New AX Management Reporter is now Financial reports. As you know Management Reporter is a real-time financial reporting application that is designed to empower information workers to quickly and easily create, generate, secure, and publish financial statements, such as Profit and Loss statements, balance sheets, and cash flow reports. In Dynamics 365 For Operation, I can access these reports within AX means directly from the web client in the browser. This feature allows me to run financial statements, such as a balance sheet and income statements. The 22 default reports that are included, default financial reports including income statements, balance sheet reports, cash flow statements, and general ledger reports, which can be modified depending on your company’s requirements. Here is the list \r\r","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:1","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":"2. Access You can find the financial reporting menu in Dynamics 365 For Operation by visiting General Ledger \u003e Inquiries and reports \u003e Financial reporting. Although, there are some privileges and duties relating to this. These report functions are available to users that have their appropriate privileges and duties assigned to them already. In order to view, edit, and manage reports in Management Reporter you need to add security administrator role to business Users. Besides, if you only need users can run the financial reports then you have to add the appropriate privileges and duties assigned to them. Before creating and generating financial reports for a legal entity, you must be done set up for that legal entity: Fiscal calendar Ledger Chart of Accounts Currency ","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:2","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":"3. Management Reporter Benefits With Management Reporter, business users can: Create their own boardroom-quality reports without IT assistance. Take advantage of secure report distribution through the centralized Report Library. Gain strong support for regulatory compliance (Change the report date, currency, view in Summary view or a detailed view, Add either dimension filters or attribute filters). Report design flexibility likes Save dimension combinations, and reuse the dimensions for multiple reports. Management Report Components. Financial report collaboration: Schedule reports so that they are automatically generated on a daily, weekly, monthly, or annual basis. Export to the read-only XPS format, which provides better document security through digital signatures. Export to a Microsoft Excel worksheet. To share reports, you can create email messages that contain links to the reports. ","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:3","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":"4. Management Report Components Some important components I want to mention here: Report Designer Create report building blocks that can be combined to define and generate a report. The report wizard guides less experienced users through the design process. Advanced users can create new report building blocks or modify existing building blocks to meet their requirements. Desktop Viewer Used to organize and view reports and supporting files. It also stores the report library. Web Viewer Displays Management Reporter reports in a web browser. The Web Viewer does not require an installation of Management Reporter server components. Report schedules A user can schedule a single report or a group of reports to generate regularly. Management Reporter database This SQL database stores the components, known as building blocks, which are used to generate reports. It also stores report definitions and previously generated reports. Application service Controls access to the data provider and provides connectivity to clients. Process service Generates the reports that are created and queued by the Management Reporter client. ","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:4","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":"5. Generate financial reports We are currently at Financial reports screen as picture below \r\rAs you can see there’s nowhere on the screen or anything that indicates that there’s the Management Reporter available, but if we click this edit button and entering your email account and password. After you log in, it will open the Report Definitions Management Reporter window for us. \r\rOn the left, here we have a list of all the same reports that we were looking at in AX. Let’s look at the income statement - default report, So I have a couple parameter fields we need to change before we can generate our report. Please prefer below picture \r\rAfter we click **generate** button, Financial will be generated on current web browser\r\r\rwe can see here by the report date. So, on our income statement, we have all the usual fields here. We have total revenues, gross profit, total operating experiences, net operating income and net income. That all is pretty standard and it all looks good.\r","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:5","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":"6. Conclusion Row, Column, Tree, Report definitions work essentially the same as they did in Dynamics AX 2012. I can still use row, column, and tree definitions with multiple reports, and options for the Report definition tabs. \r\rHere are some of the functions that are not available in Financial Reporting for Dynamics 365 for Operations: Publishing/distributing reports to SharePoint and/or SharePoint Online locations is not available. Report Viewer/Library has been removed. Import data from an Excel file is not available. XBRL (extensible Business Reporting Language) is no longer available. Comments are not currently available in the web client. Running a consolidation between companies in different instances of AX is not available. The Wizard has been removed. Management Reporter includes direct integration with the Microsoft Dynamics AX general ledger so that there is no need to create a custom connection to the data source. Nevertheless, with custom reporting structures, ledger accounts, and dimensions mapping, creation and the capabilities to publish reports to multiple channels and formats from the desktop, and embedding transactional and analytical reports into a customizable dashboard, Financial Reporting in Dynamics 365 For Operation is all set to simplify the financial reporting process, providing instant insight into your financials. Thank you for reading! ","date":"July 24, 2017","objectID":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/:0:6","tags":["Management reporter","Financial reporting","Dynamics 365 for finance and operations"],"title":"Management reporter in new AX, Dynamics 365 For Operation","uri":"/2017-07-24-management-reporter-in-dynamics-365-for-operation/"},{"categories":null,"content":" There are many explanations that we can find in internet about C# OOP, but here in my article I will give a very simple example. In this article, I will use a “House (like the houses we live in) “as a real-time example for easy understanding of OOP Concept in C#. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:0","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"1. Class Class is a like a Blueprint. Blueprint is outline drawing of our actual plan. For example if we plan to build our new house, the Engineer will explain our new house plan with a blue print as shown in the image below. Once we finalized the plan the engineer will start building the house with same plan. Same like blueprint class is an outline of program. Using the class we can write our own method and declare the variables and using the objects we can access the class Method and Variables. The class will be complete with Variables, Methods and Objects. \r\rFor more easy understanding of OOP with real world example here I have explained a class with House. We can imagine a House as an example for a Class. In a house, we will have rooms like living room, bedroom, kitchen and items like TV, fridge etc. House owner can access and use all the rooms and rooms' items. Same like this in a Class will have a group of Methods and Variables. Rooms and Rooms’items are example for Methods and Variables. So now, we have a complete house with all rooms and rooms’items. House owner can access and use all the rooms and Rooms' Items. To access and use a Class, methods and variables here we use Objects. Objects are instance of a class. We will see details about objects in the next section. What will happen if there are no rooms and items in a House? It will be empty and no one can use the house until it has all the rooms and Items. See the below image as an example for the empty house. \r\rNow this empty house is a Class. So what is the use of a Class without Methods and variable. Now let’s see an example for a Complete House with Rooms and items. \r\rSo here, we have a complete house. Similarly, the Class will be complete with group of Variables, Methods and Objects. We can see details of all this in next sections of this article. Class and objects are the base concept of OOP – Object Oriented Programming. Class should be started with the Keyword class and next we give the name for our class we can give any meaning full name as Class Name, next we will have the Open and close brackets. {% highlight csharp %} using System; public class ClassA { } {% endhighlight %} ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:1","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"2. Object As we have already seen that, House Owner will access and use all the Rooms of the House and its Items. Similarly, to access all Class Method and Variable we use Objects. We can create one or many object for a same Class. Example we can say for a house there might be one or many owners. objHouseOwner is the Object for a class which will be used to access all variable and Method of a class. {% highlight csharp %} namespace ConsoleApplication1 { class Program { static void Main(string[] args) { Program pro = new Program(); } } } {% endhighlight %} ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:2","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"3. Variable Variables are used to store our value. Our value can be numeric or characters for example to store a Phone no we can use int type variable and to store our name we can use string type variable with name for each variable. Variables can be local or Global. For Example, we can say if we buy a new TV , TV Service man will come and setup the TV in our home. He will give his contact number for future contacts. Usually what we do is take a memo paper and write his contact number and keep it in a common place or in a wallet of ours. If we keep the memo in a Common place everyone who is visiting our house can see that contact number. Global or public variables are similar to this. If we declared the variable as Global, All the Methods inside the class can access the variable. If we store the memo Only in our wallet, we can see the contact number. Local or private variables are similar to this. Syntax for variable: Access-Modifiers Data-Type Variable-Name By default the Access-Modifiers are by private, we can also use public to variable. Example of Variable: {% highlight csharp %} namespace ConsoleApplication1 { // Example Program class ShanuHouseClass { public int noOfTV = 0; private Boolean doYouHaveTV = true; protected String yourTVName = “SAMSUNG”; static void Main(string[] args) { ShanuHouseClass objHouseOwner = new ShanuHouseClass(); Console.WriteLine(“You Have total \" + objHouseOwner.noOfTV + \" no of TV :\"); Console.WriteLine(“Your TV Name is :” + objHouseOwner.yourTVName); Console.ReadLine(); } } } {% endhighlight %} \r\rIn Above example program I have declared two variables inside a class. In main method I have created object for class. Here we can see using the object we can access the variable of a class and display the output. Main Method is the default Method of C#, where every console and windows application will start the program execution, In the Main Method, we can declare the Object for the class and use the object, and we can access all variables and Methods of a Class. For example, we can say there will be entrance gate for every house. Using the entrance gate we can enter inside our house. Similarly, to run our program there should be some default program execution starting Method. Main method will be useful in this program execution starting point. Whenever we run our C# Console or windows application, first the Main method will be executed .From the main method we can create an object for our other classes and call their Methods. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:3","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"4. Method or Functions Method is a group of code statement .Now here we can see the above example program with method. {% highlight csharp %} class ShanuHouseClass { public int noOfTV = 2; private Boolean doYouHaveTV = true; protected String yourTVName = “SAMSUNG”; public void myFirstMethod()\r{\rConsole.WriteLine(\"You Have total \" + noOfTV + \"no of TV :\");\rConsole.WriteLine(\"Your TV Name is :\" + yourTVName);\rConsole.ReadLine();\r}\r } class a { static void Main(string[] args) { ShanuHouseClass a = new ShanuHouseClass(); a.myFirstMethod(); } } {% endhighlight %} \r\r Most of developers were wondering about what is the difference between the Method and Function, both Methods and Functions are the same. Here in my article, I will use Method instead of functions. However, there is one difference in Methods and Functions, In OOP Languages like C#, Java etc. We use the term Method while the non-OOP programming like C etc. we use the term Function. What is the use of Methods? Another real-time example let’s take our mobile phone, we can say as we have Mobile phone and store many Songs in it. However, we always like to listen to the selected songs. It will be boring and hard for us to select our favorite song every time and play it. Instead of doing the same work repeatedly, we use the playlist. In playlist, we can add all-favorite songs of ours. Just click on the playlist of our collections and listen to the music. This will make our work easier and we don’t need to do the same thing again and again. Methods are used like a playlist where we can write all our repeated code in one Method and just call the method wherever we needed. In a house, there might be one big room or multiple rooms but each room will have different facilities, similarly in a class we can write one or multiple Methods. In a house, there might be two or three Bedrooms. Here the room name is Bedroom, but each bedroom can be different by size, color etc. This means same Rooms with different type. Similarly, in a class we can create more than one method with the same name but different parameter. In OOP it’s called as Polymorphism we can see details about Polymorphism later on in this article. Syntax for the Functions Access-Modifiers Return-Type Method-Name (Parameter-List) Access-Modifiers: We will see more details about this Topic later on. Return-Type: If our Method returns any value then we use the return Type with any Data Type as String, int etc., if our Method does not return any value then we use the type “Void”. Method-Name: Here we give our Name for every Method, which we create Parameter-List: Parameter-List or Arguments, which we pass to the function. Here is an example of Method: Method with Void Type: Void is a keyword which will not return any data from the Method, for example we can see the below Method with void Type, here in this method we display all our output using the Console.WriteLine and have used the Console.ReadLine()); to get the Input. This Method has all Input and Output Operation but this method don’t return any value. {% highlight csharp %} // Function with void and no parameter – here void means no return type public void veranda() { Console.WriteLine(“Welcome to Veranda”); Console.WriteLine(“How Many Chairs Do you have in your Veranda”); NoofChair = Convert.ToInt32(Console.ReadLine()); Console.WriteLine(“I have total \" + NoofChair + \" Chairs in my Veranda”); } {% endhighlight %} Method with Return Type: Method with return type will return some result, which can be used in our program, for example, here we have Method TVNAME with return Type as String. We can say in our home we might have a TV in our LivingROOM and in the parent’s bedroom and also in kids bedroom .We might have different TV brand in each room, suppose if we want to know each room TV Brand Name then we need to enter the same code 3 times. Instead of writing the same code again, we can use a method with Return Type. {% highlight csharp %} // Function with Return type as Str","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:4","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"5. Access Modifiers Access Modifiers are nothing but the Usage and Limitation of our type like variable, Methods and Class. For Example we can say it as a security limit. This six are the basic Access modifiers which we used in our C# Class/method and in Variables. Private Let’s take our House Example .We will have a Security Guard in House, His duty is till the Entrance of the house. He cannot go inside the house and access all the things. In this case we can create a SecurityGuardClass and declare the variable and method for Security as private . Public House Owners are public to the class where they can access all classes related to the House. They have no restrictions to access their house. Internal Access limit of variable or method is within a project. For example let’s consider in our project we have more than one class and we have declared a variable as internal in one class. Let’s see an example program for internal variable. {% highlight csharp %} class Modifiers { public class sampleInternalClass { internal String myInternal = “Iam Internal Variable”; } class ShanuHouseClass { int noOfTV = 2; public String yourTVName = “SAMSUNG”; public void myFirstMethod() { Console.WriteLine(“You Have total \" + noOfTV + “no of TV :\"); Console.WriteLine(“Your TV Name is :” + yourTVName); } static void Main(string[] args) { ShanuHouseClass objHouseOwner = new ShanuHouseClass(); objHouseOwner.myFirstMethod(); sampleInternalClass intObj = new sampleInternalClass(); Console.WriteLine(“Internal Variable Example :” + intObj.myInternal); Console.ReadLine(); } } } {% endhighlight %} \r\r Protected Only the main class and derived class can have access of protected variable or method. For example servants and Guests are example for the Protected. For Example Servants can go to all room and do cleaning and other activates. However, they have limitations of access in the house, as they cannot take rest in a bed of house owner. Protected Internal Protected Internal variable or Method has limitation with in a project of class or Derived class. Here is a sample program for Protect Internal Variable .In this example I have used the Inheritance .we will see in detail about Inheritance more detail in this article. {% highlight csharp %} public class sampleProtectedInternalClass { protected internal String myprotectedInternal = “Iam Protected Internal Variable”; public void protectedInternalMethod() { Console.WriteLine(“Protected Internal Variable Example :” + myprotectedInternal); } } public class derivedClass : sampleProtectedInternalClass { public void derivedprotectedInternal() { Console.WriteLine(“Derived Protected Internal Variable Example :” + myprotectedInternal); } } class ShanuHouseClass { int noOfTV = 2; public String yourTVName = “SAMSUNG”; public void myFirstMethod() { Console.WriteLine(“You Have total \" + noOfTV + “no of TV :\"); Console.WriteLine(“Your TV Name is :” + yourTVName); } static void Main(string[] args) { ShanuHouseClass objHouseOwner = new ShanuHouseClass(); objHouseOwner.myFirstMethod(); sampleProtectedInternalClass intObj = new sampleProtectedInternalClass(); intObj.protectedInternalMethod(); derivedClass proIntObj = new derivedClass(); proIntObj.derivedprotectedInternal(); Console.ReadLine(); } } {% endhighlight %} \r\r The main and major things we need to know in OOP concept are Encapsulation, Abstraction,Polymorphism and Inheritance. We will discuss them in detail in this article. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:5","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"6. Encapsulation Encapsulation is to hide the member or variable to outside class. In our house example, I have already told that House security guard limitation is till the entrance of the house. The security guard doesn’t need to know about what is happening inside the house. Therefore, the House Owner will hide all the happenings to Security guard for more safety. The hiding and limitation are called as Encapsulation. For example, we have two Classes the first one is Houseclass and the other class as houseSecurityClass. Here we can see all the variables are wrap into a class where houseSecurityClass is set as public, so the Houseclass can access that, but houseClass has both Public and private variable where the private variable of a class cannot be accessed outside of the class. {% highlight csharp %} //Encapsulation in OOP public class houseSecurityClass { public int noofSecurity; public String SecurityName = String.Empty; } public class Houseclass { private int noofLockerinHosue = 2; public string OwnerName = String.Empty; } {% endhighlight %} ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:6","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"7. Abstraction Abstraction is to show and share some common information to the user. Let’s take our House example, in our house we will have servant, servants can go to all rooms and do cleaning and other works. The house owner can give full rights or some partial rights to the servant for accessing his house. Here we can see an example program as private declared variables and Methods are not shared with servant but the public variable and Methods are shared with servant. {% highlight csharp %} public class HouseServerntClass { private int SaftyLoackerKeyNo = 10001; public String roomCleanInstructions = “Clean All rooms”; private void saftyNos()\r{\rConsole.WriteLine(\"My SaftyLoackerKeyNo is\" + SaftyLoackerKeyNo);\r}\rpublic void roomCleanInstruction()\r{\rConsole.WriteLine(roomCleanInstructions);\r}\rstatic void Main(string[] agrs)\r{\rHouseServerntClass a = new HouseServerntClass();\ra.saftyNos();\ra.roomCleanInstruction();\rConsole.ReadLine();\r}\r } {% endhighlight %} \r\r","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:7","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"8. Inheritance Inheritance is used to reuse the code. In Protected Internal Access modifier section we have already seen an example program for Inheritance. Inheritance is nothing but accessing and using all base class variable and methods in the Derived Class. Inheritance can be Single level Inheritance With one Base class and one derived Class for example. {% highlight csharp %} public class baseClass { private void privateMethod() { Console.WriteLine(“private Method”); } public void publicMethod() { Console.WriteLine(“This Method Shared”); } } public class DerivedClass : baseClass { static void Main(string[] args) { DerivedClass obj = new DerivedClass(); obj.publicMethod(); //This will be error as private method can not be accessed in Derived Class obj.privateMethod(); } } {% endhighlight %} The Error is: \r\r Some time users might be not clear of what Base class is and what Derived class is. Base class is the super class and derived class is the classes which inherit the base class. Here we can see a simple Inheritance where the base class is the GuestVist and derived class is the HouseOwnerClass. Here HouseOwnerClass class inherits the base class of GuestVist \r\r Multi level Inheritance With more than one Derived Class for example. Here we can see an example first base class is derived in DerivedClass1 and then the DerivedClass1 is derived in DerivedClass2 .Now from DerivedClass2 we can access both baseClass and DerivedClass1 variable and methods. {% highlight csharp %} public class baseClass { private void privateMethod() { Console.WriteLine(“private Method”); } public void publicMethod() { Console.WriteLine(“This Method Shared”); } } public class DerivedClass1 : baseClass { public void DerivedClass1() { Console.WriteLine(“Derived Class 1”); } } public class DerivedClass2 : DerivedClass1 { static void Main(string[] args) { DerivedClass2 obj = new DerivedClass2(); obj.publicMethod(); obj.DerivedClass1(); //This will be error as private method can not be accessed in Derived Class //obj.privateMethod(); } } {% endhighlight %} \r\r Multiple Inheritance Will the .Net Support Multiple Inheritance? The Answer to this Question is No. In C #, it’s not possible to write a Multiple Inheritance using Class. What is Multiple Inheritance? Multiple Inheritance is nothing but we can have more than one class and we can inherit both Classes in our derived class. What will happen if I write a Multiple Class Inheritance Using C#? Let’s take our example House .Here we have the derived Class as HouseOwnerClass and have Two More classes as GuestVist and FriendsandRelationsClass. Now suppose for our house both Guest and Friend have visited. For this, we write above three classes and inherit the two classes in our derived class. When I write the Multiple Inheritance in C #, it will display the warning message during our code and execute our program. See the below image which shows the Warning error message while I write Multiple Inheritance. \r\r* Then how can we use the Multiple Inheritance\r Interface will be used for Multiple Inheritance. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:8","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"9. Polymorphism Ploy means more than one form. In the beginning of the Article at Method Section, we have already seen an example of Polymorphism. Same method name with different parameter is an example for the polymorphism. Method Overloading and Method Overriding will be used in polymorphism. Polymorphism have two types of execution one is Compile Time Polymorphism and the other one is called the Run time Polymorphism. Method Overloading Method overloading are nothing but same Method name will be used for more than one method with different Argument. Here is an example program for the Method Overloading. As we can see here Method name BedRoom has been used for two Method but the parameter for both methods are different. {% highlight csharp %} class HouseOwnerClass { //Function with parameter public void BedRoom(String nameandColor) { Console.WriteLine(nameandColor); } // Same Function Name with Different Paramenter public void BedRoom(String MemberName, String Color) { Console.WriteLine(MemberName + \" Like \" + Color + \" Color”); } static void Main(string[] args) { HouseOwnerClass objHouseOwner = new HouseOwnerClass(); objHouseOwner.BedRoom(“My Name is Shanu I like Lavender color”); objHouseOwner.BedRoom(“My Name is Afraz I like Light Blue color”); objHouseOwner.BedRoom(“SHANU”, “Lavender”); Console.ReadLine(); } } {% endhighlight %} \r\r Method Overriding The difference between the Method Overloading and Overriding are.In Method Overloading we will have same method name with different argument. In Method Overriding we will have same Method Name same Argument and same type but method overriding can only be used in the derived class, Method Overriding cannot be done in the same class. We will see how Method Overriding can be used in Abstract Method, Virtual Method and in Sealed Method kindly refer to that section in this article. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:9","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"10. Abstract Class/Method Abstract Class: Abstract class will have a keyword abstract. The Abstract class will be as a super class for all our class. Abstract class cannot be accessed by an object, which means we cannot create an object for an abstract class. What will happen when we create an object for an Abstract Class? Here we can see an error warning message as “An instance of an abstract class cannot be created” when I try to create an object for my abstract class. \r\rAbstract class can have both Abstract Method and normal Method. In Abstract Class at least one Abstract Method should be declared. In addition, derived class should override the abstract method. To access the abstract method we should use the “override” keyword in our derived class. What will happen if we create an abstract method but which is not override in derived class? Here we can see an abstract class has an abstract method, But the abstract method is not override in the derived class. See the below image for the warning message displaying as class must implement the abstract member. \r\rHere we can see an example of Abstract Class and for Abstract Method in detail. In this example, we can see an abstract class, which has normal Method and Abstract Method. Abstract Methods; do not have body part in Abstract Class, which means we can only declare an Abstract Method at Abstract Class, There should be minimum one Abstract Method in an Abstract Class. {% highlight csharp %} public abstract class GuestVist { public void Guestwelcomemessage() { Console.WriteLine(“Welcome to our AbstractHome”); } public void GuestName() { Console.WriteLine(“Guest name is: Abstract”); } public abstract void purposeofVisit(); } // derived class to inherit the abstract class public class A : GuestVist { public override void purposeofVisit() { Console.WriteLine(“Abstract just came for a Meetup and spend some time “); } static void Main(string[] args) { A objHouse = new A(); objHouse.purposeofVisit(); objHouse.Guestwelcomemessage(); objHouse.GuestName(); Console.ReadLine(); } } {% endhighlight %} \r\r","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:10","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"11. Virtual Class/Method Virtual method is very useful in our day-to-day programming. What is virtual Method and what is the use of Virtual Method? Take our House example one guest confirms, as today total five persons will visit your home. For this, we write a function as message display as five Guest visiting our home. Once Guest visits, we see their total 20 persons have visited. In Some cases it might be increase or decrease we will come to know when they reach us. In that case, the guest will be as a Separate Class and House will be as separate class. Without changing the message in Guest class how can we change the data in our Derived class? What is the Difference between Abstract Method and Virtual Method? Both similarities use the override keyword. Abstract Method can only be declared in Abstract Class, which means no body part for abstract method in Abstract class. However, for virtual it can have body part. See the example program below. Here we have both Abstract Method and Virtual Method. In Abstract class, the virtual method says as total five guests but in the derived Class program, the message was override as 20 guests. See the final output in below. Guess what will be displayed for Virtual Method? Will the result be 5 Guests or 20 Guests check for the output below the program. {% highlight csharp %} public abstract class GuestVist { public abstract void purposeofVisit(); // Abstract Method public virtual void NoofGuestwillvisit() // Virtual Method { Console.WriteLine(“Total 5 Guest will Visit your Home”); } } class AbstractHouseClass : GuestVist { public override void purposeofVisit() // Abstract method Override { Console.WriteLine(“Abstract just for a Meetup and spend some time “); } public override void NoofGuestwillvisit() // Virtual method override { Console.WriteLine(“Total 20 Guest Visited our Home”); } static void Main(string[] args) { AbstractHouseClass objHouse = new AbstractHouseClass(); objHouse.purposeofVisit(); objHouse.NoofGuestwillvisit(); Console.ReadLine(); } } {% endhighlight %} \r\r","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:11","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"12. Sealed Class/Method Sealed Class: As name says this class cannot be inherited by other classes. Take our House Example. In a house, the Houseowner can have a secret room, as might be official or financial rooms. The owner don’t want others to access his official room. The sealed class will be useful in those cases. Sealed class can be declared using the keyword Sealed. If one class is declared as Sealed, it cannot be inherited in other derived classes. What will happen when we inherit sealed class in our derived class? Let’s see an example when I try to inherit my sealed class from my derived class. It shows me the below warning message. \r\rHere we can see an example program of Sealed Class. {% highlight csharp %} public sealed class OwnerofficialRoom { public void AllMyPersonalItems() { Console.WriteLine(“All Items in this rooms are personal to me no one else can access or inherit me”); } } class HouseSealedClass { static void Main(string[] args) { OwnerofficialRoom obj = new OwnerofficialRoom(); obj.AllMyPersonalItems(); Console.ReadLine(); } } {% endhighlight %} Sealed Method: If we declared a method as sealed that specific method cannot be override in the derived class. Let’s see our house class here I have base class with Virtual Method and virtual Sealed method. The Virtual method can be override in the derived class .But the Virtual Sealed Method cannot be override in sealed class. ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:12","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"13. Static Class/Method We have already learned about what is Sealed Class in this Article; now let’s see what are Static Class and Static Method. Both Static and Sealed Class cannot be inherited. What is the Difference between Static Class and Sealed Class? We can create an Object (instance) for the Sealed Class, we can see in my sealed class section I have created a sample Sealed class and in Main Method I have created an object to access the sealed Class. And in a Sealed Class both Static and non-Static methods can be written. But for a Static Class it’s not possible to create an Object. In Static Class only Static members are allowed which means in a static Class it’s not possible to write non-static method. We can say our main method as an example for the Static method. When we create a console application in c# we can see each class will have a default main method. In my article I have explained that when an Console or Windows application start execute first the main method will be executed .There is no need to create an object for the main method since it was been declared as a static method. static void Main(string[] args) Another interesting one in Static class is that memory will be allocated for all static variable and methods during execution but for the non static variable and methods memory will be allocated only when the object for the class are created. Let’s take our same sealed class Example for our static Class and method. What will happen when we inherit Static class in our derived class? Let’s see an example when I try to inherit my static class from my derived class. It shows me the below warning message. \r\r What will happen when we declare non-Static method in a Static class? Let’s see an example when I try to create a non-Static method at my Static Class. \r\r What will happen when we create an object for the Static class? Let’s see an example when I try to create an object for my Static Class. \r\rWhen we run the program we get the error message as Can not create an instance of a static class How to call the Static Class Method and variable without creating the Object? It’s simple just we can use the ClassName.Variable or Method Name for example OwnerofficialRoom.AllMyPersonalItems(); See the below example with Static class {% highlight csharp %} public static class OwnerofficialRoom { public static void AllMyPersonalItems() { Console.WriteLine(“All Items in this rooms are personal to me no one else can access or inherit me”); } } class HouseStaticClass { static void Main(string[] args) { OwnerofficialRoom.AllMyPersonalItems(); Console.ReadLine(); } } {% endhighlight %} Is that possible to create a Static Method in non-Static Class? The answer is yes. We can create a Static Method to the non Static class. No need to create an object to access the static method in non-static class. We can directly use the class name to access the Static method. See the below example with Static method in non-static Class. {% highlight csharp %} public class OwnerofficialRoom { public static void AllMyPersonalItems() { Console.WriteLine(“No need to create object for me just use my class name to access me :)\"); } public void non_staticMethod() { Console.WriteLine(“You need to create an Object to Access Me :(\"); } } class StaticmethodClass { static void Main(string[] args) { // for statci method no need to create object just call directly using the classname. OwnerofficialRoom.AllMyPersonalItems(); // for non-static method need to create object to access the method. OwnerofficialRoom obj = new OwnerofficialRoom(); obj.non_staticMethod(); Console.ReadLine(); } } {% endhighlight %} \r\r","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:13","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"14. Interface Interface is same like abstract class but in Interface we will have only method declaration but in abstract class we can have both method declaration and method definition .Methods of Interface must be implemented in a implementing class. See the below Example program for an Interface. All the methods of Interface have been implemented in the class. As I have already told you that c# don’t support multiple inheritance for using multiple inheritance we can use Interface. This below program is an example for multiple inheritance using Interface. {% highlight csharp %} interface GuestInterface { void GuestWelcomeMessage(); void NoofGuestes(); } interface FriendsandRelationsInterface { void friendwelcomemessage(); void FriendName();} class HouseOwnerClass : GuestInterface, FriendsandRelationsInterface { public void GuestWelcomeMessage() { Console.WriteLine(“All guests are well come to our home”); } public void NoofGuestes() { Console.WriteLine(“Total 15 Guestes has visited”); } public void friendwelcomemessage() { Console.WriteLine(“Welcome to our Home”); } public void FriendName() { Console.WriteLine(“Friend name is: Afraz”); } static void Main(string[] args) { HouseOwnerClass obj = new HouseOwnerClass(); obj.GuestWelcomeMessage(); obj.NoofGuestes(); obj.friendwelcomemessage(); obj.FriendName(); Console.ReadLine(); } } {% endhighlight %} \r\rIn some cases we need to have certain methods which will be used in many derived classes. Each derived can implement different functionality for those Methods. In These cases, we can use the Interface. We can say our Guest and house example. For Guest the Welcome Message and No of Guest Function are common, but it will be different for different owners in the same house, Guest might a fathers guest, Mothers Guest, Children’s Guest or Family Guest. Each guest can have different welcome message subject, but the functions are same as Message .let’s consider now Father is a Class, Mother is a class and Children are one Class. Both guestWelcome Message and Noofguest method are same for all. In this case, we can create an Interface and declare both methods in the Interface. All father, mother and Children Classes can inherit the interface and write their own method details. Interface is similar to Abstract class but the major difference between the Abstract Class and the Interface are .In Abstract Class there can be both Abstract Method and Non Abstract methods .But in Interface all methods are abstract by default which means there is no non Abstract type method in the Interface. All the Methods declared in Interface should be override in the derived class. What will happen when non-abstract methods with body part are declared in an Interface? It will display the warning message as unexpected modifier in Access modifier part and Unexpected Method body error warning at message Body. This article repost from here under markdown format. Thank you! ","date":"April 11, 2017","objectID":"/2017-04-10-oops_concept/:0:14","tags":["C#","OOP","Object-oriented programming","Class","method"],"title":"Basic C# OOP Concept","uri":"/2017-04-10-oops_concept/"},{"categories":null,"content":"All main entry points to the UI and reports are access though the menu structure. This is presented in three ways: the left-hand navigation pane, the content area, and the navigation bar (at the top of the client). The menu design is controlled from the Menus node in the AOT. Each module will have a menu, which is created by adding a menu reference (or shortcut) to the main menu: \r\r\rThis matches the list of modules shown in the client’s left-hand navigation pane. Create Menu in AOT Open your project. Right-click on the Menus node and select New \u003e Menu. Rename the menu as YourMainMeunuName and open the property sheet. For Porperties of created Menu: . Enter the label and create a label. . As this menu will be a module with company-specifc information, set the SetCompany property to Yes. . Choose the icons in the NormalImage property and set ImageLocation to EmbeddedResource. Create Submenu, by right-clicking on the menu and navigating to New | Submenu. Finally, we need to add our menu as a module to the main menu, which is done as follows: Place the AOT window next to our project window (if required, open the AOT window by pressing Ctrl + D). Scroll down to Menus and expand MainMenu. Right-click on MainMenu and navigate to New \u003e Menu reference. This opens a new window titled Select: Menus. Locate your menu and drag it to MainMenu, as shown in the following screenshot (the title changes from Select: Menus to the path of the select node when you click on it): \r\r\rNote: Do not drag the menu from your project! Save AOT and you can check new menu on AX client. Thank you for reading! ","date":"March 29, 2017","objectID":"/2017-03-29-how-to-create-main-menu-in-dynamics-ax-2012/:0:0","tags":["main menu","X++","AX2012"],"title":"How to create main menu in Dynamics AX 2012","uri":"/2017-03-29-how-to-create-main-menu-in-dynamics-ax-2012/"},{"categories":null,"content":"\r\rFor this demo, I will create New module along with NumberSequence, about creating Number Sequence without module you also use same steps just leave some steps base on Design picture above. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:0:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"ETD Create ETD ContosoId extends num datatype. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:1:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Table Create Contoso Table with ContosoId field. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:2:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Enum Create a new enum value Contoso in BaseEnum NumberSeqModule. This value will be used to link number sequence to the module and to restrict displayed number sequence by module in Form. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:3:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"NumberSeqModule Class Create NumberSeqModuleXXX class Create a new NumberSeqModuleXXX class, such as NumberSeqModuleContoso, which extends the NumberSeqApplicationModule class. The sample code for creating this class is as follows: {% highlight csharp %} public class NumberSeqModuleContoso extends NumberSeqApplicationModule { } protected void loadModule() { NumberSeqDatatype datatype = NumberSeqDatatype::construct(); ; /* Contoso Id */\rdatatype.parmDatatypeId(extendedtypenum(ContosoId));\rdatatype.parmReferenceHelp(\"ContosoId\");\rdatatype.parmWizardIsContinuous(true);\rdatatype.parmWizardIsManual(NoYes::No);\rdatatype.parmWizardIsChangeDownAllowed(NoYes::No);\rdatatype.parmWizardIsChangeUpAllowed(NoYes::No);\rdatatype.parmWizardHighest(999999);\rdatatype.addParameterType(NumberSeqParameterType::DataArea, true, false);\rthis.create(datatype);\r } public NumberSeqModule numberSeqModule() { ; return NumberSeqModule::Contoso; } {% endhighlight %} Use of the DataArea segment in Step 4 to describe the default segment for the extended data types used for ContosoId. Note In Microsoft Dynamics AX 2009, number sequence references could be initialized by restarting the Application Object Server (AOS). In Microsoft Dynamics AX 2012, the initialization of references to populate the NumberSequenceDatatype and NumberSequenceParameterType tables has moved to the initialization checklist. To initialize the newly created references, run a job that executes the LoadModule method likes below. {% highlight csharp %} static void loadNumSeq (Args _args) { //define the class variable NumberSeqModuleContoso seqMod = new NumberSeqModuleContoso (); //load the number sequences that were not generated seqMod.load(); } {% endhighlight %} You can also reinitialize all references by running a job that executes the LoadAll method in the NumberSequenceModuleSetup class. However, for reinitializing all references, you must ensure that there are no existing number sequences already defined in the system. Then run the wizard in Organization Administration \u003e CommonForms \u003e Numbersequences \u003e Numbersequences \u003e Generate \u003e run the wizard. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:4:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Parameters Table and Form Create a Number sequences page in the parameters form of the new module. You need to Create ContosoParameters Table along with form, See existing forms such as CustParameters or LedgerParameters for examples of the implementation. These forms are using DetailsFormMaster form parten as Best Practice for Setup form. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:5:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Create ContosoParameters Table Add field key, Extends from ParametersKey Properties on Field key Visible = false, AllowEdit = false, AllowEditOnCreate = false Create index name Key with AllowDuplicate = No. Set table properties. TableContent = Default data ConfigurationKey CacheLookup = Found TableGroup = Parameter PrimaryKey = Key ClusterKey = Key The sample code for creating method this table as below: {% highlight csharp %} void delete() { throw error(\"@SYS23721\"); } public void initValue() { ; super(); // Key is set to mandatory so set it to 1 this.Key = 1; } static ContosoParameters find(boolean _forupdate = false) { ContosoParameters parameter; if (_forupdate)\r{\rparameter.selectForUpdate(_forupdate);\r}\rselect firstonly RecId from parameter\rwhere parameter.Key == 1;\rif (!parameter \u0026\u0026 !parameter.isTmp())\r{\rCompany::createParameter(parameter);\r}\rreturn parameter;\r } client server static NumberSeqModule numberSeqModule() { ; return NumberSeqModule::Contoso; } public server static NumberSequenceReference numRefContosoId() { ; NumberSeqScopeFactory::CreateDataAreaScope(curext()); return NumberSeqReference::findReference(extendedtypenum (ContosoId)); } {% endhighlight %} ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:5:1","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Create ContosoParameters form Note This form can only be used for references that have a scope of DataArea. The administration forms described in the Setup and Administration of number sequences section can be used for references that have any scope. These forms can be found in Organization Administration \u003e Common \u003e Number Sequences The data source of Parameters form likes picture below, you can also refer to CustParameters form for design. \r\rCode example for form methods: {% highlight csharp %} public class FormRun extends ObjectRun { NumberSeqReference numberSeqReference; boolean runExecuteDirect; TmpIdRef tmpIdRef; NumberSeqScope scope; NumberSeqApplicationModule numberSeqApplicationModule; container numberSequenceModules; } void init() { ; this.numberSeqPreInit(); super(); ContosoParameters::find(); this.numberSeqPostInit(); } void numberSeqPostInit() { numberSequenceReference_ds.object(fieldNum(NumberSequenceReference, AllowSameAs)).visible(numberSeqApplicationModule.sameAsActive()); referenceSameAsLabel.visible(numberSeqApplicationModule.sameAsActive()); } void numberSeqPreInit() { ; runExecuteDirect = false; numberSequenceModules = [NumberSeqModule::Contoso];\rnumberSeqApplicationModule = new NumberSeqModuleContoso ();\rscope = NumberSeqScopeFactory::createDataAreaScope();\rNumberSeqApplicationModule::createReferencesMulti(numberSequenceModules, scope);\rtmpIdRef.setTmpData(NumberSequenceReference::configurationKeyTableMulti(numberSequenceModules));\r } {% endhighlight %} Code example for NumberSequenceReference data source methods {% highlight csharp %} void removeFilter() { ; runExecuteDirect = false; numbersequenceReference_ds.executeQuery(); } void executeQuery() { if (runExecuteDirect) { super(); } else { runExecuteDirect = true; this.queryRun(NumberSeqReference::buildQueryRunMulti(numberSequenceReference, tmpIdRef, numberSequenceTable, numberSequenceModules, scope)); numbersequenceReference_ds.research(); } } {% endhighlight %} ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:5:2","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"How to use on Table Set number sequence in Contoso Table {% highlight csharp %} private void setContosoId() { NumberSeq num; NumberSequenceReference numberSequenceReference; ; numberSequenceReference = CVRParameters::numRefContosoId(); if (numberSequenceReference)\r{\rnum = NumberSeq::newGetNum(numberSequenceReference);\rthis.Id = num.num();\r}\r } {% endhighlight %} Optional method – in case you don’t want to expose Number sequence on Form Level {% highlight csharp %} public void initValue() { ; super(); // Initialise the title id\rthis. setContosoId ();\r } public void insert() { ; if(!this.Id) { this. setContosoId (); } super();\r } {% endhighlight %} From now on you can create new record in Contoso Table with number sequence. ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:6:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"How to use on Form How to use on form level (In case you don’t want to expose NS in Table Level) In the class declaration of the form that will be accessing data, add a variable declaration for the number sequence handler. The following example shows the variable definition for a number sequence handler. {% highlight csharp %} public class FormRun extends ObjectRun { NumberSeqFormHandler numberSeqFormHandlerContosoId; } {% endhighlight %} Add the NumberSeqFormHandler method to the form. The code in this method will create an instance of the number sequence form handler and return it. {% highlight csharp %} public NumberSeqFormHandler numSeqFormHandlerContosoId() { if (!numberSeqFormHandlerContosoId) { numberSeqFormHandlerContosoId = NumberSeqFormHandler::newForm(ContosoParameters:: numRefContosoId().NumberSequenceId, element, Contoso_ds, fieldNum(Contoso, ContosoId) ); } return numberSeqFormHandlerContosoId; } {% endhighlight %} Add create, delete, and write methods to the data source of the table that contains the field for which the number sequence is being used. The following code examples show these methods that are added to the data source for the Contoso table to support the number sequence for the ContosoId field. {% highlight csharp %} public void create(boolean _append = false) { //before create, (ensure the number seuence has not run out of numbers) element.numSeqFormHandlerContosoId().formMethodDataSourceCreatePre(); // start: inherited table code\r// we need to let the create happen so the user can\r// choose the type\rsuper(_append);\r//number sequence, create action, (get next number)\relement.numSeqFormHandlerContosoId().formMethodDataSourceCreate();\r } public void delete() { //release the number sequence value. element. numSeqFormHandlerContosoId().formMethodDataSourceDelete(); //delete the record\rsuper();\r } public void write() { super(); element. numSeqFormHandlerContosoId().formMethodDataSourceWrite(); } public boolean validateWrite() { boolean ret; ret = super(); ret = element.numberSeqFormHandler().formMethodDataSourceValidateWrite(ret) \u0026\u0026 ret; if (ret) { Contoso.validateWrite(); } return ret; } Link Active() public void linkActive() { ; element.numberSeqFormHandler().formMethodDataSourceLinkActive(); super(); } {% endhighlight %} ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:7:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Optional method Continuous sequence To avoid having gaps for continuous sequence you should add this code to the delete of the table. {% highlight csharp %} public void delete() { super(); NumberSeq::releaseNumber(ContosoParameters::numRefContosoId().NumberSequenceId, this.ContosoId); } {% endhighlight %} ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:8:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Testing Testing Number sequence by Job {% highlight csharp %} static void Max_numberSeqRefCustAccount(Args _args) { NumberSequenceReference numberSeqRefCustAccount = CustParameters::numRefCustAccount(); NumberSeq numSeqCustAccount; try { //Use the TTS level to decide whether sequence is consumed or not. ttsBegin; if (numberSeqRefCustAccount) { numSeqCustAccount = NumberSeq::newGetNum(numberSeqRefCustAccount); if (numSeqCustAccount) { info(numSeqCustAccount.num()); } } ttsCommit; } catch (Exception::Error) { info(“Caught ‘Exception::Error’.\"); } } {% endhighlight %} Thank you for reading! ","date":"January 19, 2017","objectID":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/:9:0","tags":["X++","numbersequence","programming"],"title":"Number sequence farmework overview in Dynamics AX 2012","uri":"/2017-01-19-number-sequence-farmework-in-dynamics-ax-2012/"},{"categories":null,"content":"Overview delete action in Dyanmics AX 2012","date":"January 19, 2017","objectID":"/2017-01-19-overview-delete-action-in-dyanmics-ax-2012/","tags":["delete acitons","AX2012"],"title":"Overview delete action in Dyanmics AX 2012","uri":"/2017-01-19-overview-delete-action-in-dyanmics-ax-2012/"},{"categories":null,"content":"We normally create action delete in foreign table to make sure referential integrity in Logic and validation. The delete action has the following options: None, Restricted, Cascade, Cascade + Restricted None: This has no effect, and effectively disables the delete action. This is useful if you want to specifically state do nothing so that someone else doesn’t try to correct what seems to be an omission. Restricted: This will prevent the record from being deleted if there are records in the related table that match the selected relation. This occurs within the validateDelete table event, which is called by the delete table event. Cascade: This will delete the record in the related table, based on the relation. Ex: A sales order line is of no use without a sales order. This is an extension of the delete table event. Cascade + Restricted This is a little special. In a two-table scenario, it is the same as Restricted. It will stop the record from being deleted if a related record exists. But if the record is being deleted as part of a cascade from a table related to it, the records will be deleted. for more infomation about how to create DeleteActions at MSDN. ","date":"January 19, 2017","objectID":"/2017-01-19-overview-delete-action-in-dyanmics-ax-2012/:0:0","tags":["delete acitons","AX2012"],"title":"Overview delete action in Dyanmics AX 2012","uri":"/2017-01-19-overview-delete-action-in-dyanmics-ax-2012/"},{"categories":["ax2012","trick","tools","integration"],"content":"Handle AIF error messages in dynamics AX 2012 R3","date":"January 12, 2017","objectID":"/2017-01-12-handle-aif-error-messages-in-dynamics-ax-2012-r3/","tags":["xpp","aif"],"title":"Handle AIF error messages in dynamics AX 2012 R3","uri":"/2017-01-12-handle-aif-error-messages-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","trick","tools","integration"],"content":"Normally, when we consume AIF Service, we use this code like below to handle Error messages {% highlight csharp %} try { client.register(ctx, contract); Console.WriteLine(“items registed on Trans Id: \" + contract.InventTransId + \" with \" + contract.Qty + \" quantities.\"); Console.ReadLine(); } catch (Exception ex) { Console.WriteLine(string.Format(“Ex: {0}”, ex.Message)); Console.ReadLine(); } {% endhighlight %} If it cause error, message would return like this If you want to know more details, you have to go In Dynamics ax AIF Exceptions form then check It’s quite hard for 3rd party developer, especially they don’t have right to access AX server. Anyway, we can get meaningful error message by doing below steps Check that box in AIF inbound ports Use FaultException class to get message {% highlight csharp %} try { client.register(ctx, contract); Console.WriteLine(“items registed on Trans Id: \" + contract.InventTransId + \" with \" + contract.Qty + \" quantities.\"); Console.ReadLine(); } catch (System.ServiceModel.FaultException\u003cItemsRegistration.RegRef.AifFault\u003e aifFault) { //FaultMessageList[] list = aifFault.Detail.FaultMessageListArray[0]; InfologMessage[] list = aifFault.Detail.InfologMessageList; foreach (InfologMessage message in list)\r{\rConsole.WriteLine(message.Message);\r}\rConsole.ReadLine();\r } {% endhighlight %} what we got Thank you for reading. ","date":"January 12, 2017","objectID":"/2017-01-12-handle-aif-error-messages-in-dynamics-ax-2012-r3/:0:0","tags":["xpp","aif"],"title":"Handle AIF error messages in dynamics AX 2012 R3","uri":"/2017-01-12-handle-aif-error-messages-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","trick","tools","integration"],"content":"How to create HTTP adapter port","date":"January 12, 2017","objectID":"/2017-01-12-how-to-create-http-adapter-port/","tags":["xpp","aif"],"title":"How to create HTTP adapter port","uri":"/2017-01-12-how-to-create-http-adapter-port/"},{"categories":["ax2012","trick","tools","integration"],"content":"We normally use NETTCP adapter for .NET system, It going to very easy to consume by. As my experience, if we use NETTCP adapter for consuming by Java system, we will need add some extension or 3rd party due to binding and mismatch schema and of course client doesn’t want to do that either me. So, my solution is creating HTTP adapter for Java, you can also use .NET system to consume HTTP adapter without any problems ","date":"January 12, 2017","objectID":"/2017-01-12-how-to-create-http-adapter-port/:0:0","tags":["xpp","aif"],"title":"How to create HTTP adapter port","uri":"/2017-01-12-how-to-create-http-adapter-port/"},{"categories":["ax2012","trick","tools","integration"],"content":"How to do You need to make sure install web services component on Internet Information Services (IIS) and verify that the default website is working. In AX, under System administrator \u003e Services and AIF \u003e Web sites, open from a create new record follow information Name: DynamicsAXAif60 Virtual directory share path: \\\\YourServerName\\MicrosoftDynamicsAXAif60 URL: http://YourServerName/MicrosoftDynamicsAXAif60 From now on, you can create AIF inbound port with HTTP adapter. After you’ve actived the services, that Port will deployed under DynamicsAXAif60 folder in IIS. Thank you for reading. ","date":"January 12, 2017","objectID":"/2017-01-12-how-to-create-http-adapter-port/:0:1","tags":["xpp","aif"],"title":"How to create HTTP adapter port","uri":"/2017-01-12-how-to-create-http-adapter-port/"},{"categories":["ax2012","trick","tools","integration"],"content":"Response in AIF custom service class","date":"January 12, 2017","objectID":"/2017-01-12-respone-in-aif-custom-service-class/","tags":["xpp","aif"],"title":"Response in AIF custom service class","uri":"/2017-01-12-respone-in-aif-custom-service-class/"},{"categories":["ax2012","trick","tools","integration"],"content":"At the previous post I already show how to customize Response Value list in AIF Document standard service, today we will talk about response in Custom AIF service class. We already know for Custom AIF service we actually need 2 classes, one is contract for data input and one is service to process a logic. With Response class, it’s literally same with contract class. They both hold parm value. contract class gets parametters. Response class sets return values. ","date":"January 12, 2017","objectID":"/2017-01-12-respone-in-aif-custom-service-class/:0:0","tags":["xpp","aif"],"title":"Response in AIF custom service class","uri":"/2017-01-12-respone-in-aif-custom-service-class/"},{"categories":["ax2012","trick","tools","integration"],"content":"Scenario I want to get HcmPersonnelNumberId and HcmWorkerName of current userID on C#.NET application. ","date":"January 12, 2017","objectID":"/2017-01-12-respone-in-aif-custom-service-class/:0:1","tags":["xpp","aif"],"title":"Response in AIF custom service class","uri":"/2017-01-12-respone-in-aif-custom-service-class/"},{"categories":["ax2012","trick","tools","integration"],"content":"Solution Write Custom AIF service to get Worker information, and then public this service. Write C#.NET console to consume that service. ","date":"January 12, 2017","objectID":"/2017-01-12-respone-in-aif-custom-service-class/:0:2","tags":["xpp","aif"],"title":"Response in AIF custom service class","uri":"/2017-01-12-respone-in-aif-custom-service-class/"},{"categories":["ax2012","trick","tools","integration"],"content":"Walkthrough Response class {% highlight csharp %} [DataContractAttribute] class MaxWorkerResponse { str gId; str gName; } {% endhighlight %} two value that I want to return is HcmPersonnelNumberId and HcmWorkerName, I will store it in 2 parms method {% highlight csharp %} [DataMemberAttribute(‘HcmWorkerName’)] public HcmWorkerName parmName(HcmWorkerName _name = gName) { gName = _name; return gName;\r } [DataMemberAttribute(‘HcmPersonnelNumberId’)] public HcmPersonnelNumberId parmId(HcmPersonnelNumberId _id = gId) { gId = _id; return gId;\r } {% endhighlight %} Service class Create MaxPRService Class, This class consume through service that need to be extend SysOperationServiceBase class {% highlight csharp %} class MaxPRService extends SysOperationServiceBase { } {% endhighlight %} Main logic {% highlight csharp %} [SysEntryPointAttribute(true), AifCollectionTypeAttribute(‘return’, Types::String)] public MaxWorkerResponse getEmployee() { HcmWorkerRecId workerRecId; HcmPersonnelNumberId personnelNumber; HcmWorkerName name; MaxWorkerResponse response; workerRecId = DirPersonUser::currentWorker();\rpersonnelNumber = HcmWorker::find(workerRecId).PersonnelNumber;\rname = HcmWorker::find(workerRecId).name();\rresponse = new MaxWorkerResponse();\rresponse.parmId(personnelNumber);\rresponse.parmName(name);\rreturn response;\r } {% endhighlight %} Create service In AOT create new service and add recent created class to that Service, in operations node add getEmployee method, you will get something likes Then right click service \u003e Add-ins \u003e Register Service. go to AIF inbound form to create new service and add getEmployee operation to that service then Active. Consume service Add recent WSDL URI http://WINSERVER:8104/DynamicsAx/Services/MaxPurchReqGeneral into Service reference in C# Console project {% highlight csharp %} static void Main(string[] args) { CallContext context = new CallContext() { Company = “USMF”, Language = “EN-US”, }; MaxPRServiceClient client = new MaxPRServiceClient();\rMaxWorkerResponse response = client.getEmployee(context);\rConsole.WriteLine(response.HcmWorkerName + \", \" + response.HcmPersonnelNumberId);\rConsole.ReadLine();\r } {% endhighlight %} Thank you for reading. ","date":"January 12, 2017","objectID":"/2017-01-12-respone-in-aif-custom-service-class/:0:3","tags":["xpp","aif"],"title":"Response in AIF custom service class","uri":"/2017-01-12-respone-in-aif-custom-service-class/"},{"categories":["ax2012","trick","tools","integration"],"content":"AIF Custom response value in Dynamics AX 2012 R3","date":"January 11, 2017","objectID":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/","tags":["xpp","aif"],"title":"AIF Custom response value in Dynamics AX 2012 R3","uri":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","trick","tools","integration"],"content":"For this demonstration, I use AIF service to create Sales order with SalesSalesOrderService and I gonna consume AIF using C#.NET. Normally, in consume service application we handle return value by using EntityKeyList, EntityKey, KeyData[0].Value. And for Sales Order It will return Created SalesID. Let’s take a look on AxdSalesOrder class. More about Axd class please prefer this. Then go to createList method, this method will handle response value {% highlight csharp %} public AifEntityKeyList createList( AifDocumentXml _xml, AifEndpointActionPolicyInfo _actionPolicyInfo, AifConstraintListCollection _constraintListCollection) { AifEntityKeyList aifEntityKeyList; aifEntityKeyList = super(_xml, _actionPolicyInfo, _constraintListCollection);\r// Sales orders are committed - master planning explosion can be executed and confirmed dates be set\rthis.postSalesOrderCreation(aifEntityKeyList);\rreturn aifEntityKeyList;\r } {% endhighlight %} So, how about customer wants another meaning value beside SalesID likes InventTransId information in SalesLine table or another tables base on your requirement. To do that, we need to customize this method. ","date":"January 11, 2017","objectID":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/:0:0","tags":["xpp","aif"],"title":"AIF Custom response value in Dynamics AX 2012 R3","uri":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","trick","tools","integration"],"content":"How to do I will use Map and MapEnumerator classes (Please refer MSDN to understand these class), this is steps: We get the SalesId from the original entityKeyList and add into Map. add Map to MapEnumerator. Use SalesId to find the sales line. (mapEnumerator.currentValue() can get current SalesID). Create a new entityKey and insert the sales line information to this entityKey. add back entityKey to entityKeyList From here in entityKeyList will store information of SalesID and List fields of SalesLine table. Here is the code for createList method, beside SalesId I will try to get InventTransId in SalesLine Table {% highlight csharp %} public AifEntityKeyList createList( AifDocumentXml _xml, AifEndpointActionPolicyInfo _actionPolicyInfo, AifConstraintListCollection _constraintListCollection) { AifEntityKeyList aifEntityKeyList; SalesId salesId;\rSalesLine salesLine;\rAifEntityKey entityKey;\rAifEntityKey salesEntityKey;\rMap keyDataMap;\rMap salesOrderMap;\rMapEnumerator mapEnumerator;\raifEntityKeyList = super(_xml, _actionPolicyInfo, _constraintListCollection);\r// Sales orders are committed - master planning explosion can be executed and confirmed dates be set\rthis.postSalesOrderCreation(aifEntityKeyList);\rentityKey = aifEntityKeyList.getEntityKey(1);\rkeyDataMap = entityKey.parmKeyDataMap();\rmapEnumerator = keyDataMap.getEnumerator();\rwhile (mapEnumerator.moveNext())\r{\rsalesId = mapEnumerator.currentValue();\rif (salesId)\r{\rwhile select InventTransId, RecId from salesLine\rwhere salesLine.SalesId == salesId\r{\rsalesEntityKey = new AifEntityKey();\rsalesOrderMap = new Map(Types::Integer, Types::Container);\rsalesEntityKey.parmTableId(tableNum(SalesLine));\rsalesEntityKey.parmRecId(salesLine.RecId);\rsalesOrderMap.insert(fieldNum(SalesLine, InventTransId), [salesLine.InventTransId]);\rsalesEntityKey.parmKeyDataMap(salesOrderMap);\raifEntityKeyList.addEntityKey(salesEntityKey);\r}\r}\r}\rreturn aifEntityKeyList;\r } {% endhighlight %} Code in C#.NET to get list key {% highlight csharp %} SalesOrderServiceClient client = new SalesOrderServiceClient(); try { EntityKey[] salesOrderCreatedEntity = client.create(callContext, salesOrder); //EntityKey salesOrderCreated = (EntityKey)salesOrderCreatedEntity.GetValue(0); System.Collections.IEnumerator enumerator = salesOrderCreatedEntity.GetEnumerator();\rwhile (enumerator.MoveNext())\r{\rEntityKey salesOrderCreated = (EntityKey)enumerator.Current;\rConsole.WriteLine(salesOrderCreated.KeyData[0].Field);\rConsole.WriteLine(salesOrderCreated.KeyData[0].Value);\r}\r//Console.WriteLine(\"The sales order created has a Sales ID of \" + salesOrderCreated.KeyData[0].Value);\rConsole.ReadLine();\r } catch (Exception e) { Console.WriteLine(e.ToString()); Console.ReadLine(); } {% endhighlight %} Here is what we got Just remember this one just for AIF Document Standard, for AIF custom service we do another way I will so in next post. Thank you for reading. ","date":"January 11, 2017","objectID":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/:0:1","tags":["xpp","aif"],"title":"AIF Custom response value in Dynamics AX 2012 R3","uri":"/2017-01-11-aif-custom-response-value-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","trick","tools","integration"],"content":"Using batch to find and block vendor base on last transaction condition and notify for them by emails.","date":"January 10, 2017","objectID":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/","tags":["xpp","batch"],"title":"How to block vendor and send email for notification.","uri":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/"},{"categories":["ax2012","trick","tools","integration"],"content":"Main requirements is Using batch to find and block vendor base on last transaction condition and notify for them by emails. ","date":"January 10, 2017","objectID":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/:0:0","tags":["xpp","batch"],"title":"How to block vendor and send email for notification.","uri":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/"},{"categories":["ax2012","trick","tools","integration"],"content":"Set up E-mail parameters For set up email, we need Go to AX System administrator \u003e Setup \u003e E-mail parameters ","date":"January 10, 2017","objectID":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/:0:1","tags":["xpp","batch"],"title":"How to block vendor and send email for notification.","uri":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/"},{"categories":["ax2012","trick","tools","integration"],"content":"Vendor emails Vendor emails locate on LogisticsElectronicAddress.Locator, partyTable.PrimaryContactEmail, partyLocation.Location, please take a look on this job to find how to update Vendor emails and you also could see the relations more clearly. {% highlight csharp %} static void UpdateVendorEmail(Args _args) { VendTable vendTable; LogisticsElectronicAddress electronicAddress; DirPartyTable partyTable; DirPartyLocation partyLocation; electronicAddress.initValue();\relectronicAddress.Type = LogisticsElectronicAddressMethodType::Email;\relectronicAddress.Description = \"Max Nguyen\";\relectronicAddress.Locator = \"luan52@outlook.com\";\relectronicAddress.IsPrimary = NoYes::Yes;\relectronicAddress.insert();\rwhile select forUpdate partyTable\rexists join vendTable\rwhere vendTable.Party == partyTable.RecId\r{\rttsBegin;\rpartyTable.PrimaryContactEmail = electronicAddress.RecId;\rpartyTable.update();\rttsCommit;\rselect firstOnly forupdate partyLocation\rwhere partyLocation.Party == partyTable.RecId;\rif (partyLocation)\r{\rttsBegin;\rpartyLocation.Location = electronicAddress.Location;\rpartyLocation.update();\rttsCommit;\r}\relse\r{\rpartyLocation.initValue();\rpartyLocation.Location = electronicAddress.Location;\rpartyLocation.Party = partyTable.RecId;\rpartyLocation.insert();\r}\r}\r } {% endhighlight %} ","date":"January 10, 2017","objectID":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/:0:2","tags":["xpp","batch"],"title":"How to block vendor and send email for notification.","uri":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/"},{"categories":["ax2012","trick","tools","integration"],"content":"Batch class Main logic here is find Vend accounts are not exist in VendTrans table with condition endTrans.TransDate \u003e= beginDate, and beginDate count from today systemDateGet(). {% highlight csharp %} public class Max_VendorBlockedBatch extends RunBaseBatch { } {% endhighlight %} Get the date before 6 months from today {% highlight csharp %} public TransDate getBeginDate() { TransDate beginDate; TransDate currentDate; Months month; YearBase years; Day day; currentDate = systemDateGet();\rday = dayOfMth(currentDate);\rmonth = mthOfYr(currentDate);\ryears = year(currentDate);\rif (month \u003c 6)\r{\rbeginDate = mkDate(day, 12 - (6 - month) + 1, years - 1);\r}\relse\r{\rbeginDate = mkDate(day, month - 6 + 1, years);\r}\rreturn beginDate;\r } {% endhighlight %} Send E-mail {% highlight csharp %} public void sendEmail(AccountNum _vendor, str _recipient) { str sender = ‘sender@email.com’; str subject = ‘Account blocked’; str body = ‘Your account is blocked due to last transaction’; List toList; ListEnumerator le; Set permissionSet; System.Exception e; str mailServer; int mailServerPort; System.Net.Mail.SmtpClient mailClient; System.Net.Mail.MailMessage mailMessage; System.Net.Mail.MailAddress mailFrom; System.Net.Mail.MailAddress mailTo; System.Net.Mail.MailAddressCollection mailToCollection; try { toList = strSplit(_recipient, ‘;'); permissionSet = new Set(Types::Class); permissionSet.add(new InteropPermission(InteropKind::ClrInterop)); CodeAccessPermission::assertMultiple(permissionSet); mailServer = SysEmaiLParameters::find(false).SMTPRelayServerName; mailServerPort = SysEmaiLParameters::find(false).SMTPPortNumber; mailClient = new System.Net.Mail.SmtpClient(mailServer, mailServerPort); le = toList.getEnumerator(); le.moveNext(); mailFrom = new System.Net.Mail.MailAddress(sender); mailTo = new System.Net.Mail.MailAddress(strLTrim(strRTrim(le.current()))); mailMessage = new System.Net.Mail.MailMessage(mailFrom, mailTo);  mailToCollection = mailMessage.get_To(); while (le.moveNext()) { mailToCollection.Add(strLTrim(strRTrim(le.current()))); } mailMessage.set_Priority(System.Net.Mail.MailPriority::High); mailMessage.set_Subject(subject); mailMessage.set_Body(body); mailClient.Send(mailMessage); mailMessage.Dispose(); CodeAccessPermission::revertAssert(); info(strFmt(‘Email was sent to vendor %1.’, _vendor)); } catch (Exception::CLRError) { e = ClrInterop::getLastException(); while (e) { info(e.get_Message()); e = e.get_InnerException(); }  CodeAccessPermission::revertAssert(); } } {% endhighlight %} Initializes a new instance of the Batch class. {% highlight csharp %} public static MAX_VendorBlockedBatch construct() { return new MAX_VendorBlockedBatch(); } {% endhighlight %} Gets description of the dialog. {% highlight csharp %} public static ClassDescription description() { return ‘Vendor blocked batch’; } {% endhighlight %} Find the vendor without transaction and disable, then send email to vendor {% highlight csharp %} public void run() { VendTrans vendTrans; VendTable vendTable; TransDate beginDate; Email email; int i; try\r{\rbeginDate = this.getBeginDate();\rwhile select forUpdate AccountNum, Party from vendTable\rNotexists join vendTrans\rwhere vendTrans.AccountNum == vendTable.AccountNum\r\u0026\u0026 vendTrans.TransDate \u003e= beginDate\r{\r//Set the vendor blocked\rttsBegin;\rvendTable.Blocked = CustVendorBlocked::All;\rvendTable.update();\rttsCommit;\r//Send E-mail to vendor\remail = vendTable.email();\rif (email)\r{\rthis.sendEmail(vendTable.AccountNum, email);\r}\relse\r{\rwarning(strFmt('The vendor %1 did not have E-mail address.', vendTable.AccountNum));\r}\r}\r}\rcatch (Exception::Deadlock)\r{\rretry;\r}\r } {% endhighlight %} Provides an enter point for the Batch class. {% highlight csharp %} public static void main(Args _args) { MAX_VendorBlockedBatch vendorBlockedBatch = MAX_VendorBlockedBatch::construct(); if (vendorBlockedBatch.prompt())\r{\rvendorBlockedBatch.run();\r}\r } {% endhighlight %} From here you can run class and set up recurrence for batch job. Thank you for rea","date":"January 10, 2017","objectID":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/:0:3","tags":["xpp","batch"],"title":"How to block vendor and send email for notification.","uri":"/2017-01-10-block-vendor-and-send-email-for-notification-in-dynamics-ax/"},{"categories":["ax2012","trick","tools"],"content":"Simple summary Keys are in Dynamics AX","date":"January 3, 2017","objectID":"/2017-01-03-simple-custom-serivce-in-ax-r3/","tags":["key"],"title":"Simple summary Keys are in Dynamics AX","uri":"/2017-01-03-simple-custom-serivce-in-ax-r3/"},{"categories":["ax2012","trick","tools"],"content":" There is a maximum of one Primary Key per table, whereas a table can have several alternate keys. The primary key is usually the type of key that other tables, called child tables, refer to when a foreign key field in those other tables need a relational identifier. For new tables the default is a primary key based on the RecId field , incremented number or a completely meaningless number that is generated by the system surrogate key. Alternate key can be chosen as the Replacement Key of a table that can display on forms instead of a meaningless numeric primary key value. Each table can have a maximum of one replacement key. Natural key has meaning to people. Most replacement keys are natural keys. Relations represents a foreign key. Thank you for reading! ","date":"January 3, 2017","objectID":"/2017-01-03-simple-custom-serivce-in-ax-r3/:0:0","tags":["key"],"title":"Simple summary Keys are in Dynamics AX","uri":"/2017-01-03-simple-custom-serivce-in-ax-r3/"},{"categories":["ax2012","trick","problem"],"content":"AX1004 error in Dynamics AX","date":"January 2, 2017","objectID":"/2017-01-02-ax1004-error/","tags":["error"],"title":"AX1004 error in Dynamics AX","uri":"/2017-01-02-ax1004-error/"},{"categories":["ax2012","trick","problem"],"content":"I got this error at version Dynamics 2012 R3 CU9, SQL Server 2014, Windows Server 2012 R2. Those kind of errors will come when you move report from Dev Server to Live Server, even compilation in DP Class, Query, Contract, table … without any error Image_rounded {:.rounded} AX1004: Reference System.Core, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089 was not a valid model assembly. MSB3644: The reference assemblies for framework “.NETFramework,Version=v4.0” were not found. To resolve this, install the SDK or Targeting Pack for this framework version or retarget your application to a version of the framework for which you have the SDK ","date":"January 2, 2017","objectID":"/2017-01-02-ax1004-error/:0:0","tags":["error"],"title":"AX1004 error in Dynamics AX","uri":"/2017-01-02-ax1004-error/"},{"categories":["ax2012","trick","problem"],"content":"Cause There is no reference Assemblies Version 4.0 under C:\\Program Files (x86)\\Reference Assemblies\\Microsoft\\Framework\\.NETFramework on Windows Server 2012 R2 (only Version 4.5 it have) ","date":"January 2, 2017","objectID":"/2017-01-02-ax1004-error/:0:1","tags":["error"],"title":"AX1004 error in Dynamics AX","uri":"/2017-01-02-ax1004-error/"},{"categories":["ax2012","trick","problem"],"content":"Solution Copy those Assemblies from your any where (Windows 7,8,10) to Server Restore and compile again. Thank you for reading! ","date":"January 2, 2017","objectID":"/2017-01-02-ax1004-error/:0:2","tags":["error"],"title":"AX1004 error in Dynamics AX","uri":"/2017-01-02-ax1004-error/"},{"categories":["ax2012","trick","tools"],"content":"Recalculate InventSum in Dynamics AX","date":"January 2, 2017","objectID":"/2017-01-02-recalculate-inventsum/","tags":["inventsum","expression","trick","xpp","programming"],"title":"Recalculate InventSum in Dynamics AX","uri":"/2017-01-02-recalculate-inventsum/"},{"categories":["ax2012","trick","tools"],"content":"InventSum is needed to recalculate sometimes. We should use InventSumRecalcItem class in Dynamics AX. {% highlight csharp %} InventSumRecalcItem InventSumRecalcItem; ; InventSumRecalcItem = new InventSumRecalcItem(“ITEM001”, true, checkfix::fix); InventSumRecalcItem.updatenow(); {% endhighlight %} First parameter : ItemId Second parameter : Show errors Third parameter : Fix or only check What if you want to calculate for all items: {% highlight csharp %} InventTable InventTable; InventSumRecalcItem InventSumRecalcItem; WHILE SELECT InventTable WHERE (InventTable.ItemType == ItemType::Item) || (InventTable.ItemType == ItemType::BOM) { InventSumRecalcItem = new InventSumRecalcItem(InventTable.ItemId, true, checkfix::fix); InventSumRecalcItem.updatenow(); } {% endhighlight %} Thank you for reading! ","date":"January 2, 2017","objectID":"/2017-01-02-recalculate-inventsum/:0:0","tags":["inventsum","expression","trick","xpp","programming"],"title":"Recalculate InventSum in Dynamics AX","uri":"/2017-01-02-recalculate-inventsum/"},{"categories":["ax2012","trick","tools"],"content":"Simple summary Keys are in Dynamics AX","date":"January 2, 2017","objectID":"/2017-01-02-simple-summary-keys-are-in-dynamics-ax/","tags":["key"],"title":"Simple summary Keys are in Dynamics AX","uri":"/2017-01-02-simple-summary-keys-are-in-dynamics-ax/"},{"categories":["ax2012","trick","tools"],"content":" There is a maximum of one Primary Key per table, whereas a table can have several alternate keys. The primary key is usually the type of key that other tables, called child tables, refer to when a foreign key field in those other tables need a relational identifier. For new tables the default is a primary key based on the RecId field , incremented number or a completely meaningless number that is generated by the system surrogate key. As The RecId data type, surrogate keys exist on a primary key table. As The RefRecId ETD, surrogate foreign keys exist on a foreign key table (Ex: Party field is on CustTable Table). Alternate key can be chosen as the Replacement Key of a table that can display on forms instead of a meaningless numeric primary key value. Each table can have a maximum of one replacement key. Natural key has meaning to people. A set of fields that uniquely identify a record and would have formed the primary key of the table, if not for the existence of a surrogate key. Relations represents a foreign key. Thank you for reading! ","date":"January 2, 2017","objectID":"/2017-01-02-simple-summary-keys-are-in-dynamics-ax/:0:0","tags":["key"],"title":"Simple summary Keys are in Dynamics AX","uri":"/2017-01-02-simple-summary-keys-are-in-dynamics-ax/"},{"categories":["ax2012","tools","trick"],"content":"Using Methods in Table Filters \u0026 Query Ranges in Dynamics AX 2012","date":"January 2, 2017","objectID":"/2017-01-02-using-methods-in-table-filters-query-ranges-in-dynamics-ax-2012/","tags":["trick","sysqueryrangeutil","QUERYFILTER","QUERYBUILDRANGE"],"title":"Using Methods in Table Filters \u0026 Query Ranges in Dynamics AX 2012","uri":"/2017-01-02-using-methods-in-table-filters-query-ranges-in-dynamics-ax-2012/"},{"categories":["ax2012","tools","trick"],"content":"In Dynamics AX, there is a class called SysQueryRangeUtil that can be utilized in both query ranges and table filters. Using methods from this class allow you to be very precise about what dates you want to use in reports or for filtering your data. Let’s say you have a report that you always want to run to see orders with shipping dates of the next day. It is possible to do so by using one of the methods from the SysQueryRangeUtil. The use of the letter ’t' will work for today’s date, but when you try to add days to it, it doesn’t work in reports. Instead, I will use the currentdate() method and add 1 to it. All methods \u0026 expressions must be surrounded by parentheses as shown below. Filtering the requested ship dates in an AX query for tomorrow (current day() + 1) On any form with a grid, you filter your data by pressing Ctrl+G. If I were to want to see open customer invoices from the last 90 days, I would filter my open customer invoices form and use the method (dayRange(-90,0)). The first number represents how many months backward from this month, and the second represents how many months forward. The same sorts of things can be done for the monthRange(), yearRange(), and dateRange() methods. The best part about this is that you can of course save these filters to create views that you might use on a daily basis. If you are creating your query ranges in code, these methods can also be utilized whenever you are setting them. Definitely be sure to check out the SysQueryRangeUtil class as there are many more methods to use. Here is some methods you can use: {% highlight html %} currentCustomerAccount() currentVendorAccount() currentUserId() currentDate() dateRange() day() dayRange() greaterThanDate() greaterThanUtcDate() greaterThanUtcNow() lessthanDate() lessthanUtcDate() lessthanUtcNow() monthRange() yearRange() {% endhighlight %} for example: {% highlight html %} (dayRange(-30,0)) – Results in a date range for the last 30 days: “26-01-2017”..“25-02-2017” (day(-1)) – Results in yesterday’s date: 24-02-2017 (day(0)) – Results in today’s date: 25-02-2017 (day(1)) – Results in tomorrow’s date: 26-02-2017 (greaterThanDate(2)) – Results in every date after today plus 2: \u003e 27-02-2017 (lessThanDate(-1)) – Results in every date of today minus 1: \u003c 24-02-2017 (monthRange(0,2)) – Results in first day till the last day of the month’s choosen (0 = current month): “01-02-2017”..“30-04-2017” (yearRange(-1,-1)) – Results in first day till the last day of the chosen year: “01-01-2017”..“31-12-2017” {% endhighlight %} Thank you for reading! ","date":"January 2, 2017","objectID":"/2017-01-02-using-methods-in-table-filters-query-ranges-in-dynamics-ax-2012/:0:0","tags":["trick","sysqueryrangeutil","QUERYFILTER","QUERYBUILDRANGE"],"title":"Using Methods in Table Filters \u0026 Query Ranges in Dynamics AX 2012","uri":"/2017-01-02-using-methods-in-table-filters-query-ranges-in-dynamics-ax-2012/"},{"categories":["ax2012","sql","trick"],"content":"Difference between QUERYFILTER and QUERYBUILDRANGE","date":"January 1, 2017","objectID":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/","tags":["buildquery","programming","QUERYFILTER","QUERYBUILDRANGE"],"title":"Difference between QUERYFILTER and QUERYBUILDRANGE","uri":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/"},{"categories":["ax2012","sql","trick"],"content":"In Dynamics AX, we have two way to filter the result set of records in joined query is using QueryFilter class and QueryBuildRange class. So what’s difference between them? when do we use QueryFilter class? When do we use QueryBuildRange class? Today, i will make a simple sample to show what is difference between them. You can download example project from here. I have two table : Table DuyDang_ParentTable which have 1 columns : ID. Table DuyDang_ChildTable which have 3 columns : ID, ParentID, Qty. and they have relation like this : DuyDang_ParentTable.ID = DuyDang_ChildTable.ParentID. I have the Outer Join query: ","date":"January 1, 2017","objectID":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/:0:0","tags":["buildquery","programming","QUERYFILTER","QUERYBUILDRANGE"],"title":"Difference between QUERYFILTER and QUERYBUILDRANGE","uri":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/"},{"categories":["ax2012","sql","trick"],"content":"Use QueryFilter class: {% highlight csharp %} static void DuyDang_QueryFilter(Args _args) { Query query; QueryBuildDataSource qbds, qbds1; QueryRun queryRun; DuyDang_ParentTable parentTable; DuyDang_ChildTable childTable; QueryFilter qFilter; QueryBuildRange qRange; struct structSet; structSet = new struct\r(\"str ParentID;\"\r+ \"str ChildID;\"\r+ \"real Quantity\"\r);\rquery = new Query();\rqbds = query.addDataSource(tableNum(DuyDang_ParentTable)); qbds1 = qbds.addDataSource(tableNum(DuyDang_ChildTable)); qbds1.joinMode(JoinMode::OuterJoin); // Set join type. qbds1.addLink(fieldNum(DuyDang_ParentTable, ID), fieldNum(DuyDang_ChildTable, ParentID));\rqFilter = query.addQueryFilter(qbds1, 'Qty');\rqFilter.value(queryValue(15));\r//qRange = qbds1.addRange(fieldNum(DuyDang_ChildTable, Qty));\r//qRange.value(queryValue(15));\rqueryRun = new QueryRun(query); while (queryRun.next())\r{\rparentTable = queryRun.get(tableNum(DuyDang_ParentTable));\rchildTable = queryRun.get(tableNum(DuyDang_ChildTable));\rstructSet.value(\"ParentID\", parentTable.ID);\rstructSet.value(\"ChildID\", childTable.ID);\rstructSet.value(\"Quantity\", childTable.Qty);\rinfo(structSet.toString());\r}\r } {% endhighlight %} and result info here: ","date":"January 1, 2017","objectID":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/:0:1","tags":["buildquery","programming","QUERYFILTER","QUERYBUILDRANGE"],"title":"Difference between QUERYFILTER and QUERYBUILDRANGE","uri":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/"},{"categories":["ax2012","sql","trick"],"content":"Use QueryBuildRange class: {% highlight csharp %} static void DuyDang_QueryFilter(Args _args) { Query query; QueryBuildDataSource qbds, qbds1; QueryRun queryRun; DuyDang_ParentTable parentTable; DuyDang_ChildTable childTable; QueryFilter qFilter; QueryBuildRange qRange; struct structSet; structSet = new struct\r(\"str ParentID;\"\r+ \"str ChildID;\"\r+ \"real Quantity\"\r);\rquery = new Query();\rqbds = query.addDataSource(tableNum(DuyDang_ParentTable)); qbds1 = qbds.addDataSource(tableNum(DuyDang_ChildTable)); qbds1.joinMode(JoinMode::OuterJoin); // Set join type. qbds1.addLink(fieldNum(DuyDang_ParentTable, ID), fieldNum(DuyDang_ChildTable, ParentID));\r//qFilter = query.addQueryFilter(qbds1, 'Qty');\r//qFilter.value(queryValue(15));\rqRange = qbds1.addRange(fieldNum(DuyDang_ChildTable, Qty));\rqRange.value(queryValue(15));\rqueryRun = new QueryRun(query); while (queryRun.next())\r{\rparentTable = queryRun.get(tableNum(DuyDang_ParentTable));\rchildTable = queryRun.get(tableNum(DuyDang_ChildTable));\rstructSet.value(\"ParentID\", parentTable.ID);\rstructSet.value(\"ChildID\", childTable.ID);\rstructSet.value(\"Quantity\", childTable.Qty);\rinfo(structSet.toString());\r}\r } {% endhighlight %} and result info here: now you can see the difference between them When you use QueryBuidRange class, the restriction is in the ON clause of the OUTER JOIN in the ANSI SQL select statement that is generated by the AOS for the underlying database system. {% highlight sql %} SELECT * FROM DuyDang_ParentTable(DuyDang_ParentTable_1) OUTER JOIN * FROM DuyDang_ChildTable(DuyDang_ChildTable_1) ON DuyDang_ParentTable.ID = DuyDang_ChildTable.ParentID AND ((Qty = 15)) {% endhighlight %} When you use QueryFilter class, the restriction is in the WHERE clause of the OUTER JOIN in the ANSI SQL select statement that is generated by the AOS for the underlying database system. {% highlight sql %} SELECT * FROM DuyDang_ParentTable(DuyDang_ParentTable_1) OUTER JOIN * FROM DuyDang_ChildTable(DuyDang_ChildTable_1) ON DuyDang_ParentTable.ID = DuyDang_ChildTable.ParentID WHERE ((DuyDang_ChildTable(DuyDang_ChildTable_1).Qty = 15)) {% endhighlight %} Thank you for reading! ","date":"January 1, 2017","objectID":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/:0:2","tags":["buildquery","programming","QUERYFILTER","QUERYBUILDRANGE"],"title":"Difference between QUERYFILTER and QUERYBUILDRANGE","uri":"/2017-01-01-difference-between-queryfilter-and-querybuildrange/"},{"categories":["ax2012","integration"],"content":"CRUD Purchase Requisition using AIF in Dynamics AX 2012 R3","date":"December 29, 2016","objectID":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase Requisition using AIF in Dynamics AX 2012 R3","uri":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"The workflow process moves purchase requisitions through the review process, from an initial status of Draft to a final status of Approved. When a purchase requisition is submitted for review, the workflow process is started. After a purchase requisition is approved, a purchase order can be generated for the purchase requisition lines and submitted to the vendor for order fulfillment. We will use AIF standard service for import PR from outside, service name PurchReqImportService. in AxPurchReqTable class and setPurchReqId() method {% highlight csharp %} protected void setPurchReqId() { NumberSequenceReference numberSequenceReference; if (this.isMethodExecuted(funcName()))\r{\rreturn;\r}\rif (this.isFieldSetExternally(fieldNum(PurchReqTable, PurchReqId)))\r{\rif (this.isSetMethodsCalledFromSave())\r{\rif (!this.purchReqTable())\r{\rnumberSequenceReference = PurchReqTable::numRefPurchReqId();\rthis.checkNumber(numberSequenceReference.numberSequenceTable(),fieldNum(PurchReqTable,PurchReqId),this.parmPurchReqId());\rif (numberSequenceReference.NumberSequenceId \u0026\u0026 numberSequenceReference.numberSequenceTable().Continuous)\r{\rNumberSeq::newReserveNum(numberSequenceReference).reserve(this.parmPurchReqId());\r}\r}\r}\r}\relse\r{\rif (this.isFieldSet(fieldNum(PurchReqTable, PurchReqId)))\r{\rreturn;\r}\rif (!this.parmPurchReqId())\r{\rif (this.isSetMethodsCalledFromSave())\r{\r//this.parmPurchReqId(NumberSeq::newGetNum(PurchParameters::numRefPurchReqId()).num());\rnumberSequenceReference = PurchReqTable::numRefPurchReqId();\rif(numberSequenceReference)\r{\rthis.setField(fieldNum(PurchReqTable, PurchReqId), NumberSeq::newGetNum(PurchParameters::numRefPurchReqId()).num());\r}\relse\r{\rthis.setField(fieldNum(PurchReqTable, PurchReqId), this.parmExternalSourceID());\r}\r}\r}\r}\r } {% endhighlight %} Base on this method, you could know how System get PurchReqId. ","date":"December 29, 2016","objectID":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/:0:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase Requisition using AIF in Dynamics AX 2012 R3","uri":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"How to do Go to Inbound ports form to create new service with NETTCP adapter, choose service operations likes below: Then active AIF inbound service ","date":"December 29, 2016","objectID":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/:0:1","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase Requisition using AIF in Dynamics AX 2012 R3","uri":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Consume Pruchase requisition service Open visual studio and create new console project. Add service reference http://DEV-ERP:8101/DynamicsAx/Services/MavPurchaseRequisition This one just for demo, so I just create code base on required fields of AIF. Here is the code in main method {% highlight csharp %} PurchReqImportServiceClient client = new PurchReqImportServiceClient(); CallContext context = new CallContext() { Company = “BGR”, Language = “En-us” }; AxdEntity_PurchReqLine purchReqLine = new AxdEntity_PurchReqLine() { Requisitioner = “000007”, BuyingLegalEntity = “BGR”, ItemId = “110329”, PurchUnitOfMeasure = “Box”, CurrencyCode = “KRW”, PurchQty = 100, PurchQtySpecified = true, PriceUnit = 1, PriceUnitSpecified = true, }; // Create an instance of the document class. AxdEntity_PurchReqTable purchReqTable = new AxdEntity_PurchReqTable() { PurchReqId = “”, PurchReqName = “Purch Req by Max”, ExternalSourceID = “PR002”, ExternalSourceName = “PR002”, AutoSubmitToWorkflowRequired = AxdEnum_NoYes.No, StatusToBeSaved = AxdEnum_PurchReqCreationStatus.Draft, RequisitionStatus = AxdEnum_PurchReqRequisitionStatus.Draft, RequisitionStatusSpecified = true, RequiredDate = new DateTime(2016, 12, 30), RequiredDateSpecified = true, TransDate = new DateTime(2016, 12, 30), TransDateSpecified = true, PurchReqLine = new AxdEntity_PurchReqLine[1] { purchReqLine } }; // Create instances of the entities that are used in the service and // set the needed fields on those entities. AxdPurchReqImport purchReq = new AxdPurchReqImport() { PurchReqTable = new AxdEntity_PurchReqTable[1] { purchReqTable } }; try { client.create(context, purchReq); } catch (Exception e) { Console.WriteLine(e.ToString()); Console.ReadLine(); } {% endhighlight %} Run it and check result in AX Please prefer previous post for another operations Thank you for reading! ","date":"December 29, 2016","objectID":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/:0:2","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase Requisition using AIF in Dynamics AX 2012 R3","uri":"/2016-12-29-crud-purchase-requisition-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Due to Purchase order doesn’t have Standard document service so we have to create new Document service for that using AIF wizards. I’m using AIF document service with NETTCP or HTTP Adapter to Create Purchase order service, here is steps ","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:0:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Create Query with three datasouce (PurchTable, PurchLine, InventDim) likes below As best practice for Document service, name of query should be start with Axd* prefix. ","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:1:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Using AIF Wizards In AX development environment, go to Tools \u003e Wizards \u003e AIF document service wizards Choose recent created query and click next. ","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:2:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Create Service operation and AxBC class Click next and then Generate. You will get service project in Private project ","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:3:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Deploy and create service • Right click on PurchOrderService \u003e Add-Ins \u003e Register service • System administration \u003e Setup \u003e Services and AIF \u003e Inbound ports • Click New on Inbound ports form and name the Service. • Adapter: NETTCP (it also works with HTTP adapter) • In Service contract customizations fast tab click Service operations Active recent created Service ","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:4:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Consume service using C#.NET After service is activated, you can get WSDL URI likes http://servername:port/DynamicsAx/Services/PurchaseOrder Create console project and Add Service References, the code below In Class, I will write method to return list of EnityKey PurchId {% highlight csharp %} private static EntityKey[] EntityForPurchId(string purchId) { KeyField field = new KeyField() { Field = “PurchId”, Value = purchId }; EntityKey key = new EntityKey()\r{\rKeyData = new[] { field }\r};\rreturn new[] { key };\r } {% endhighlight %} Code for create purchase order {% highlight csharp %} var dim = new AxdEntity_InventDim() { InventSiteId = “DN”, InventLocationId = “F10-S120”, InventBatchId = “BATCH001” }; var purchLine = new AxdEntity_PurchLine() { ItemId = “220067”, PurchQty = 15, PurchUnit= “ea”, InventDim = new AxdEntity_InventDim[] { dim }\r }; var purchTable = new AxdEntity_PurchTable() { OrderAccount = “101-01-75441”, LanguageId = “en-us”, CurrencyCode = “KRW”, PurchName = “AIF PO Test”, PurchLine = new AxdEntity_PurchLine[] { purchLine } }; AxdMav_PurchOrderService purchOrder = new AxdMav_PurchOrderService(); purchOrder.PurchTable = new AxdEntity_PurchTable[] { purchTable }; CallContext callContext = new CallContext { Company = “bgr”, Language = “en-us” }; Mav_PurchOrderServiceServiceClient client = new Mav_PurchOrderServiceServiceClient(); try { EntityKey[] purchOrderCreatedEntity = client.create(callContext, purchOrder); EntityKey purchOrderCreated = (EntityKey)purchOrderCreatedEntity.GetValue(0); Console.WriteLine(\"The purch order created has a Purch ID of \" + purchOrderCreated.KeyData[0].Value);\rConsole.ReadLine();\r } catch (Exception e) { Console.WriteLine(e.ToString()); Console.ReadLine(); } {% endhighlight %} Code for read purchase order {% highlight csharp %} EntityKey[] entityKeyList = EntityForPurchId(“BGR-000054”); CallContext callContext = new CallContext(); callContext.Company = “bgr”; Mav_PurchOrderServiceServiceClient client = new Mav_PurchOrderServiceServiceClient(); AxdMav_PurchOrderService purchOrders = client.read(callContext, entityKeyList); AxdEntity_PurchTable[] purchTables = purchOrders.PurchTable; AxdEntity_PurchTable purchTable = purchTables[0]; AxdEntity_PurchLine purchLine = purchTable.PurchLine[0]; Console.WriteLine(“Purch Name: \" + purchTable.PurchName); Console.WriteLine(“Order Account: \" + purchTable.OrderAccount); Console.WriteLine(“Language Id: \" + purchTable.LanguageId); Console.WriteLine(“Qty: \" + purchLine.PurchQty); Console.WriteLine(“Item Id: \" + purchLine.ItemId); client.Close(); Console.ReadLine(); {% endhighlight %} Code for update purchase order {% highlight csharp %} Mav_PurchOrderServiceServiceClient client = new Mav_PurchOrderServiceServiceClient(); CallContext callContext = new CallContext(); callContext.Company = “bgr”; EntityKey[] entityKeyList = EntityForPurchId(“BGR-000078”); AxdMav_PurchOrderService purchOrders = client.read(callContext, entityKeyList); //salesOrders.GetHashCode(); AxdEntity_PurchTable[] purchTables = purchOrders.PurchTable; AxdEntity_PurchTable purchTable = new AxdEntity_PurchTable(); purchTable = purchTables.First(); //salesTable.GetHashCode(); AxdEntity_PurchLine purchLine = new AxdEntity_PurchLine(); purchLine = purchTable.PurchLine.First(); decimal purchQty = 20; purchLine.PurchQty = purchQty; try { client.update(callContext, entityKeyList, purchOrders); EntityKey purchOrdersUpdated = (EntityKey)entityKeyList.GetValue(0); Console.WriteLine(“The purchase order has been updated has a Purch ID of \" + purchOrdersUpdated.KeyData[0].Value + \" with Qty \" + purchQty.ToString() + “\"); Console.ReadLine(); } catch (Exception ex) { Console.WriteLine(ex.ToString()); Console.ReadLine(); } {% endhighlight %} Code for delete purchase order {% highlight csharp %} Mav_PurchOrderServiceServiceClient client = new Mav_PurchOrderServiceServiceClient(); CallContext callContext = new CallContext(); callContext.Company = “bgr”; EntityKey[] entityKeyList = EntityForPurchId(“BGR-0","date":"December 28, 2016","objectID":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/:5:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Purchase order using AIF in Dynamics AX 2012 R3","uri":"/2016-12-28-crud-purchase-order-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Insert, update, Delete order line through AIF In AX 2012 R3","date":"December 28, 2016","objectID":"/2016-12-28-insert-update-delete-order-line-through-aif-in-ax-2012-r3/","tags":["aif","programming","csharpdotnet","xpp"],"title":"Insert, update, Delete order line through AIF In AX 2012 R3","uri":"/2016-12-28-insert-update-delete-order-line-through-aif-in-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"In previous post, I already show how to create purchase order through AIF with NETTCP or HTTP adapter. In this post, we will get little deep more about action on line of order. The following code sample shows how to insert, update, delete a line of an existing purchase order through AIF, currently I’m using C#.NET console project for demo. As Partial update, we must include just the fields to change and any fields required by the document (you can check Data policies in AIF Service ports form for that). Also, notice how action properties are specified – no matter we do with the line, which means updating the order. I’m giving you an idea how it looks like, here is the code The first method will handle the key of AIF Service {% highlight csharp %} private static EntityKey[] EntityForPurchId(string purchId) { KeyField field = new KeyField() { Field = “PurchId”, Value = purchId }; EntityKey key = new EntityKey()\r{\rKeyData = new[] { field }\r};\rreturn new[] { key };\r } {% endhighlight %} create Line, delete Line, update line in Purchase order {% highlight csharp %} EntityKey[] entityKeyList = EntityForPurchId(“BGR-000054”); CallContext callContext = new CallContext(); callContext.Company = “bgr”; Mav_PurchOrderServiceServiceClient client = new Mav_PurchOrderServiceServiceClient(); AxdMav_PurchOrderService purchOrders = client.read(callContext, entityKeyList); //Define which line need to be update or delete var lastLine = purchOrders.PurchTable[0].PurchLine.Last(); var purchLine = new AxdEntity_PurchLine() { ItemId = “110329”, PurchQty = 1, CurrencyCode = “KRW”, RecIdSpecified = true, LineNumberSpecified = true, action = AxdEnum_AxdEntityAction.create, actionSpecified = true //for delete\r//RecId = lastLine.RecId,\r//RecIdSpecified = true,\r//action = AxdEnum_AxdEntityAction.delete,\r//actionSpecified = true\r//for Update\r//RecId = lastLine.RecId,\r//RecIdSpecified = true,\r//action = AxdEnum_AxdEntityAction.update,\r//actionSpecified = true\r }; var purchTable = new AxdEntity_PurchTable() { _DocumentHash = purchOrders.PurchTable[0]._DocumentHash, OrderAccount = “101-01-75441”, LanguageId = “en-us”, CurrencyCode = “KRW”, PurchName = “AIF PO Test”, action = AxdEnum_AxdEntityAction.update, actionSpecified = true, PurchLine = new[] { purchLine } }; AxdMav_PurchOrderService purchOrder = new AxdMav_PurchOrderService() { PurchTable = new AxdEntity_PurchTable[] {purchTable} }; client.update(callContext, entityKeyList, purchOrder); {% endhighlight %} Thank you for reading! ","date":"December 28, 2016","objectID":"/2016-12-28-insert-update-delete-order-line-through-aif-in-ax-2012-r3/:0:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"Insert, update, Delete order line through AIF In AX 2012 R3","uri":"/2016-12-28-insert-update-delete-order-line-through-aif-in-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"CRUD Items, products, products master dimension, variants using AIF in Dynamics AX 2012 R3","date":"December 27, 2016","objectID":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Items, products, products master dimension, variants using AIF in Dynamics AX 2012 R3","uri":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Scenarios: I’m trying to create product/master product in Dynamics AX using AIF inbound port, the AIF services consume by C#.NET. From AX 2012 R2, Item is replaced with Product. Item master was in Inventory Management Module, now there is a separate module for item/product creation Product information Management. Some definitions you should know There are two types of Products in 2012 they are: Product Product information management/Common/Products/Products Product Master Product information management/Common/Products/Products master a. Variants: To create a product variant, you must define at least one product dimension for a product master. You can also rename dimensions. To create product variants, you must complete the following tasks: Set up dimensions, such as size, color, and style. Set up variant groups. Assign variant groups to a retail hierarchy. Create a product master and variants. b. Product dimensions Product dimensions are characteristics that serve to identify a product variant. You can use combinations of product dimensions to define product variants. You must define at least one product dimension for a product master to create a product variant. ","date":"December 27, 2016","objectID":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/:1:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Items, products, products master dimension, variants using AIF in Dynamics AX 2012 R3","uri":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"Process: Normally in AX, we create items master follow process: Create product/product master. Assigning Dimensions Groups to a Product Master. Create Product dimension combinations (Product Variants) Release product to legal entities Assigning Item Model Group \u0026 Item Groups to a Product Master ","date":"December 27, 2016","objectID":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/:2:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Items, products, products master dimension, variants using AIF in Dynamics AX 2012 R3","uri":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012","integration"],"content":"How to do: Ax provides us standard services for this purpose, so we don’t need to create any custom services for this. I will use 4 services for this purpose, descriptions below Service Purpose EcoResProductService Create products (all types). The service can also be used to retrieve data that has already been created (Create Product details in The EcoRes tables). —- EcoResProductMasterDimValueService Specify values of product dimensions for a product master. These values become available for the creation of product variants. The service can also be used to retrieve data that has already been created. —- ItemService Release distinct products and product masters. The service can also be used to retrieve data that has already been created. —- InventDimCombinationService Release product variants. The service can also be used to retrieve data that has already been created. {: rules=“groups”} we have 4 steps Create 4 AIF inbound services against Services operation above and active it http://DEV-ERP:8103/DynamicsAx/Services/BCEcoResProduct http://DEV-ERP:8103/DynamicsAx/Services/BCEcoResProductMasterDimValue http://DEV-ERP:8103/DynamicsAx/Services/BCItemsMaster http://DEV-ERP:8103/DynamicsAx/Services/BCInventDimCombination After services creation, open visual studio then creates new Console project and add service References for that, you will get somethings like pic below: Using C#.Net to consume service {% highlight csharp %} using ItemsMaster.ItemsRef; using ItemsMaster.EcoResProductRef; using ItemsMaster.EcoResProductMasterRef; using ItemsMaster.InventDimRef; static void Main(string[] args) { Program master = new Program(); master.createDistinctProduct(); Program.releaseProduct(); } {% endhighlight %} EcoResProductServiceClient {% highlight csharp %} public void createDistinctProduct() { AxdEntity_Product_EcoResDistinctProduct distinctProduct = new AxdEntity_Product_EcoResDistinctProduct() { DisplayProductNumber = “MAX00002”, ProductType = AxdEnum_EcoResProductType.Item, SearchName = “Max”, };\rdistinctProduct.Translation = new AxdEntity_Translation[1];\rdistinctProduct.Translation[0] = new AxdEntity_Translation()\r{\rLanguageId = \"en-us\",\rName = \"Max Nguyen\"\r};\rdistinctProduct.Identifier = new AxdEntity_Identifier[1];\rdistinctProduct.Identifier[0] = new AxdEntity_Identifier()\r{\rProductNumber = \"MAX00002\"\r};\rdistinctProduct.StorageDimGroup = new AxdEntity_StorageDimGroup[1];\rdistinctProduct.StorageDimGroup[0] = new AxdEntity_StorageDimGroup()\r{\rProduct = \"MAX00002\",\rStorageDimensionGroup = \"SW_P\"\r};\rdistinctProduct.TrackingDimGroup = new AxdEntity_TrackingDimGroup[1];\rdistinctProduct.TrackingDimGroup[0] = new AxdEntity_TrackingDimGroup()\r{\rProduct = \"MAX00002\",\rTrackingDimensionGroup = \"Batch Only\"\r};\rAxdEcoResProduct product = new AxdEcoResProduct()\r{\rProduct = new AxdEntity_Product_EcoResProduct[1] { distinctProduct }\r};\rEcoResProductRef.CallContext EcoResProductSctx = new EcoResProductRef.CallContext()\r{\rCompany = \"bgr\",\rLanguage = \"en-us\",\r};\rEcoResProductRef.EcoResProductServiceClient ecoResProductSClient = new EcoResProductRef.EcoResProductServiceClient();\recoResProductSClient.create(EcoResProductSctx, product);\r } {% endhighlight %} EcoResProductServiceClient {% highlight csharp %} public void createMaster() { AxdEntity_Product_EcoResProductMaster productMaster = new AxdEntity_Product_EcoResProductMaster() { DisplayProductNumber = “MAX00002”, ProductType = AxdEnum_EcoResProductType.Item, SearchName = “Max Nguyen” }; productMaster.Translation = new AxdEntity_Translation[1];\rproductMaster.Translation[0] = new AxdEntity_Translation()\r{\rLanguageId = \"en-us\",\rName = \"Max Nguyen\"\r};\rproductMaster.Identifier = new AxdEntity_Identifier[1];\rproductMaster.Identifier[0] = new AxdEntity_Identifier()\r{\rProductNumber = \"MAX00002\"\r};\rproductMaster.ProductDimGroup = new AxdEntity_ProductDimGroup[1];\rproductMaster.ProductDimGroup[0] = new AxdEntity_ProductDimGroup()\r{\rProduct = \"MAX00002\",\rProductDimensionGroup = \"MAX10\"\r};\rproductMaster.Vari","date":"December 27, 2016","objectID":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/:3:0","tags":["aif","programming","csharpdotnet","xpp"],"title":"CRUD Items, products, products master dimension, variants using AIF in Dynamics AX 2012 R3","uri":"/2016-12-27-crud-items-products-products-master-dimension-variants-using-aif-in-dynamics-ax-2012-r3/"},{"categories":["ax2012"],"content":"The Microsoft Dynamics AX runtime manages the storage of value type data on the call stack and reference type objects on the memory heap. The call stack is the memory structure that holds data about the active methods called during program execution. The memory heap is the memory area that allocates storage for objects that are destroyed automatically by the Microsoft Dynamics AX run-time. ","date":"November 24, 2016","objectID":"/2016-11-25-the-type-system-of-dynamics-ax-2012/:0:0","tags":["operator","programming"],"title":"The Type system of Dynamics AX 2012","uri":"/2016-11-25-the-type-system-of-dynamics-ax-2012/"},{"categories":["ax2012"],"content":"Value types Value types include the built-in primitive types, extended data types, enumeration types, and built-in collection types. The primitive types are boolean, int, int64, real, date, utcDateTime, timeofday, str, and guid. The extended data types are specialized primitive types and specialized base enumerations. The enumeration types are base enumerations and extended data types. The collection types are the built-in array and container types. By default, variables declared as value types are assigned their zero value by the Microsoft Dynamics AX runtime. These variables can’t be set to null. Variable values are copied when variables are used to invoke methods and when they are used in assignment statements. Therefore, two value type variables can’t reference the same value. ","date":"November 24, 2016","objectID":"/2016-11-25-the-type-system-of-dynamics-ax-2012/:1:0","tags":["operator","programming"],"title":"The Type system of Dynamics AX 2012","uri":"/2016-11-25-the-type-system-of-dynamics-ax-2012/"},{"categories":["ax2012"],"content":"Reference types Reference types include the record types, class types, and interface types. The record types are table, map, and view. User-defined record types are dynamically composed from application model layers. Microsoft Dynamics AX runtime record types are exposed in the system application programming interface (API). Although the methods are not visible in the AOT, all record types implement the methods that are members of the system xRecord type, a Microsoft Dynamics AX runtime class type. User-defined class types are dynamically composed from application model layers and Microsoft Dynamics AX runtime class types exposed in the system API. Interface types are type specifications and can’t be instantiated in the Microsoft Dynamics AX runtime. Class types can, however, implement interfaces. Variables declared as reference types contain references to objects that the Microsoft Dynamics AX runtime instantiates from dynamically composed types defined in the application model layering system and from types exposed in the system API. The Microsoft Dynamics AX runtime also performs memory deallocation (garbage collection) for these objects when they are no longer referenced. Reference variables declared as record types reference objects that the Microsoft Dynamics AX runtime instantiates automatically. Class type objects are programmatically instantiated using the new operator. Copies of object references are passed as reference parameters in method calls and are assigned to reference variables, so two variables can reference the same object. Thank you for reading! ","date":"November 24, 2016","objectID":"/2016-11-25-the-type-system-of-dynamics-ax-2012/:2:0","tags":["operator","programming"],"title":"The Type system of Dynamics AX 2012","uri":"/2016-11-25-the-type-system-of-dynamics-ax-2012/"},{"categories":["services","ax2012"],"content":"Document services Document services use documents to represent business objects such as purchase and sales orders, customers, vendors, and so on. A document service is composed of the following components: Document query : This is a query that is created in the Application Object Tree (AOT) and contains all the tables that are related to the business object that you want to expose. Based on this query, the Document Service Generation Wizard can be used to generate the other artifacts that make up the document service. Table AxBC classes : An AxBC class is a wrapper for a table and contains business logic that is needed for Create, Read, Update, Delete (CRUD) operations. Document class : The purpose of the document class is to contain business logic that is associated with the creation and modification of the business entity itself. For example, the AxdCustomer class could contain logic to handle party information of a customer. Document service class : This is the actual service implementation class and extends the AifDocumentService class. This class implements the service operations that are published through the service contract. When creating document services, developers need to make sure that the business object is mapped correctly to the document query. The document services framework will handle all other things such as the serialization and deserialization of XML, date effectiveness, and so on. Document services can be deployed using the integration ports and all available adapters can be used. Custom services Custom services were already available in Microsoft Dynamics AX 2009, but support for Extended Data Types(EDTs) was limited, which resulted in developers having to provide custom serialization and deserialization logic. Microsoft Dynamics AX 2012 introduces the concept of attributes. Attributes provide a way to specify metadata about classes and methods. Two of these attributes are used when creating data contracts: the DataContractAttribute and DataMemberAttribute attributes. The ‘DataContractAttribute’ attribute is used to define that a class is a data contract. The’DataMemberAttribute' attribute is added to methods of data contracts that represent data members that have to be exposed. This way of defining data contracts is very similar to other programming languages such as C#. Support for more complex data types such as collections and tables has been added so that these types can be serialized and deserialized without developers having to provide the logic themselves. In a typical custom service you will find the following components: Service contract : A service contract is an X++ class that contains methods with the SysEntryPointAttribute attribute. This identifies methods that will result in a service operation contract when the service is exposed. Data contracts : A data contract is an X++ class that is attributed with the DataContractAttribute attribute. It contains parameter methods that will be attributed as data members for each member variable that needs to be part of the data contract. Custom services can be deployed using the integration ports and any available adapter can be used. System services These services are new since the release of Microsoft Dynamics AX 2012. The main difference between these services and the previous two types is that they are not customizable and are not mapped to a query or X++ code. They are not customizable because they are written by Microsoft in managed code. One exception is the user session service, which is written in X++ code but is generally considered as a system service. There are three system services available for use in Microsoft Dynamics AX 2012: the query service, the metadata service, and the user session service. Query service The query service provides the means to run queries of the following three types: Static queries defined in the AOT. User-defined queries by using the QueryMetaData class in the service. Dynamic queries that are written in X++ ","date":"November 10, 2016","objectID":"/2016-11-10-types-services-microsoft-dynamics-ax-2012/:0:0","tags":["aif","xpp","aos"],"title":"Types of services in Microsoft Dynamics AX 2012","uri":"/2016-11-10-types-services-microsoft-dynamics-ax-2012/"},{"categories":["ax2012","tools"],"content":"SUMMARY Tool can be used for two different purposes. One is to install demo data and other one is elaborated as below. Customers often need to have a production dataset to use when building and validating customizations in non-production environments. The Microsoft Dynamics AX 2012 Test Data Transfer Tool (beta) is a tool that helps move data between from production to non-production environments or from non-production environments to production environments to make a new production environment. But you must be careful becasue the tool imports data table by table and deletes the data in the table before importing. Hence it is highly advised against running the tool for import in production environments. ","date":"November 8, 2016","objectID":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/:1:0","tags":["xpp","data","trick"],"title":"Microsoft AX 2012 Test Data Transfer Tool","uri":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/"},{"categories":["ax2012","tools"],"content":"BENEFITS Export and import data outside AX, without running an AOS instance. Export and import processing are faster compared to other tools because this tool is based on SQL Server bcp. The tool can work around the table/field metadata changes between builds and environments and hence can be used to move data from build to build, and environment to environment even when there are customizations, and metadata changes. The tool minimally changes data during the import process. The only data the tool changes are the entity IDs (IDs related to table, field, etc.) that are stored as data and that could change with each deployment. The tool recognizes the changes and patches the data with the AXIDs of the system that the data is being imported into. The data file format is the standard format produced by SQL Server bcp. The output is text based and can be stored and compared against other versions in a version control system. ","date":"November 8, 2016","objectID":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/:2:0","tags":["xpp","data","trick"],"title":"Microsoft AX 2012 Test Data Transfer Tool","uri":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/"},{"categories":["ax2012","tools"],"content":"How to Download AX2012TestDataTransferTool.zip file from LCS ahihi PROD Environment Run the setup file in SQL SERVER environment and complete the installation. “C:\\Program Files (x86)\\Microsoft Dynamics AX 2012 Test Data Transfer Tool (Beta)\" file appears automatically. Find the MetadataXMLGenerator.xpo file and import it into AX. A job named MetadataXMLGenrator appears among AOT/jobs. Find and run the job. Job generates a file named MetaData.Xml and gives you a file path via infolog. Copy MetaData.Xml file and paste in “C:\\Program Files (x86)\\Microsoft Dynamics AX 2012 Test Data Transfer Tool (Beta)[Lists]\" file in Prod(Golden) SQL SERVER. Overwrite the existing MetaData.Xml file. DEV or TEST Environment Repeat the steps 2-6 for DEV environment. The windows user who is going to execute the process should have access MicrosoftDynamicsAx ve Model database in DEV and Prod SQL servers. “Read” is enough for (Prod) exporting. “Full” right is enough for importing (DEV). The windows user who is going to execute the process should have “full” access “C:\\Program Files (x86)\\Microsoft Dynamics AX 2012 Test Data Transfer Tool (Beta)\" in both DEV and Prod SQL servers. System generates logs here. Now, Live (Golden) environment’s data will be exported. Prepare a file to export live(Golden) data on Live SQL Server. For instance C:\\DC_EXPORT Type the following command in command line and initiate the exportation process: DP.exe EXPORT Directory\u003e\u003e Database name\u003e\u003e Server\u003e\u003e DP.exe EXPORT C:\\DC_EXPORT \"MicrosoftDynamicsAX\" \"ServerName\" Copy the exported file (C:\\DC_EXPORT) to DEV environment Stop DEV AOS service Type the following command in command line and initiate the importation process: DP.exe IMPORT Directory\u003e\u003e Database name\u003e\u003e Server\u003e\u003e Start DEV AOS service. Note: DP.exe EXPORT/IMPORT commands must be run from the related directories ","date":"November 8, 2016","objectID":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/:2:1","tags":["xpp","data","trick"],"title":"Microsoft AX 2012 Test Data Transfer Tool","uri":"/2016-11-08-microsoft_dyanmics_ax_2012_test_data_transfer_tool/"},{"categories":["ax2012","general"],"content":"Dear all, We use modifiedField() method to perform any actions after the field is modifed Ex: Create new table with 2 fields ItemId and ItemNameDisplay from Extended Data Types node in AOT then Override modifiedField() in Table’s method node, something likes: public void modifiedField(FieldId _fieldId) { InventTable inventTable; super(_fieldId); switch (_fieldId) { case fieldNum(IBD_Invent,itemid): this.ItemNameDisplay = inventTable::find(this.itemid).NameAlias; break; } } the modifiedField() method is located on tables and it is called by a form (or a dataset) when any field is changed. It has field ID as a parameter and therefore it is very easy to write code reacting to a change of a particular field. It is so easy that the modifiedField() method is often used even in such cases, when it really shouldn’t be used. If you want to get previous field value in the modifiedField() for comparative purpose, you can use this.orig() method: public void modifiedField(fieldId _fieldId) { super(_fieldId); info(strfmt(\"Field number %1 changed from %2 to %3\",_fieldId,this.orig().(_fieldId),this.(_fieldId))); } ","date":"November 8, 2016","objectID":"/2016-11-08-understanding_modifedfield_table_method_in_dax_2012/:0:0","tags":["xpp","modifedField"],"title":"Understanding modifedField() Table method in DAX 2012","uri":"/2016-11-08-understanding_modifedfield_table_method_in_dax_2012/"},{"categories":null,"content":"Expressions are usually used for appearance of the data in a report, change properties of the fields, calculate some values and display them in a proper way, compares values between data of fields and then display them. Types of Expressions We have 3 types: Globals Operators - Arithmetic, Comparison,Concatenation, Logical Common Functions - Text, Date \u0026 Time, Math, Inspection, Program Flow, Aggregate, Financial, Conversion, Miscellaneous We can see each and every one very deataily ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:0:0","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"1. Globals Global expressions executes/works in Page Header and Footer parts only. ExecutionTime Shows date and time at when report executes PageNumber shows page number of each and every page but allowed only in page header and footer ReportName displays name of the active report what name we have assigned to the active report UserId shows current user name like company/userID Language displays language like US-English… ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:1:0","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"2. Operators ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:2:0","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Arithmetic ^ power of *multiplication / divides two numbers and returns a floating point result : divides two numbers and returns a integer result Mod divides two numbers and returns remainder only adds two numbers and concatenation for two strings - subtraction and indicates negative value for numeric values \r","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:2:1","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Comparison Known operators : \u003c \u003c= \u003e \u003e= \u003c\u003e Like compares two strings and return true if matched or else returns False. Ex: =Fields!Title.Value Like Fields!LoginID.Value Is compare two object reference variables Ex: =Fields!Title.Value Is Null ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:2:2","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Concatenation + and \u0026 symbols uses for concatenation ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:2:3","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Logical Known: And, Not, Or, Xor SELECT*FROMuserswherefirstname='Larry'XORlastname='Smith'`AndAlso First condition will check first and if it is true only, goes to next or else it won’t need to check. Because our execution time is saving in a logical operation in which more conditions is combined using AndAlso function. OrElse same like above ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:2:4","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"3. Common Functions ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:0","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Text Asc, AscW returns an integer value represents character code corresponding to a character. Chr, chrw returns the character associated with the specified character code Filter =Filter(Fields!Title.Value,“Pr”,true,0) Format=Format(Fields!Price.Value, “#,##0.00”), Format(Fields!Date.Value, “yyyy-MM-dd”) FormatCurrency =formatcurrency(Fields!SickLeaveHours.Value,3) FormatDateTime =FormatDateTime(Fields!BirthDate.Value,Integer) Ex: 0 returns 6/3/1977 1 returns Friday, June 03, 1977 2 returns 6/3/1977 3 returns 12:00:00AM 4 returns 00:00 FormatNumber =FormatNumber(Fields!EmployeeID.Value,2), then result is 2.00 FormatPercent =“Percentage : \" \u0026 formatpercent(Fields!SickLeaveHours.Value) GetChar =GetChar(Fields!Title.Value,5) InStr =InStr(Fields!Title.Value,“a”) InStrRev =Instrrev(Fields!Title.Value,“a”) LCase =Lcase(Fields!Title.Value), Change strings into lower case Left =Left(Fields!Title.Value,4), Returns left side characters from a string Len =Len(Fields!Title.Value), Finds length of a string LSet =Lset(Fields!Title.Value,5), Returns some length of a string from left LTrim =Ltrim(” “\u0026Fields!Title.Value), Trim left side of a string Mid =Mid(Fields!Title.Value,InSTrRev(Fields!Title.Value,“T”)), Returns characters from the mentioned starting position Replace =Replace(Fields!Title.Value,“a”,“A”), Replaces one string with another Right =Right(Fields!Title.Value,10), Returns right side characters from a string RSet =Rset(Fields!Title.Value,5),Returns some length of a string from left RTrim =Rtrim(Fields!Title.Value \u0026 \" “), Trim left side of a string Space =Fields!Title.Value \u0026 Space(5) \u0026 Fields!Title.Value, Specifies some spaces within strings StrComp Returns a value indicating the result of a string comparison vbBinaryCompare 0 Perform a binary comparison. vbTextCompare 1 Perform a textual comparison. string1 is less than string2 -1 string1 is equal to string2 0 string1 is greater than string2 1 string1 or string2 is Null Null StrConv =Strconv(Fields!Title.Value,vbProperCase) =Strconv(Fields!Title.Value,vbLowerCase) =Strconv(Fields!Title.Value,vbUpperCase) StrDup =StrDup(3,“M”), Returns a string or object consisting of the specified character repeated the specified number of times. StrReverse =StrReverse(Fields!Title.Value) Trim =Trim(” “\u0026 Fields!Title.Value \u0026 \" “) UCase =Ucase(Fields!Title.Value) ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:1","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Date \u0026 Time CDate Converts a object into date format =Format(CDate(Fields!BirthDate.Value),“MMMM yyyy”) DateAdd Returns a datetime that is the result of adding the specified number of time interval units to the original datetime. =dateadd(“m”,12,Fields!BirthDate.Value) DateDiff Find number of days, months and years between two dates =datediff(“d”,Fields!BirthDate.Value,Now) DatePart DatePart(DateInterval.Weekday, CDate(“2009/11/13”), FirstDayOfWeek.Monday) returns 5 (Friday) DateSerial for first day of the month =DateSerial(Year(Now), Month(Now), 1) for the last day of the month =DateSerial(Year(Now), Month(Now)+1, 0) DateString Returns string value of system date =datestring() DateValue Returns current date Day Returns day value from date =day(Fields!BirthDate.Value) FormatDateTime =FormatDateTime(Fields!BirthDate.Value,Integer) Examples: 0 returns 6/3/1977 1 returns Friday, June 03, 1977 2 returns 6/3/1977 3 returns 12:00:00AM 4 returns 00:00 Hour =Hour(Fields!BirthDate.Value) Minute =Minute(Fields!BirthDate.Value) Month =Month(Fields!BirthDate.Value) MonthName =MonthName(Month(Fields!BirthDate.Value)) Now Indicates current month =Now() or =Now Second =Second(Fields!BirthDate.Value) TimeOfDay =TimeOfDay() Returns a date value containing the current time of day according to your system Timer =Timer() Returns number of seconds elapsed since midnight TimeSerial =TimeSerial(24,60,60) Returns a date value representing a specified hour, minute and second TimeString =TimeString() Returns string value representing the current time of day according to your system TimeValue Returns a date value set to jan 1 of year 1 =TimeValue(Fields!BirthDate.Value) Today Returns Current date Weekday Returns an integer value representing day of week =WeekDay(Fields!BirthDate.Value) WeekdayName =WeekdayName(Weekday(Fields!BirthDate.Value)) Returns name of the day of week Year =year(Fields!BirthDate.Value) Returns year of specified date ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:2","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Math Abs=Abs(-2.36) Returns the absolute value BigMul =BigMul(2,3) Returns multiplication value of two specified numbers Ceiling =Ceiling(2.67) Returns next highest value Cos=Cos(2.33) Returns cos value for specified number Cosh=Cosh(2.33) Returns hyperbolic cos value DivRem=DivRem(23,2,5) Fix=Fix(23.89) Returns integer portion Floor=Floor(24.54) Returns largest integer Int=Int(24.78) Returns integer portion of a number Log=Log(24.78) Returns logarithm value Log10=Log10(24.78) Returns the base 10 logaritm value Max=Max(Fields!EmployeeID.Value) Returns larger value in the specified values Min=Min(Fields!EmployeeID.Value) Returns smaller value in the specified values Pow=Pow(Fields!EmployeeID.Value,2) Returns power of value for specified number Rnd=Rnd() Returns a random number Round=Round(43.16) Returns rounded value to the nearest integer Sign=Sign(-34534543) Sin=Sin(Fields!EmployeeID.Value) Returns the sin value Sinh=Sinh(Fields!EmployeeID.Value) Returns the hyperbolic sin value ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:3","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Inspection IsArray\r=IsArray(Fields!EmployeeID.Value) Returns a boolean value indicating whether the specified object is array or not IsDate\r=IsDate(Fields!BirthDate.Value) Returns a boolean value indicating whether the specified object is Date or not IsNothing\r=IsNothing(Fields!EmployeeID.Value) Returns a boolean value depends on specified object is Nothing or not IsNumeric\r=IsNumeric(Fields!EmployeeID.Value) Returns a boolean value depends on specified object is Numeric value or not ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:4","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Program Flow Choose\r=CHOOSE(3, \"Red\", \"Yellow\", \"Green\", \"White\") Returns a specific value using index in a list of arguments IIf\r=IIF(Fields!EmployeeID.Value\u003e10,\"Yes\",\"No\") Returns any one value depends on condition Switch\r=Switch(Fields!EmployeeID.Value\u003c10,\"Red\",Fields!EmployeeID.Value\u003e10,\"Green\") Evaluates list of expressions ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:5","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Aggregate Avg\r=Avg(Fields!EmployeeID.Value) Returns average value for all specified values Count\r=Count(Fields!EmployeeID.Value) Returns count of all specified values CountDistinct\r=CountDistinct(Fields!EmployeeID.Value) Returns count of all distinct values CountRows\r=CountRows() Returns count of rows First\r=First(Fields!EmployeeID.Value) Returns first for all specified values Last\r=Last(Fields!EmployeeID.Value) Returns last for all specified values Max\r=Max(Fields!EmployeeID.Value) Returns max for all specified values Min\r=Min(Fields!EmployeeID.Value) Returns min for all specified values StDev\r=StDev(Fields!EmployeeID.Value) Returns standard deviation value StDevP\r=StDevP(Fields!EmployeeID.Value) Returns Population standard deviation value Sum\r=Sum(Fields!EmployeeID.Value) Returns sum of all values Var\r=Var(Fields!EmployeeID.Value) Returns variance of all values VarP\r=Var(Fields!EmployeeID.Value) Returns population variance of all values RunningValue\r=RunningValue(Fields!EmployeeID.Value,sum,nothing) Returns running aggregate of the specified expression ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:6","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Financial DDB DDB (Double Declining Balance) method computes depreciation of an asset for a specified period. Syntax: DDB (Cost, Salvage, life, period, factor) FV FV (Future Value) of an investment based on periodic, constant payments and a constant interest rate. Syntax: FV (rate, nper, pmt, pv, type) IPmt IPmt (Interest Payment) for a given period for an investment based on periodic, constant payment and a constant interest rate IPMT (rate, per, nper, pv, fv, type) IRR IRR (Interest Rate of Return) for a series of cash flows represented by the numbers in values. IRR(values,guess) MIRR MIRR ( Modified internal rate of return ) for a series of periodic cash flows MIRR(values,finance_rate,reinvest_rate) NPer Returns the number of periods for an investment based on periodic, constant payments and a constant interest rate. NPER (rate, pmt, pv, fv, type) NPV Calculates the net present value of an investment by using a discount rate and a series of future payments (negative values) and income (positive values). Syntax: NPV(rate,value1,value2, ...) Pmt Calculates the payment for a loan based on constant payments and a constant interest rate. PMT(rate,nper,pv,fv,type) PPmt Returns the payment on the principal for a given period for an investment based on periodic, constant payments and a constant interest rate. PPMT(rate,per,nper,pv,fv,type) PV Returns the present value of an investment. The present value is the total amount that a series of future payments is worth now. For example, when you borrow money, the loan amount is the present value to the lender. PV(rate,nper,pmt,fv,type) Rate Returns the interest rate per period of an annuity. RATE is calculated by iteration and can have zero or more solutions. RATE(nper,pmt,pv,fv,type,guess) SLN Returns the straight-line depreciation of an asset for one period. SLN(cost,salvage,life) SYD Returns the sum-of-years' digits depreciation of an asset for a specified period. SYD(cost,salvage,life,per) ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:7","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Conversion CBool Convert to boolean CByte Convert to byte CChar Convert to char CDate Convert to date CDbl Convert to double CDec Convert to decimal CInt Convert to integer CLng Convert to long CObj Convert to object CShort Convert to short CSng Convert to single CStr Convert to string Hex =Hex(Fields!EmployeeID.Value) Returns a hexadecimal value of a number Int =Int(43.44) Returns integer portion of a number Oct =Oct(Fields!EmployeeID.Value) Returns a octal value of a number Str =Str(Fields!EmployeeID.Value) Returns string value of a number Val =Val(\"32.43\") Returns numeric value in string format ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:8","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":null,"content":"Miscellaneous Previous =Previous(Fields!EmployeeID.Value) Returns the previous value ","date":"October 7, 2016","objectID":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/:3:9","tags":null,"title":"Expressions or Functions used in SSRS","uri":"/2016-10-07-ssrs-sql-server-reporting-services-expressions-or-functions-used-in-ssrs/"},{"categories":["ax2012","trick"],"content":"Sometime we need this RecId value in DimansionAttributeValueCombination Table for some reasons likes putting new dimension in LedgerDimension field in LedgerJournalTrans Table, or somewhere else. Suppose my Account structure likes: MainAcct - Dept - Woker - SubAcct - Item, you can custom base on your struture. This code is for creating a record into DimansionAttributeValueCombination in code and then get RecID of this. static void createDimensionAttributeValueCombination(Args _args) { DimensionAttributeValueContract ValueContract; DimensionAttributeValueCombination davc; MainAccount valueMainAccount; DimensionStorage dimStorage; DimensionServiceProvider DimensionServiceProvider = new DimensionServiceProvider(); LedgerAccountContract LedgerAccountContract = new LedgerAccountContract(); List ListValueContract = new List(Types::Class); // Get main account with structure : Mainacct - DE - woker - subacct - item valueMainAccount = MainAccount::findByMainAccountId('910001'); //Get main account ValueContract = new DimensionAttributeValueContract(); ValueContract.parmName('Department') ; ValueContract.parmValue('6020'); //Value for dimension Department ListValueContract.addEnd(ValueContract); ValueContract = new DimensionAttributeValueContract(); ValueContract.parmName('Worker') ; ValueContract.parmValue('000001'); //Value for dimension ExpenseCode ListValueContract.addEnd(ValueContract); ValueContract = new DimensionAttributeValueContract(); ValueContract.parmName('SubAcct') ; ValueContract.parmValue('교보생명'); //Value for dimension Project ListValueContract.addEnd(ValueContract); ValueContract = new DimensionAttributeValueContract(); ValueContract.parmName('Item') ; ValueContract.parmValue('110329'); //Value for dimension Project ListValueContract.addEnd(ValueContract); LedgerAccountContract.parmMainAccount(valueMainAccount.MainAccountId); LedgerAccountContract.parmValues(ListValueContract); //if combination is not exist then create new one dimStorage = DimensionServiceProvider::buildDimensionStorageForLedgerAccount(LedgerAccountContract); davc = DimensionAttributeValueCombination::find(dimStorage.save()); info(strFmt(\"RecId : %1 - DisplayValue : %2\", davc.RecId, davc.DisplayValue)); } or you can use this way static void createDimension(Args _args) { Struct struct = new Struct(); container financialDimension; LedgerDimensionAccount legder; //// Get main account with structure : Mainacct - DE - woker - subacct - item struct.add('Department', '6020'); struct.add('Item', '220006'); struct.add('SubAcct', 'Max test account'); struct.add('Worker', '000002'); financialDimension += struct.fields(); financialDimension += struct.fieldName(1); financialDimension += struct.valueIndex(1); financialDimension += struct.fieldName(2); financialDimension += struct.valueIndex(2); financialDimension += struct.fieldName(3); financialDimension += struct.valueIndex(3); financialDimension += struct.fieldName(4); financialDimension += struct.valueIndex(4); legder = DimensionDefaultingService::serviceCreateLedgerDimension( DimensionStorage::getDefaultAccountForMainAccountNum(\"910001\"), AxdDimensionUtil::getDimensionAttributeValueSetId(financialDimension)); info(strFmt(\"%1\",legder)); } ","date":"July 5, 2016","objectID":"/2016-07-05-create-record-in-dimensionattributevaluecombination-manually/:0:0","tags":["xpp","programming","fidim"],"title":"Create record in DimensionAttributeValueCombination table manually.","uri":"/2016-07-05-create-record-in-dimensionattributevaluecombination-manually/"},{"categories":["ax2012"],"content":"If you want to list items come along with their Actvie Dimension, you can do it easily with this simple job InventTable inventTable; InventDimParm inventDimParm; ; inventTable = InventTable::find('110924'); inventDimParm = InventDimParm::activeDimFlag(InventDimGroupSetup::newInventTable(inventTable)); if(inventDimParm.InventSiteIdFlag) { info(\"Site Actived\"); } ","date":"January 17, 2016","objectID":"/2016-01-17-how-to-verify-active-inventory-dimensions-on-an-item/:0:0","tags":["inventdim"],"title":"How to verify active inventory dimensions on an item","uri":"/2016-01-17-how-to-verify-active-inventory-dimensions-on-an-item/"},{"categories":["services","ssrs","ax2012","trick","problem"],"content":"I updated my dynamics Ax development Environment by restoring Database from Production Database . After the restoring the database, when I run any report form Dynamics Ax, all gave error “Only integrated security is supported for AX queries.” The reporting Services are still working fine. For this, best way to redeploy them, create a new report folder, open Microsoft Dynamics Ax 2012 Management Shell (make sure you run Powershell as Administrator). Publish-AXReport -ReportName * ","date":"January 17, 2016","objectID":"/2016-01-15-only-integrated-security-is-supported-for-ax-queries/:0:0","tags":["ssrs","programming"],"title":"Only integrated security is supported for AX queries","uri":"/2016-01-15-only-integrated-security-is-supported-for-ax-queries/"},{"categories":["services","ssrs","ax2012","trick","problem"],"content":"Recently I updated my dynamics Ax development Environment by restoring Database from Production Dynamics AX DB and I got this problem Make sure that SQL Server Reporting Services is configured correctly. Verify the Web Service URL and Report Manager URL configuration in the SQL Reporting Services Configuration Manager. Anyway, The reporting Services are still working fine and i have already granted the AX Admin as System Administrator under site settings, Home folder settings and DynamicsAX folder with “Browser, Content Manager, DynamicsAXBrowser, My Reports, Publisher, Report Builder” roles. Solution is we need disable UAC (I’m using Windows Server 2012 R2) by Regedit go to Regedit: “HKEY_LOCAL_MACHINESOFTWAREMicrosoftWindowsCurrentVersionpoliciessystem” and changing the DWORD “EnableLUA” from 1 to 0. After the reboot, UAC is disabled. Happy AXsing ","date":"January 15, 2016","objectID":"/2016-01-15-ssrs-report-server-settings-validation-error-ax-2012-r3-cu9/:0:0","tags":["ssrs","programming"],"title":"SSRS Report Server Settings Validation Error- AX 2012 R3 CU9","uri":"/2016-01-15-ssrs-report-server-settings-validation-error-ax-2012-r3-cu9/"},{"categories":["ax2012"],"content":"Link Type: Active: Parent and child data source is updated immediately when a new record in the parent data source is selected. Continuous updates consume lots of resources consuming. Delayed: Parent and child A pause is inserted before linked child data sources are updated. This enables faster navigation in the parent data source because the records from child data sources are not updated immediately. For example, you can scroll a list of orders where you do not want to review the lines associated with the order until you stop scrolling. Passive: Parent and child Linked child data sources are not updated automatically. Updates of the child data source must be programmed on the active() method of the master data source. Join Types: InnerJoin Combined data source select the record from the main table that matches records in the joined table and vice versa. //X++selectAccountNumfromcustTablejoinTaxGroupIdfromcustGroupwherecustGroup.CustGroup==custTable.CustGroup;//CROSSJOINinT-SQL:SELECTT1.ACCOUNTNUM,T1.RECID,T2.TAXGROUPID,T2.RECIDFROMCUSTTABLET1CROSSJOINCUSTGROUPT2WHERE((T1.PARTITION=?)AND(T1.DATAAREAID=?))AND(((T2.PARTITION=?)AND(T2.DATAAREAID=?))AND(T2.CUSTGROUP=T1.CUSTGROUP))There is one record for each match. Records without related records in the other data source are eliminated from the result. Outer Join: Combined data source select the records from the main table. The records are retrieved whether they have matching records in the joined table //X++:selectAccountNumfromcustTableouterjoinAccountIDfromcustBankAccountwherecustBankAccount.CustAccount==custTable.AccountNum;//LEFTOUTERJOINinT-SQL:SELECTT1.ACCOUNTNUM,T1.RECID,T2.ACCOUNTID,T2.RECIDFROMCUSTTABLET1LEFTOUTERJOINCUSTBANKACCOUNTT2ON(((T2.PARTITION=?)AND(T2.DATAAREAID=?))AND(T1.ACCOUNTNUM=T2.CUSTACCOUNT))WHERE((T1.PARTITION=?)AND(T1.DATAAREAID=?))Exist Join: Combined data sourceThe data source retrieves a record from the main table for each matching record in the joined table. //X++:selectAccountNumfromcustBankAccountexistsjoincustTablewherecustBankAccount.CustAccount==custTable.AccountNum;//EXISTS(SELECT'x'...)inT-SQL:SELECTT1.ACCOUNTNUM,T1.RECIDFROMCUSTBANKACCOUNTT1WHERE((T1.PARTITION=?)AND(T1.DATAAREAID=?))ANDEXISTS(SELECT'x'FROMCUSTTABLET2WHERE(((T2.PARTITION=?)AND(T2.DATAAREAID=?))AND(T1.CUSTACCOUNT=T2.ACCOUNTNUM)))The differences between InnerJoin and ExistJoin are as follows: When the join type is ExistJoin, the search ends after the first match has been found. When the join type is InnerJoin, all matching records are searched for. NotExistJoin: Combined data source Select records from the main table that do not have a match in the joined table. ","date":"January 7, 2016","objectID":"/2016-01-07-link-type-and-join-types-in-ax-2012/:0:0","tags":["trick","linktype","jointype"],"title":"Link Type and Join Types in ax 2012","uri":"/2016-01-07-link-type-and-join-types-in-ax-2012/"},{"categories":["ax2012"],"content":"This blog post is show how to apply OR conditions in query build ranges in a simple way on same field in a table. Let’s see the simple query : select*fromCustTablewhereAccountNum=='2001'||AccountNum=='2002'We can find out solutions on MSDN by using expression in query ranges, but as it has lot of specifications which needs to be followed. However there is a simple way to do it : static void Job12(Args _args) { CustTable cust; Query query = new Query(); QueryBuildDataSource qbds; QueryBuildRange queryRange1, queryRange2; ; qbds = query.addDataSource(tableNum(CustTable)); queryRange1 = qbds.addRange(fieldNum(CustTable, AccountNum)); queryRange1.value('1168201'); queryRange2 = qbds.addRange(fieldNum(CustTable, AccountNum)); queryRange2.value('9034518'); info(qbds.toString()); } Result in string format as below image : SELECT*FROMCustTable(CustTable_1)WHERE((AccountNum=N'1168201')OR(AccountNum=N'9034518'))Thanks for reading :). Happy New Year. ","date":"December 30, 2015","objectID":"/2015-12-30-how-to-use-operator-in-querybuildrange/:0:0","tags":["trick"],"title":"How to use operator \"or\" in QueryBuildRange","uri":"/2015-12-30-how-to-use-operator-in-querybuildrange/"},{"categories":["ax2012","ssrs"],"content":"Scenario: I have 2 AOS AX (maybe same in one server or different servers), but only one server for reporting server (I will install and configure multiple SRS instances in this server). Thing is how can we install and configure 2 SSRS instances on same server and running for 2 AOS. easierly, please take a look the picture below Figure 1: Two SSRS instance are running same server. ","date":"December 16, 2015","objectID":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/:1:0","tags":["trick","aos"],"title":"How to install two instances SSRS on one server","uri":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/"},{"categories":["ax2012","ssrs"],"content":"Problems: First you need to install 2 SSRS instance in same server, and install reporting service component for first AOS, this step is very simple. The problems come when we install second reporting service component for second AOS. Reporting service component uses business connector to connect to AX, and it’s saved on configuration in Registry. When we install second reporting service component it will through message that component already installed. ","date":"December 16, 2015","objectID":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/:2:0","tags":["trick","aos"],"title":"How to install two instances SSRS on one server","uri":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/"},{"categories":["ax2012","ssrs"],"content":"How to do: After installed second instance into C:\\Program Files\\Microsoft SQL Server\\MSRS12.InstanceName\\Reporting Services\\ReportServer\\bin, we need to create one Dynamics.AX.ReportConfiguration.axc file by AX configuration client with second AOS information. open MS Dyanmics AX Management Shell, run command below: Install-AXReportInstanceExtensions –ReportServerInstanceName [SSRSInstanceName] -Credential [DomainNameUserName] goto C:\\Program Files\\Microsoft SQL Server\\MSRS12.SecondInstance\\Reporting Services\\ReportServer fix fileconfi with value from Execution to FullTrust After this, remember restart reporting services. From now on, you can run 2 AX reporting instance in same server. Thank you for reading! ","date":"December 16, 2015","objectID":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/:3:0","tags":["trick","aos"],"title":"How to install two instances SSRS on one server","uri":"/2015-12-16-how-to-install-2-instances-ssrs-on-1-server/"},{"categories":["ax2012","sourcecontrol"],"content":"When you try connecting between TFS and Dynamics AX CU8, CU9 and you got error like this: Error 1 Team Foundation services are not available from server ****.visualstudio.com/defaultcollection. Technical information (for administrator): TF400813: Resource not available for anonymous access. Client authentication required. Error 2 Could not load file or assembly ‘Microsoft.TeamFoundation.Client, Version=10.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a’ or one of its dependencies. The system cannot find the file specified. Client computers that are not running Visual Studio 2010 must have the Team Foundation Server 2010 SP1 Object Model installed to use TFS source control with Microsoft Dynamics AX. TFS support TFS 2010, TFS 2012, TFS 2013 and TFS online, but to connect to these from AX you will need “TFS 2010 object model Sp1” which is client to connect to server. After install Team Foundation Server 2010 SP1 Object Model above. Client computers that are not running Visual Studio 2010 must have hotfix KB 2662296 installed to use TFS source control with Microsoft Dynamics AX. Once you have installed the above , restart your AOS and open AX client again, then try to check-in some Jobs. ","date":"November 20, 2015","objectID":"/2015-11-20-ax-2012-r3-cu8-cu9-and-tfs-online-2013-error/:0:0","tags":["error","tfs"],"title":"AX 2012 R3 CU8 CU9 and TFS Online 2013 Error","uri":"/2015-11-20-ax-2012-r3-cu8-cu9-and-tfs-online-2013-error/"},{"categories":["ax2012","sourcecontrol"],"content":"Scenario: Normally when we open form for the first time in Dynamics AX, it will take sometimes to compilte and cache into AOS. That’s why at second time always faster. If we often restart AOS, how can we keep performance ? Solution: After restart AOS we can let some scripts run to open up some often used forms then cache to AOS, then close those forms. Here is the code static void WarmupRF(Args _args) { UtilElements e; TreeNode treeNode; FormRun formRun; Args args = new Args(); while select e where e.utilLevel == UtilEntryLevel::var //\u003c-- specify layer here \u0026\u0026 e.recordType == UtilElementType::Form //\u003c-- and only forms \u0026\u0026 e.name like \"nameofformPrefix\" { try { treeNode = xUtilElements::getNodeInTree(xUtilElements::parentElement(e)); args.name(treeNode.AOTname()); formRun = ClassFactory.formRunClass(args); formRun.init(); //formRun.run(); //\u003c-- No need to run the form, but sometimes it can load the data formRun.close(); } catch { Infolog.clear(); continue; } } } ","date":"November 17, 2015","objectID":"/2015-11-17-caching-form-into-aos-to-increase-performance-for-dynamics-ax/:0:0","tags":["trick","aos","programming"],"title":"Caching form into AOS to increase performance for Dynamics AX","uri":"/2015-11-17-caching-form-into-aos-to-increase-performance-for-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"Beside modify metadata on form properties, as best practice we can use code like below to assign default value for combobox. You can use this code in the form’s init method after super(): {% highlight csharp %} ComboBoxName.selection(ComboBoxName::DefaultValue); {% endhighlight %} If this is a table field we should you best practice overriding the initValue method in the table: {% highlight csharp %} this.ComboBoxName = ComboBoxName::DefaultValue; {% endhighlight %} Override initValue in the form’s datasource only if it should be a specific behaviour in this form only. ","date":"November 13, 2015","objectID":"/2015-11-03-defaultvale-combobox-in-x/:0:0","tags":["operator","programming","trick"],"title":"DefaultValue ComboBox in Dynamics AX with X++","uri":"/2015-11-03-defaultvale-combobox-in-x/"},{"categories":["ax2012"],"content":"To make something as the LIKE operator in a query, just assign a value to the QueryRange including a wildcard. static void QueryBuildRange_Sample(Args _args) { Query query = new Query(); QueryRun queryRun; QueryBuildDataSource qbds; QueryBuildRange queryRange; CustTable custTable; qbds.addDataSource(tableNum(CustTable)); queryRange = qbds.addRange(fieldNum(CustTable, AccountNum)); queryRange.value(\"axd*\"); queryRun = new QueryRun(query); while(queryRun.next()) { custTable = queryRun.get(tableNum(CustTable)); print custTable.AccountNum; } pause; } ","date":"November 13, 2015","objectID":"/2015-11-13-how-to-use-like-operator-in-querybuildrange/:0:0","tags":["operator","programming"],"title":"HOW TO USE \"LIKE\" OPERATOR IN QUERYBUILDRANGE","uri":"/2015-11-13-how-to-use-like-operator-in-querybuildrange/"},{"categories":["general","sql"],"content":" Open Microsoft SQL Server Management Studio. Connect to the server where in the DB you want to rename is located. Modify the following script and run it -- Replace all MyDBs with the name of the DB you want to change its name USE[MyDB];-- Changing Physical names and paths -- Replace all NewMyDB with the new name you want to set for the DB -- Replace 'C:...NewMyDB.mdf' with full path of new DB file to be used ALTERDATABASEMyDBMODIFYFILE(NAME=' MyDB ',FILENAME='C:...NewMyDB.mdf');-- Replace 'C:...NewMyDB_log.ldf' with full path of new DB log file to be used ALTERDATABASEMyDBMODIFYFILE(NAME=' MyDB _log',FILENAME='C:...NewMyDB_log.ldf');-- Changing logical names ALTERDATABASEMyDBMODIFYFILE(NAME=MyDB,NEWNAME=NewMyDB);ALTERDATABASEMyDBMODIFYFILE(NAME=MyDB_log,NEWNAME=NewMyDB_log); Right click on the DB and select Tasks\u003eTake Offline Go to the location that MDF and LDF files are located and rename them exactly as you specified in first two alter commands. If you changed the folder path, then you need to move them there. Go back to Microsoft SQL Server Management Studio and right click on the DB and select Tasks\u003eBring Online. ","date":"November 3, 2015","objectID":"/2015-11-03-rename-a-database-in-sql-server/:0:0","tags":["trick","programming"],"title":"Rename a Database in SQL Server","uri":"/2015-11-03-rename-a-database-in-sql-server/"},{"categories":null,"content":"Web Services on IIS - Exception has been thrown by the target of an invocation","date":"August 4, 2015","objectID":"/2015-08-04-web-services-on-iis-exception-has-been-thrown-by-the-target-of-an-invocation-ax-installation/","tags":["error","ssrs"],"title":"Web Services on IIS - Exception has been thrown by the target of an invocation","uri":"/2015-08-04-web-services-on-iis-exception-has-been-thrown-by-the-target-of-an-invocation-ax-installation/"},{"categories":null,"content":"When I try to install Web Services on IIS for Retails POS Component, and I got the problem. This scenario shouldn’t be common in a production environment, but, it is indeed quite common in a VM machine (I’m using virtual machine Hyper-V on Windows 8.1) Error: Exception has been thrown by the target of an invocation So, the problem is relate to thee AOS Service account, which by default is usually NT AUTHORITYNETWORK SERVICE account. but because of we are running on a Domain Controller Server, we should use any specific Domain account created just for running AOS services, then you’ll success installing Web Services on IIS. Now please restart services and try again. Thank you for reading ","date":"August 4, 2015","objectID":"/2015-08-04-web-services-on-iis-exception-has-been-thrown-by-the-target-of-an-invocation-ax-installation/:0:0","tags":["error","ssrs"],"title":"Web Services on IIS - Exception has been thrown by the target of an invocation","uri":"/2015-08-04-web-services-on-iis-exception-has-been-thrown-by-the-target-of-an-invocation-ax-installation/"},{"categories":["ax2012","trick","ssrs"],"content":"reportManagerWebConfig.ps1 {% highlight powershell %} #Modify the Report Server Web.config file. ie replace MSRS11.VAS with your folder name Set-ExecutionPolicy Unrestricted $webConfig = “C:Program FilesMicrosoft SQL ServerMSRS11.VASReporting ServicesReportManagerWeb.config” $currentDate = (get-date).tostring(“mm_dd_yyyy-hh_mm_s”) # month_day_year - hours_mins_seconds $backup = $webConfig + “_$currentDate” $doc = new-object System.Xml.XmlDocument $doc.Load($webConfig) #save a backup copy $doc.Save($backup) Write-Host “Backup saved as \" + $backup $node = $doc.get_DocumentElement().“system.web”.httpRuntime $attribute = $doc.CreateAttribute(“maxRequestLength”) $attribute.set_Value(“100000”) $node.SetAttributeNode($attribute ) $doc.Save($webConfig) Write-Host “1) Modified the Report Manager Web.config file” {% endhighlight %} RsReportServer.ps1 {% highlight powershell %} #Modify the Report Server Web.config file. ie replace MSRS11.VAS with your folder name Set-ExecutionPolicy Unrestricted $version = “6.3.0.0” $webConfig = “C:Program FilesMicrosoft SQL ServerMSRS11.VASReporting ServicesReportServerRsReportServer.config” $currentDate = (get-date).tostring(“mm_dd_yyyy-hh_mm_s”) # month_day_year - hours_mins_seconds $backup = $webConfig + “.xml” #\"_$currentDate” $doc = new-object System.Xml.XmlDocument $doc.Load($webConfig) #save a backup copy $doc.Save($backup) Write Write-Host “Backup saved as \" + $backup #remove node “RSWindowsNegotiate” $node = $doc.documentElement.SelectSingleNode(\"//Configuration/Authentication/AuthenticationTypes/RSWindowsNegotiate”) if ($node) { { $node.ParentNode.RemoveChild($node) Write Write-Host “RSWindowsNegotiate Removed” } #Add node “IsRdceEnabled” $nodeService = $doc.documentElement.SelectSingleNode(\"//Configuration/Service\") $nodeIsRdceEnabled = $doc.documentElement.SelectSingleNode(\"//Configuration/Service/IsRdceEnabled\") #Set to true if already exists, otherwise create the node if ($nodeIsRdceEnabled) { { $nodeIsRdceEnabled.InnerXml = “True” } else { if ($nodeService) { {\r$subnodeService = $doc.createElement(\"IsRdceEnabled\")\r$subnodeService.InnerXml = \"True\"\r$nodeService.appendChild($subnodeService)\rWrite\rWrite-Host \"IsRdceEnabled added\"\r}\r } #Find Data $nodeCodeAxQuery = $doc.documentElement.SelectSingleNode(\"//Configuration/Extensions/Data/Extension[@Name=‘AXQUERY’]\") #Add Data Extension if (-not($nodeCodeAxQuery)) { { $nodeData = $doc.documentElement.SelectSingleNode(\"//Configuration/Extensions/Data\") if ($nodeData) {\r{\r$nodeData.InnerXml = $nodeData.InnerXml + \"\u003cExtension Name='AXQUERY' Type='Microsoft.Dynamics.Framework.Reports.AxQueryConnection,Microsoft.Dynamics.Framework.ReportsExtensions, Version=\" +\r$version +\r\", Culture=neutral, PublicKeyToken=31bf3856ad364e35'/\u003e\r\u003cExtension Name='AXDATAMETHOD' Type='Microsoft.Dynamics.Framework.Reports.AxDataMethodConnection,Microsoft.Dynamics.Framework.ReportsExtensions, Version=\" +\r$version +\r\", Culture=neutral, PublicKeyToken=31bf3856ad364e35'/\u003e\r\u003cExtension Name='AXREPORTDATAPROVIDER' Type='Microsoft.Dynamics.Framework.Reports.AxReportProviderConnection,Microsoft.Dynamics.Framework.ReportsExtensions, Version=\" +\r$version +\r\", Culture=neutral, PublicKeyToken=31bf3856ad364e35'/\u003e\r\u003cExtension Name='AXADOMD' Type='Microsoft.Dynamics.Framework.Reports.AxAdomdConnection,Microsoft.Dynamics.Framework.ReportsExtensions, Version=\" +\r$version +\r\", Culture=neutral, PublicKeyToken=31bf3856ad364e35'/\u003e\r\u003cExtension Name='AXENUMDATAPROVIDER' Type='Microsoft.Dynamics.Framework.Reports.EnumProviderConnection,Microsoft.Dynamics.Framework.ReportsExtensions, Version=\" +\r$version +\r\", Culture=neutral, PublicKeyToken=31bf3856ad364e35'/\u003e\"\rWrite-Host \"Data Extension added\"\r}\r } #Find Extensions $nodeExtensions = $doc.documentElement.SelectSingleNode(\"//Configuration/Extensions\") $nodeReportDefinitionCustomization = $doc.documentElement.SelectSingleNode(\"//Configuration/Extensions/ReportDefinitionCustomization\") if (-not($nodeReportDefinitionCustomization)) { { #Add ReportDefinition","date":"July 2, 2015","objectID":"/2015-07-02-modify-microsoft-dynamics-ax-2012-r3-ssrs-configurations/:0:0","tags":null,"title":"Modify Microsoft Dynamics AX 2012 R3 SSRS configurations using PowerShell","uri":"/2015-07-02-modify-microsoft-dynamics-ax-2012-r3-ssrs-configurations/"},{"categories":["ax2012","trick"],"content":"AxBuild.exe for Parallel Compile on AOS","date":"July 1, 2015","objectID":"/2015-07-01-axbuild-exe-for-parallel-compile-on-aos/","tags":["axbuild","trick","aos"],"title":"AxBuild.exe for Parallel Compile on AOS","uri":"/2015-07-01-axbuild-exe-for-parallel-compile-on-aos/"},{"categories":["ax2012","trick"],"content":"If you have only 10 mins to build ax, try this In AOS server, go to C:\\Program Files\\Microsoft Dynamics AX\\60\\Server\\DAX\\bin and open cmd from here then run this command {% highlight yaml %} axbuild.exe xppcompileall /s=01 /altbin=“C:\\Program Files (x86)\\Microsoft Dynamics AX\\60\\Client\\Bin” {% endhighlight %} Result Once compile complete, you can import compile log file at C:\\Program Files\\Microsoft Dynamics AX\\60\\Server\\DAX\\log into compiler output of AX client Reference from MSDN . ","date":"July 1, 2015","objectID":"/2015-07-01-axbuild-exe-for-parallel-compile-on-aos/:0:0","tags":["axbuild","trick","aos"],"title":"AxBuild.exe for Parallel Compile on AOS","uri":"/2015-07-01-axbuild-exe-for-parallel-compile-on-aos/"},{"categories":["ax2012"],"content":"List Page Interaction Class","date":"July 1, 2015","objectID":"/2015-06-09-list-page-interaction-class/","tags":["trick","Interaction"],"title":"List Page Interaction Class","uri":"/2015-06-09-list-page-interaction-class/"},{"categories":["ax2012"],"content":"Form interaction classes that allow user interface control logic to be shared across forms. For instance, controlling which buttons are available to a list page and the associated detail form. The interaction classes are extending a base ListPageInteraction class. This has some methods supported by the kernel to interact e.g. with initializations of the list page form. Other classes can be build stand alone to execute e.g. a batch process or represent a web service or posting classes. Form interaction classes are not mandatory for list pages but should be used on data entry forms that require logic. This ensures consistency and allows easier maintenance of logic. This class inherits from SysListPageInteractionBase, here is some methods we need to know initializing: Called when the form is initializing – Similar to the form init method intializeQuery: Also called when the form is initializing – Similar to the datasource init method. selectionChanged: Called when the active record changes – Similar to the datasource active method. setButtonEnabled: Should be overridden to dynamically enable/disable buttons based on the current selection. This is called from the selectionChanged method. {% highlight csharp %} public void selectionChanged() { Requisition requisition = this.listPage().activeRecord(queryDataSourceStr(RequisitionQuery,Requisition)); super(); if(requisition.WorkflowApprovalStatus == WorkflowApprovalStatus::Approved)\rthis.listPage().actionPaneControlEnabled(formControlStr(RequisitionListPage,Edit),true);\relse\rthis.listPage().actionPaneControlEnabled(formControlStr(RequisitionListPage,Edit),false);\r } {% endhighlight %} setButtonVisibility: Should be overridden to show/hide buttons when the form first opens. This is used more to do a one-off layout adjustment based on system configuration/parameters, as well as the menu-item used to open the form. eg If you have a menu-item that opens a form based on status, you may want to hide the relevant status field to reduce clutter. Thank you for reading! ","date":"July 1, 2015","objectID":"/2015-06-09-list-page-interaction-class/:0:0","tags":["trick","Interaction"],"title":"List Page Interaction Class","uri":"/2015-06-09-list-page-interaction-class/"},{"categories":["ax2012","trick"],"content":"Execute external database Stored Procedure from X++ code using ODBC connectivity","date":"May 13, 2015","objectID":"/2015-05-13-execute-external-database-stored-procedure-from-x-code-using-odbc-connectivity/","tags":["trick","xpp","programming"],"title":"Execute external database Stored Procedure from X++ code using ODBC connectivity","uri":"/2015-05-13-execute-external-database-stored-procedure-from-x-code-using-odbc-connectivity/"},{"categories":["ax2012","trick"],"content":"This is to show a method to execute external database stored procedures from X++ code. Create a job in AOT with following code. Follow the steps as explained here in the code like replace Server Name, Database name , Stored Procedure name. The below code is executed through the ODBC Connection. {% highlight csharp %} static void execExternalDatabase(Args _args) { LoginProperty loginProperty; ODBCConnection odbcConnection; Statement statement; ResultSet resultSet; ResultSetMetaData resultSetMetaData;\rCounter counter;\rstr sql;\rSqlStatementExecutePermission perm;\r;\rloginProperty = new LoginProperty();\rloginProperty.setServer(\"SERVERNAME Here\"); // Replace your Database Server Name here\rloginProperty.setDatabase(\"DemoDB\"); //Replace your Database name here\rodbcConnection = new ODBCConnection(loginProperty); // setting odbc connection here.\r// ODBC Connection to create statement\rstatement = odbcConnection.createStatement();\r// Replace the StoredProcedure you want to execute.\rsql = strfmt('EXEC[myStoredProcedureName]');\r// Set code access permission to Execute\rperm = new SqlStatementExecutePermission(sql);\rperm.assert();\rtry\r{\r// if Stored Procedure has Select query use executeQuery method.\rresultSet = statement.executeQuery(sql);\rresultSet.next();\rresultSetMetaData = resultSet.getMetaData();\rfor (counter = 1; counter \u003c= resultSetMetaData.getColumnCount(); counter++)\r{\rswitch(resultSetMetaData.getColumnType(counter))\r{\rcase 0,1 :\rinfo(resultSet.getString(counter));\rbreak;\rcase 3:\rinfo(date2StrUsr(resultSet.getdate(counter)));\rbreak;\r}\r}\r}\rcatch (exception::Error)\r{\rprint \"An error occured in the query.\";\rpause;\r}\r// Code access permission scope ends here.\rCodeAccessPermission::revertAssert();\r } {% endhighlight %} Used a simple select query in the stored procedure and the result will be displayed on the infolog. ","date":"May 13, 2015","objectID":"/2015-05-13-execute-external-database-stored-procedure-from-x-code-using-odbc-connectivity/:0:0","tags":["trick","xpp","programming"],"title":"Execute external database Stored Procedure from X++ code using ODBC connectivity","uri":"/2015-05-13-execute-external-database-stored-procedure-from-x-code-using-odbc-connectivity/"},{"categories":["ax2012","ssrs"],"content":"How to deploy all the reports in AX2012 by using Management Shell","date":"May 13, 2015","objectID":"/2015-05-13-how-to-deploy-all-the-reports-in-ax2012-by-using-management-shell/","tags":["trick","ssrs"],"title":"How to deploy all the reports in AX2012 by using Management Shell","uri":"/2015-05-13-how-to-deploy-all-the-reports-in-ax2012-by-using-management-shell/"},{"categories":["ax2012","ssrs"],"content":"Login to the AX AOS server and follow below steps. Click Start \u003e Administrative Tools. Right-click the Microsoft Dynamics AX 2012 Management Shell option. Click Run as administrator. Go to PowerShell command prompt and run with command Publish-AXReport –ReportName * Wait up to getting Deployment successful message in command prompt. ","date":"May 13, 2015","objectID":"/2015-05-13-how-to-deploy-all-the-reports-in-ax2012-by-using-management-shell/:0:0","tags":["trick","ssrs"],"title":"How to deploy all the reports in AX2012 by using Management Shell","uri":"/2015-05-13-how-to-deploy-all-the-reports-in-ax2012-by-using-management-shell/"},{"categories":["ax2012","trick"],"content":"Execute Stored Procedure from X++ code","date":"May 12, 2015","objectID":"/2015-05-12-execute-stored-procedure-from-x-code/","tags":["trick","xpp","programming"],"title":"Execute Stored Procedure from X++ code","uri":"/2015-05-12-execute-stored-procedure-from-x-code/"},{"categories":["ax2012","trick"],"content":"To execute a stored procedure from X++ use the Server method, the Client method does not have permissions. you don’t require any special privileges or permissions to execute a stored procedure. if used other then Server method, a message should appear like this Request for the permission of type SqlStatementExecutePermission failed. {% highlight csharp %} public static void main(AssemblyLoadEventArgs _args) { Connection con = new Connection(); Statement stmt = new Con.createStatement(); ResultSet r;\rstr sql;\rSqlStatementExecutePermission perm;\rsql = stmt('EXEC [StoreprocedureName]');\rperm = new SqlStatementExecutePermission(sql);\rperm.assert();\rtry\r{\rstmt.executeUpdate(sql);\r}\rcatch (Exception::Error)\r{\rprint \"An error occured in the query\";\rpause;\r} CodeAccessPermission::revertAssert();\r } {% endhighlight %} ","date":"May 12, 2015","objectID":"/2015-05-12-execute-stored-procedure-from-x-code/:0:0","tags":["trick","xpp","programming"],"title":"Execute Stored Procedure from X++ code","uri":"/2015-05-12-execute-stored-procedure-from-x-code/"},{"categories":["ax2012","trick"],"content":"Common prefies Dyanmics AX 2012","date":"April 13, 2015","objectID":"/2015-04-13-common-prefix-dyanmics-ax-2012/","tags":["trick"],"title":"Common prefies Dyanmics AX 2012","uri":"/2015-04-13-common-prefix-dyanmics-ax-2012/"},{"categories":["ax2012","trick"],"content":"When creating new elements, ensure that you follow the recommended naming conventions. Any future development and maintenance will be much easier. Ax Microsoft Dynamics AX typed data source Axd Microsoft Dynamics AX business document Asset Asset management BOM Bill of material COS Cost accounting Cust Customer Dir Directory, global address book EcoRes Economic resources HRM/HCM Human resources Invent Inventory management JMG Shop flor control KM Knowledge management Ledger General ledger PBA Product builder Prod Production Proj Project Purch Purchase Req Requirements Sales Sales SMA Service management SMM Sales and marketing management, also called customer relationship management (CRM) Sys Application frameworks and development tools Tax Tax engine Vend Vendor Web Web framework WMS Warehouse management ","date":"April 13, 2015","objectID":"/2015-04-13-common-prefix-dyanmics-ax-2012/:0:0","tags":["trick"],"title":"Common prefies Dyanmics AX 2012","uri":"/2015-04-13-common-prefix-dyanmics-ax-2012/"},{"categories":["ax2012","trick"],"content":"X++ Performance tips","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 1: Measure execution time of your code Measuring is knowing. Before you start changing code, make sure you have a set of data you can keep reusing for your tests. Measure the performance of your code on that data after each change in code so you know the impact of your changes. One way to do this is by using the Winapi::getTickCount() or WinApiServer::getTickCount() if your code runs on server method. {% highlight csharp %} static void KlForTickCountSample(Args _args) { int ticks; ; // get the tickcount before the process starts ticks = winapi::getTickCount(); // start the process\rsleep(2000); // simulate 2 seconds of processing\r// compare tickcount\rticks = winapi::getTickCount() – ticks;\r// display result\rinfo(strfmt('Number of ticks: %1', ticks));\r } {% endhighlight %} ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:1","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 2: limit the number of loops A LOT of time goes into loops. If you have a performance problem, start looking for loops. Code can run really fast, but it can get slow when it is executed too many time, eg, in a loop. ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:2","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 3: avoid if in while select When there is a if in a while select, see if you can rewrite it a a where statement in your select. Don’t be affraid use a join either. Consider the following example: {% highlight csharp %} static void KlForIfInLoop(Args _args) { VendTable vendTable; ; // usually slower while select vendTable { if(vendTable.VendGroup == ‘VG1’) { info(vendTable.AccountNum); } } // usually faster\rwhile select vendTable\rwhere vendTable.VendGroup == 'VG1'\r{\rinfo(vendTable.AccountNum);\r}\r } {% endhighlight %} ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:3","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 4: avoid double use of table methods Using table methods a lot can get really slow if you do it wrong. Consider the following example: {% highlight csharp %} static void klForTableMethodsSlow(Args _args) { SalesLine salesLine; InventDim inventDim; ; // select a salesline\rselect firstonly salesLine;\rinventDim.InventColorId = salesLine.inventDim().InventColorId;\rinventDim.InventSizeId = salesLine.inventDim().InventSizeId;\rinventDim.inventBatchId = salesLine.inventDim().inventBatchId;\r } {% endhighlight %} This example code looks nice, but there’s a problem. The salesLine.inventDim() method contains the following: {% highlight csharp %} InventDim inventDim(boolean _forUpdate = false) { return InventDim::find(this.InventDimId, _forUpdate); } {% endhighlight %} This means that the invendDim record is read three times from the database. It is better to declare the inventDim record locally and only retrieve it once: {% highlight csharp %} static void klForTableMethodsFast(Args _args) { SalesLine salesLine; InventDim inventDim; InventDim inventDimLoc; ; // select a salesline\rselect firstonly salesLine;\rinventDimLoc = salesLine.inventDim();\rinventDim.InventColorId = inventDimLoc.InventColorId;\rinventDim.InventSizeId = inventDimLoc.InventSizeId;\rinventDim.inventBatchId = inventDimLoc.inventBatchId;\r } {% endhighlight %} ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:4","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 5: Don’t put too much code on tables Code on tables is usually fast, but things can get slow if you use it to much. Say you have a table with an InventDimId field. If you have 5 methods that need the InventDim record, because you don’t have a classDeclaration method on your table, you need to call this function 5 times, once in every method: {% highlight csharp %} InventDim::find(this.inventDim) {% endhighlight %} When you put these methods on a class, you could optimise it by fetching the record only once and storing it in the classDeclaration, or better, passing it as a parameter to your methods. An other example is fetching parameters from parameter tables, eg InventParameters::find(). On a table, you have to fetch it each time you call a method. In a class, you would probably optimize your code to only fetch the parameter record once. ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:5","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 6: Use the fastest code For some tasks, there is special code that is faster than the code you would normally write. For example: {% highlight csharp %} // slower while select forupdate custTable where custTable.custGroup == ‘TST’ { custTable.delete(); } // faster delete_from custTable where custTable.custGroup == ‘TST’; {% endhighlight %} The same applies to update_recordset for updating records. Also, when adding values to the end of a container {% highlight csharp %} cont += “a value”; {% endhighlight %} is faster than {% highlight csharp %} cont = conins(cont, conlen(cont), “a value”); {% endhighlight %} ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:6","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Tip 7: Every optimization counts Remember that every optimization you do to you code counts, even if it’s a little one. Small performance tweaks can have a huge effect once you process large quantities of data. So don’t be lazy, and optimize. Share from http://www.artofcreation.be/ ","date":"February 12, 2015","objectID":"/2015-02-12-x-performance-tips/:0:7","tags":["trick","xpp","programming"],"title":"X++ Performance tips","uri":"/2015-02-12-x-performance-tips/"},{"categories":["ax2012","trick"],"content":"Create and write to XML file in Dynamics AX","date":"February 4, 2015","objectID":"/2015-02-04-create-and-write-to-xml-file-in-dynamics-ax/","tags":["trick","xpp","programming"],"title":"Create and write to XML file in Dynamics AX","uri":"/2015-02-04-create-and-write-to-xml-file-in-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"In this post let’s explore creating XML using X++ code in Dynamics AX. The following example shows how to create and write data to an XML file by using the XmlDocument, XmlElement, and XmlWriter classes. It loops through all of the records in the CarTable and find all the fields in the table automatically by using the DictTable and DictField classes. {% highlight csharp %} static void WriteXml(Args _args) { XmlDocument xmlDoc;\rXmlElement xmlRoot;\rXmlElement xmlField;\rXmlElement xmlRecord;\rXMLWriter xmlWriter;\rCarTable carTable;\rDictTable dTable = new DictTable(tablenum(CarTable));\rDictField dField;\rint i, fieldId;\rstr value;\r; #CarsXmlTags // Create a new object of the XmlDocument class\rxmlDoc = XmlDocument::newBlank();\r// Create the root node\rxmlRoot = xmlDoc.createElement(#CarRootNode);\r// Loop through all the records in the carTable\rwhile select carTable\r{\r// Create a XmlElement (record) to hold the\r// contents of the current record.\rxmlRecord = xmlDoc.createElement(#CarRecords);\r// Loop through all the fields in the record\rfor (i=1; i\u003c=dTable.fieldCnt(); i++)\r{\r// Get the fieldId from the field-count\rfieldId = dTable.fieldCnt2Id(i);\r// Find the DictField object that matches the fieldId\rdField = dTable.fieldObject(fieldId);\r// Skip system fields\rif (dField.isSystem())\rcontinue;\r// Create a new XmlElement (field) and\r// have the name equal to the name of the\r// dictField\rxmlField = xmlDoc.createElement(dField.name());\r// Convert values to string. I have just added\r// a couple of conversion as an example.\r// Use tableName.(fieldId) instead of fieldname\r// to get the content of the field.\rswitch (dField.baseType())\r{\rcase Types::Int64 :\rvalue = int642str(carTable.(fieldId));\rbreak;\rcase Types::Integer :\rvalue = int2str(carTable.(fieldId));\rbreak;\rdefault :\rvalue = carTable.(fieldId);\rbreak;\r}\r// Set the innerText of the XmlElement (field)\r// to the value from the table\rxmlField.innerText(value);\r// Append the field as a child node to the record\rxmlRecord.appendChild(xmlField);\r}\r// Add the record as a child node to the root\rxmlRoot.appendChild(xmlRecord);\r}\r// Add the root to the XmlDocument\rxmlDoc.appendChild(xmlRoot);\r// Create a new object of the XmlWriter class\r// in order to be able to write the xml to a file\rxmlWriter = XMLWriter::newFile(@\"c:tempcars.xml\");\r// Write the content of the XmlDocument to the\r// file as specified by the XmlWriter\rxmlDoc.writeTo(xmlWriter);\r } {% endhighlight %} The file that is created looks like the one in the following screenshot(only first part of the file is shown): As you can see, this file is based on a standard XML format with tags and values only. You can, however, use tag attributes as well. To put the values from the table into tag attributes instead of their own tags, simply change the following code snippet in the example above {% highlight csharp %} // Set the innerText of the XmlElement (field) // to the value from the table xmlField.innerText(value); // Append the field as a child node to the record xmlRecord.appendChild(xmlField); {% endhighlight %} With these lines: {% highlight csharp %} // Add the attribute to the record xmlRecord.setAttribute(dField.name(), value); {% endhighlight %} The file that is created now looks like the one in the following screenshot: ","date":"February 4, 2015","objectID":"/2015-02-04-create-and-write-to-xml-file-in-dynamics-ax/:0:0","tags":["trick","xpp","programming"],"title":"Create and write to XML file in Dynamics AX","uri":"/2015-02-04-create-and-write-to-xml-file-in-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"The answer is that there is no difference, the difference is a conceptual one rather than a functional or a technical one. So I think you will make a better choice for your scenario base on functional side. ","date":"January 27, 2015","objectID":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/:0:0","tags":["trick","xpp","programming"],"title":"What is the difference difference between menu item Display, Output and Action","uri":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"Display Menu item This folder is used to contain menu items that reference runnable application objects that primarily present forms, ddialog and so on, to the user. May be this forms, dialog called from another forms. ","date":"January 27, 2015","objectID":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/:0:1","tags":["trick","xpp","programming"],"title":"What is the difference difference between menu item Display, Output and Action","uri":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"Output Menu item An output menu item application objects whose primarily function is to print a result or report. ","date":"January 27, 2015","objectID":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/:0:2","tags":["trick","xpp","programming"],"title":"What is the difference difference between menu item Display, Output and Action","uri":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/"},{"categories":["ax2012","trick"],"content":"Action Menu item You should create a menu item under this folder if your runnable application objects whose primarily function is to do some kind of a job, such as creating or updating transactions in the database. ","date":"January 27, 2015","objectID":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/:0:3","tags":["trick","xpp","programming"],"title":"What is the difference difference between menu item Display, Output and Action","uri":"/2015-01-27-what-is-the-difference-difference-between-menu-item-display-output-and-action-in-dynamics-ax/"},{"categories":["ax2012","trick","general"],"content":"Understand model store architectural in AX 2012","date":"October 10, 2014","objectID":"/2014-10-10-understand-model-store-architectural/","tags":["architectural"],"title":"Understand model store architectural in AX 2012","uri":"/2014-10-10-understand-model-store-architectural/"},{"categories":["ax2012","trick","general"],"content":"The model store is the portion of the Microsoft Dynamics AX database where all Microsoft Dynamics AX application elements are stored, including customization. The model store replaces the AOD (application object definition) files used in previous releases of Microsoft Dynamics AX (I mean from 4.0 to 2009). Layer and model information are integral parts of the store. The AOS has access to the model store, handles layer-flattening, and provides model data to all the Microsoft Dynamics AX sub-systems, such as form- and report-rendering and X++ code. Microsoft Dynamics AX contains sixteen layers. Each layer consists of one or more logical parts called models. A system generated model exists for each layer. For example, the VAR Model is the system generated model for the VAR layer. You can use the system generated models to install and start working with the base Microsoft Dynamics AX system. You can leverage the capabilities of models, and tools and functionality that support the models, during customization of the Microsoft Dynamics AX application. The model store is the portion of the Microsoft Dynamics AX database where all Microsoft Dynamics AX application elements are stored, including customization. The model store replaces the AOD files used in previous releases of Microsoft Dynamics AX. It can be managed through the AXUtil command line utility, or by using Windows PowerShell. The baseline model store database holds model store tables for the previous version of metadata. Use it only during an upgrade. The baseline model store is similar to the old folder in previous releases of Microsoft Dynamics AX. Thank you for reading! ","date":"October 10, 2014","objectID":"/2014-10-10-understand-model-store-architectural/:0:0","tags":["architectural"],"title":"Understand model store architectural in AX 2012","uri":"/2014-10-10-understand-model-store-architectural/"},{"categories":["ax2012","general"],"content":"Architecture overview Microsoft Dynamics AX 2012","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":" Understanding the internal architecture of Microsoft Dynamics AX 2012 can help you make decision when planning and developing a Microsoft Dynamics AX 2012 system. Here are some pointers on DAX 2012 architecture primarily for DAX 2012 architects \u0026 solution developers. This topic provides a high-level overview of the system architecture of Microsoft Dynamics AX. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:0:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"System architecture This diagram provides a high-level over of a Microsoft Dynamics AX 2012 system with all components installed, and describes how communications flow between the components. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:1:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"1. Application Object Server (AOS) architecture This diagram describes the functionality within the AOS Windows service, and describes how communications flow within it. Note: Clients communicate with an AOS by using remote procedure calls (RPCs), Windows Communication Foundation (WCF), or AOS services. In previous releases, other components and third-party programs could communicate with an AOS by using either .NET Business Connector or Application Integration Framework (AIF). For this release, we recommend that third-party programs use AOS services to communicate with AOS. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:1:1","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"2. Business Connector architecture The differences between the client kernel as it runs on a standard client and a Business Connector client are: The Session Manager in the client kernel manages only a single instance–in the Business Connector kernel, it manages multiple instances. he client kernel includes forms security, while the Business Connector kernel does not. This diagram describes the architecture of the Business Connector version of the client kernel, and describes how communications flow within it. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:1:2","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"3. Application file server architecture ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:1:3","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Model store architecture Microsoft Dynamics AX contains sixteen layers. Each layer consists of one or more logical parts called models. A model is generated for each layer. For example, VAR Model is the model that the system generates for the VAR layer. The system generated models let you install and work with the base Microsoft Dynamics AX system. When you customize the Microsoft Dynamics AX program, you can take advantage of the capabilities of models. The following table describes the application object layers in Microsoft Dynamics AX 2012: ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:2:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Client architecture This diagram describes the functionality within the client, and describes how communications flow within it. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:3:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Client/server communication The client communicates with various Microsoft Dynamics AX components in the following ways: The client uses the remote procedure call (RPC) protocol to communicate with Application Object Server (AOS). The client never accesses the database or metadata directly. AOS sends the application objects and data to the client. The data layer that the client uses is based on data sources that are specified in metadata for forms and queries. In addition, any X++ code that is required to retrieve data can use the built-in language support to query and adjust data. The client uses a report Web Part to interact with the report server. By calling the web services that are exposed by the report server, the report control in the Web Part displays information that is contained in Reporting Services reports. These reports can include either transnational data from the Microsoft Dynamics AX application or OLAP cubes from Microsoft SQL Server Analysis Services. Cubes provide business analytic and key performance indicators (KPIs). The client provides workflow forms, alerts, and controls so that users can participate in the business process by using the Workflow system. The Workflow system is a Microsoft Dynamics AX component that enables workflow processes by using Windows Communication Foundation classes. The client provides a Help viewer, which is an application that displays context-sensitive Help topics. The Help topics are retrieved from a Help server that is located on-premises. The client also provides Role Centers, or role-based home pages, for users. Role Centers provide role-specific tasks, activities, alerts, reports, and business intelligence that help users increase their productivity. To interact with the Role Centers that are provided by Enterprise Portal and hosted on Internet Information Services (IIS), the client uses a browser control. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:4:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Services and AIF architecture AX 2012 exposes its functionality through services that are based on Windows Communication Foundation (WCF) and hosted on Application Object Server (AOS). External applications and client applications on the local area network consume AX services by accessing them directly from AOS. These clients and applications include AX components such as the AX client, Office Add-, and Enterprise Portal. Internet-based external applications and clients access the AX services through Internet Information Services (IIS). IIS routes the incoming requests for AX services to AOS. All services requests, regardless of their origin, are handled by the WCF runtime that is hosted on AOS. The AIF request preprocessor, if it is configured, can intercept the inbound request messages for custom preprocessing, such as message transforms or value substitutions. The AX service invokes the necessary business logic to process the inbound request message. Similarly, the AIF response postprocessor, if it is configured, can intercept the outbound response messages for custom post-processing, such as message transforms or value substitutions. The AIF response postprocessor then returns the response to the client. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:5:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Enterprise Portal architecture This diagram provides a logical overview of a Microsoft Dynamics AX 2012 system with an Enterprise Portal server, and also describes the various components of the Enterprise Portal architecture. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:6:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Security architecture This following diagram provides a high-level overview of the security architecture of Microsoft Dynamics AX 2012. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:7:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Workflow system architecture This following diagram provides a high-level architecture of the workflow infrastructure. The workflow infrastructure consists of two components that are hosted on Application Object Server (AOS): the X++ workflow run-time and the managed workflow run-time. ![](/imagesposts/Workflow_system_arcitechture (1).gif) ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:8:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Analytic architecture The following diagram shows the Microsoft SQL Server Analysis Services cubes that are included with Microsoft Dynamics AX, and the components that are used to access them. ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:9:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":["ax2012","general"],"content":"Reporting architecture The following diagram illustrates the architecture of the reporting functionality in Microsoft Dynamics AX. Thank you for reading! ","date":"January 1, 2013","objectID":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/:10:0","tags":["architectural","axbuild","xpp"],"title":"Architecture overview Microsoft Dynamics AX 2012","uri":"/2013-01-01-microsoft-dynamics-ax-2012-architecture-overview/"},{"categories":null,"content":"Start programming","date":"January 1, 2011","objectID":"/2011-01-01-start-programming/","tags":["fun"],"title":"Start programming","uri":"/2011-01-01-start-programming/"},{"categories":null,"content":"I don’t know exactly how I ended up where I am. I mean, programming, and lovin’ it. Even if I’m not so good. I’ve heard a thousand of guys telling stories like: “When I was twelve my parents bought me my first computer and I started learning on my own.” or “I won a programming contest when I was in highschool”. Great. Well done. I’ve never noticed about what coding was until I was eighteen, when I had to decide what to study at the University. Do you want to know what was I thinking about? First option: Computer Science. Second option: Arts (wtf?). Third option: Philosophy (WTF?). I’ve ever liked computers, yes, but I’d never thought I could do that amazing things with them. I also liked maths, puzzles, things that made my brain think hard and get fun at the same time. You know, quizes, enigmas, games… The conclusion was that I wanted to do something creative, where I could put my imagination on, where I could challenge myself in order to create new stuff. My first programming class was awful. I didn’t get nothing, and everyone seemed to be so cool on it, everyone with this big “Hello World” in their screens and a smile in their faces like ‘Yeah dude, I did it.”. I didn’t even know what to write down, or what was the teacher talking about. I was so frustrated, my first exam was… well, I don’t want to talk about my first exam. One day, I don’t know how, something changed. Suddenly, I realized what programming was. I really abstracted my mind, I looked at it from another perspective, and it came with me so clear and so beautiful and I can not explain with words what I felt. Was it easier from then? Not at all. In fact, I left Computer Science after the first year, with almost all the subjects passed, because there was still something that made me think I was not made for it. I was so lost, I didn’t know what to do with my life. I really liked programming, but there were so much thinks that seemed to be so far away from me. And I felt that everyone around me was going good on it, it was so frustrating that I couldn’t stand it anymore. Then, I decided I had to change my situation because there should be something out there waiting for me. I looked for other degrees in a lot of universities. It was. I do really love what I’m studying now, but the truth is that I think I’ve found my way. Actually, I will finish also Computer Science someday, but in a different place. And I’m still getting frustrated, of course, who doesn’t?, but I know I learned to love that frustration. Let me explain myself. Programming is that. Is try it out thousand of times. Is try to find a mistake between a million lines of code, it’s to abstract your mind to find an answer, it’s… beautiful. I know really good programmers that honestly, I think I’ll never reach out, I have not that brilliant brain. But I keep on trying it, I’m not the best, I just love what I do. Maybe this post is not just about programming, maybe is more about to find out what do you really love. Even if sometimes you hate it, or it makes you cry, or it makes you feel so stupid because you are not able to understand it, or if it makes you think there is a lot of people smarter than you doing the same thing better. Just… enjoy your time, fight for what you want, challenge yourself to go to the next step. ","date":"January 1, 2011","objectID":"/2011-01-01-start-programming/:0:0","tags":["fun"],"title":"Start programming","uri":"/2011-01-01-start-programming/"},{"categories":null,"content":"Professional Engineer and developer who focused on the Microsoft stack of technologies with significant experience with Dynamics 365 Finance, Supply Chain Management, Azure Cloud, and Azure DevOps. For more than ten years, I have installed, configured, developed, and managed business-critical systems for plenty of companies across the APAC region. During that time, I have worked across many industries, including manufacturing, distribution, finance, and professional services. Dynamics 365 Finance, Supply Chain Management experience Development: Familiar with extensibility in Dynamics 365 for finance and operations (Class extensions, method wrapping/replacing and Chain of Command). Strong X++ coding skills. Workflow, batch job development. Office add-ins development for form. Familiar with SSRS reports, data entity, Aggregate measurement. VSTS Azure DevOps configuration for DEV and UAT environment. Continuous build and deployment configuration for BUILD and UAT environment. Automation load test practice using Regression tool and Perf SDK. Expert in debugging in DEV/UAT and using trace parser. Project, model, package management. Provisioning and environment operation: Ability to deploy On-premises version (have successfully deployed two on-premises environments). Setup and provision Cloud-hosted environment include DEV and BUILD/TEST environment; implementation environment includes DEV, UAT sandbox, Production; VHD local development environment. LCS configuration with Azure subscription, mapping BPM with Azure DevOps. Environment maintenance and SQL performance monitoring within LCS. Apply packages, hotfixes, upgrading. Refresh data From PROD to UAT/DEV, moving data across the environments. Data management and integration: Building and using Aggregate Measurements, data entity, and Composite data entity development. Using data management framework to import and export data. Ability to use Bring your own database feature. Implement data integration in many scenarios using OData, Batch data API, Recurring integrations, Data package API, consume external web services, excel integration. Data integration by using Common Data Service (PowerApps). Ability to use Postman for integration testing. BI and Reporting: Building and extending Aggregate measurement for PowerBI report. Configure Power BI integration for workspaces. Familiar with Financial report, generate or reset data mart. Power BI integration with Entity store Configure BYOD to connect with another reporting system. Troubleshooting: Reading Trace parser for X++ logic error or data inconsistency. Using LCS to find expensive SQL queries for application hanging or slow Ability to use Fiddler to troubleshoot authentication error client interaction. Ability to use ProcDump, ListDLLs, Process Monitor tools. PowerShell scripts debugging for deployment errors. Coding philosophy Minimizing the footprint of changes (I know how painful is when merging code from different partners or upgrade or installing hot-fix). Where to make the change (always at the highest level and in this order: class, table, form data source field/method, form control). Using field groups (The reason this reduces footprint). Upgrades and system maintainability. Design for a service-oriented architecture. Design for code reuse. Apply Dynamics 365 design patterns and coding best practices. The modules which I’ve been working with General Ledger Financial Dimension Chart of accounts Financial statements – Balance sheet, Income statement Currency and exchange Journal and Journal posting framework Trade and Logistics Item creation Sales process Purchase process Transfer order Supply chain management Production BOM Routes and operations Purchase process Transfer order Retails Installation and configuration Retails POS The Async Service Real-time Service Certificate Management Warehouse management Workflows Picking and packing Mobile devices Here are my badges. ","date":"January 1, 0001","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"},{"categories":["ax2012","trick"],"content":"Base on JournalId on LedgerJournalTable you can use code below to post the transactions {% highlight csharp %} //Contract class [ DataMemberAttribute(‘gJournalId’), SysOperationDisplayOrderAttribute(‘1’) ] public LedgerJournalId parmJournalNum(LedgerJournalId _journalId = gJournalId) { gJournalId = _journalId; return gJournalId;\r } //Processing class [SysEntryPointAttribute] public void process(MAV_PostCustPaymentJourContract _contract) { LedgerJournalTable ledgerJournalTable; LedgerJournalCheckPost postCustPaymentJournal; ledgerJournalTable = LedgerJournalTable::find(_contract.parmJournalNum());\rif (ledgerJournalTable)\r{\rpostCustPaymentJournal = LedgerJournalCheckPost::newLedgerJournalTable(ledgerJournalTable, NoYes::Yes);\rpostCustPaymentJournal.run();\r}\r } {% endhighlight %} ","date":"January 1, 0001","objectID":"/2016-12-26-posting-cust-payment-journal-using-x-/:0:0","tags":null,"title":"posting Cust payment journal using X++","uri":"/2016-12-26-posting-cust-payment-journal-using-x-/"},{"categories":null,"content":"Description for Search","date":"January 1, 0001","objectID":"/search/","tags":null,"title":"Search","uri":"/search/"}]